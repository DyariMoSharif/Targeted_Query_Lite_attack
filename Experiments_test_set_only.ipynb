{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b95dc6-8822-4827-93aa-e4dd25673e8d",
   "metadata": {},
   "source": [
    "# Proposed Approach implementation on the sampled data\n",
    "## -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322a1bb-f1ee-4af2-83b2-f51ca018d26d",
   "metadata": {},
   "source": [
    "## -----  MLP1L -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f1876-defc-4da8-a823-d790b892e8dc",
   "metadata": {},
   "source": [
    "### MLP1L - 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d9d9a9-a624-4c93-8edd-d5e10779fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\808634733.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -  62 / 1145.3 / 26.4  100 / 833.5 / 24.4  97 / 1101.5 / 25.0  72 / 1143.7 / 25.8  100 / 801.9 / 24.3  100 / 600.7 / 24.3  100 / 747.4 / 24.6  66 / 1150.0 / 25.3   99 / 795.6 / 24.6\n",
      "1              98 / 969.1 / 25.9                   -  100 / 465.5 / 23.4  100 / 492.5 / 23.5   99 / 856.1 / 25.0  100 / 668.2 / 24.2  100 / 392.4 / 23.6  100 / 349.5 / 23.5  100 / 571.5 / 23.8  100 / 409.8 / 23.6\n",
      "2             77 / 1182.5 / 25.7   9 / 1223.0 / 25.9                   -  72 / 1026.6 / 24.8  38 / 1151.0 / 25.7  28 / 1067.4 / 25.2   98 / 866.4 / 24.8  100 / 822.4 / 25.1  50 / 1089.4 / 25.2   98 / 948.6 / 25.5\n",
      "3             94 / 1107.8 / 25.5   99 / 871.9 / 25.2  100 / 717.8 / 24.2                   -  77 / 1202.3 / 25.9  100 / 594.3 / 23.9  95 / 1165.4 / 25.8  100 / 758.5 / 24.6  59 / 1095.0 / 25.2   99 / 717.4 / 24.6\n",
      "4             67 / 1195.1 / 25.9   89 / 988.1 / 25.7  100 / 667.4 / 24.2   95 / 910.5 / 24.9                   -  100 / 660.0 / 24.1  100 / 403.8 / 23.6  100 / 515.2 / 23.9   99 / 950.9 / 24.9   24 / 767.9 / 24.3\n",
      "5              99 / 997.1 / 25.3  100 / 786.6 / 25.2  100 / 861.0 / 24.8   99 / 823.5 / 24.5  72 / 1192.0 / 25.7                   -   97 / 954.7 / 25.2   99 / 833.7 / 25.2  66 / 1158.9 / 25.3   97 / 957.0 / 25.2\n",
      "6              11 / 959.3 / 24.9  30 / 1085.3 / 25.7   99 / 655.8 / 23.9   67 / 904.1 / 24.7   94 / 905.4 / 24.9   97 / 807.4 / 24.5                   -  100 / 707.8 / 24.7  31 / 1083.7 / 25.0   99 / 827.8 / 24.8\n",
      "7             65 / 1237.0 / 25.8  80 / 1119.0 / 25.8  100 / 599.6 / 24.0  40 / 1035.6 / 24.7  16 / 1333.0 / 25.8  100 / 770.4 / 24.3  100 / 914.2 / 25.2                   -  13 / 1003.0 / 24.7  100 / 789.0 / 24.3\n",
      "8             100 / 824.2 / 25.2   94 / 760.8 / 25.1  100 / 487.0 / 23.9  100 / 487.5 / 23.9  98 / 1017.7 / 25.5   98 / 695.1 / 24.3  100 / 640.1 / 24.5  100 / 616.2 / 24.7                   -  100 / 595.0 / 24.4\n",
      "9             89 / 1139.3 / 26.1   71 / 919.9 / 26.0  100 / 671.3 / 24.7  100 / 586.0 / 24.3  100 / 433.1 / 23.7  100 / 623.1 / 24.4  100 / 744.3 / 25.0  100 / 458.5 / 23.7  100 / 829.2 / 24.7                   -\n",
      "\n",
      "Total successful attacks: 7681 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_32_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  62 │ 100 │  97 │  72 │ 100 │ 100 │ 100 │  66 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  98 │   0 │ 100 │ 100 │  99 │ 100 │ 100 │ 100 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  77 │   9 │   0 │  72 │  38 │  28 │  98 │ 100 │  50 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  94 │  99 │ 100 │   0 │  77 │ 100 │  95 │ 100 │  59 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  67 │  89 │ 100 │  95 │   0 │ 100 │ 100 │ 100 │  99 │  24 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  99 │ 100 │ 100 │  99 │  72 │   0 │  97 │  99 │  66 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  11 │  30 │  99 │  67 │  94 │  97 │   0 │ 100 │  31 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  65 │  80 │ 100 │  40 │  16 │ 100 │ 100 │   0 │  13 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │ 100 │  94 │ 100 │ 100 │  98 │  98 │ 100 │ 100 │   0 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  89 │  71 │ 100 │ 100 │ 100 │ 100 │ 100 │ 100 │ 100 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 25.0 │ 23.0 │ 24.0 │ 25.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 24.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ 24.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 24.0 │ 25.0 │ 27.0 │ 25.0 │ 24.0 │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 25.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.4 │ 24.4 │ 25.0 │ 25.8 │ 24.3 │ 24.3 │ 24.6 │ 25.3 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.9 │ -    │ 23.4 │ 23.5 │ 25.0 │ 24.2 │ 23.6 │ 23.5 │ 23.8 │ 23.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.7 │ 25.9 │ -    │ 24.8 │ 25.7 │ 25.2 │ 24.8 │ 25.2 │ 25.2 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.5 │ 25.2 │ 24.2 │ -    │ 25.9 │ 23.9 │ 25.8 │ 24.6 │ 25.2 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.9 │ 25.7 │ 24.2 │ 24.9 │ -    │ 24.1 │ 23.6 │ 23.8 │ 24.9 │ 24.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.3 │ 25.2 │ 24.8 │ 24.5 │ 25.7 │ -    │ 25.2 │ 25.2 │ 25.3 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.9 │ 25.7 │ 23.9 │ 24.7 │ 24.9 │ 24.5 │ -    │ 24.7 │ 25.0 │ 24.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.8 │ 25.8 │ 24.0 │ 24.7 │ 25.8 │ 24.3 │ 25.2 │ -    │ 24.7 │ 24.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.2 │ 25.1 │ 23.9 │ 23.9 │ 25.5 │ 24.3 │ 24.5 │ 24.7 │ -    │ 24.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.1 │ 26.0 │ 24.7 │ 24.3 │ 23.7 │ 24.4 │ 25.0 │ 23.7 │ 24.7 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤═════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4       │ 5      │ 6      │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪═════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ 555.20 │ 269.54 │ 531.30 │ 497.78  │ 299.01 │ 97.36  │ 162.01 │ 199.47 │ 284.60 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ 650.54 │ -      │ 253.03 │ 284.75 │ 478.39  │ 383.34 │ 153.03 │ 159.13 │ 232.18 │ 180.63 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ 529.23 │ 358.21 │ -      │ 332.61 │ 455.60  │ 455.09 │ 237.11 │ 175.53 │ 398.69 │ 382.18 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ 417.29 │ 306.64 │ 19.60  │ -      │ 500.82  │ 91.42  │ 499.96 │ 358.18 │ 75.64  │ 137.26 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ 680.19 │ 362.30 │ 214.73 │ 381.69 │ -       │ 192.16 │ 52.89  │ 162.14 │ 520.90 │ 82.05  │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ 265.37 │ 375.64 │ 271.46 │ 226.85 │ 666.78  │ -      │ 328.20 │ 292.11 │ 614.50 │ 188.32 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ 77.90  │ 653.80 │ 155.56 │ 389.08 │ 278.21  │ 304.41 │ -      │ 331.80 │ 532.45 │ 399.47 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 716.65 │ 503.36 │ 54.70  │ 278.89 │ 1037.40 │ 252.26 │ 424.79 │ -      │ 584.19 │ 263.91 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 33.62  │ 184.10 │ 109.99 │ 158.30 │ 463.31  │ 36.11  │ 81.58  │ 170.86 │ -      │ 136.26 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ 407.84 │ 226.12 │ 246.46 │ 185.89 │ 64.70   │ 168.75 │ 429.50 │ 162.06 │ 257.47 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧═════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1519.98 │ 1498.40 │ 1518.97 │ 1515.74 │ 1318.99 │ 1111.87 │ 1321.10 │ 1516.42 │ 1355.07 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1301.11 │ -       │ 804.05  │ 850.54  │ 1340.44 │ 1068.03 │ 711.77  │ 782.01  │ 1122.71 │ 928.08  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1520.04 │ 1516.56 │ -       │ 1519.84 │ 1464.45 │ 1510.33 │ 1514.11 │ 1502.03 │ 1514.18 │ 1485.32 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1521.47 │ 1371.20 │ 1316.08 │ -       │ 1521.16 │ 1147.44 │ 1515.07 │ 1340.35 │ 1505.91 │ 1431.77 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1513.05 │ 1504.39 │ 1147.54 │ 1515.80 │ -       │ 1418.13 │ 769.74  │ 1018.72 │ 1514.55 │ 1523.12 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1460.40 │ 1270.61 │ 1248.60 │ 1510.64 │ 1515.64 │ -       │ 1514.21 │ 1355.18 │ 1520.43 │ 1513.93 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1517.62 │ 1493.71 │ 1325.20 │ 1518.93 │ 1521.11 │ 1520.09 │ -       │ 1207.61 │ 1523.22 │ 1401.52 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1513.52 │ 1519.94 │ 1063.25 │ 1510.73 │ 1514.96 │ 1175.47 │ 1207.77 │ -       │ 1287.55 │ 1368.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1353.92 │ 1495.03 │ 1125.60 │ 1276.75 │ 1410.60 │ 1513.86 │ 1088.51 │ 1006.34 │ -       │ 1420.79 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1507.89 │ 1466.83 │ 1150.69 │ 1009.82 │ 783.60  │ 1197.54 │ 1015.76 │ 878.98  │ 1357.18 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4       │ 5       │ 6       │ 7      │ 8       │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪════════╡\n",
      "│            0 │ -       │ 1145.31 │ 833.53 │ 1101.46 │ 1143.75 │ 801.87  │ 600.66  │ 747.39 │ 1149.96 │ 795.59 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            1 │ 969.11  │ -       │ 465.46 │ 492.53  │ 856.07  │ 668.23  │ 392.38  │ 349.48 │ 571.54  │ 409.80 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            2 │ 1182.46 │ 1223.04 │ -      │ 1026.61 │ 1150.97 │ 1067.42 │ 866.36  │ 822.37 │ 1089.38 │ 948.58 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            3 │ 1107.81 │ 871.90  │ 717.80 │ -       │ 1202.26 │ 594.34  │ 1165.37 │ 758.53 │ 1094.99 │ 717.36 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            4 │ 1195.14 │ 988.09  │ 667.37 │ 910.47  │ -       │ 659.98  │ 403.81  │ 515.16 │ 950.94  │ 767.92 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            5 │ 997.15  │ 786.57  │ 860.99 │ 823.53  │ 1192.00 │ -       │ 954.67  │ 833.67 │ 1158.95 │ 956.95 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            6 │ 959.33  │ 1085.32 │ 655.78 │ 904.10  │ 905.40  │ 807.43  │ -       │ 707.79 │ 1083.69 │ 827.76 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            7 │ 1237.01 │ 1118.99 │ 599.64 │ 1035.61 │ 1333.03 │ 770.40  │ 914.24  │ -      │ 1003.02 │ 788.98 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            8 │ 824.21  │ 760.82  │ 487.01 │ 487.54  │ 1017.69 │ 695.11  │ 640.09  │ 616.22 │ -       │ 595.01 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            9 │ 1139.29 │ 919.91  │ 671.35 │ 585.97  │ 433.13  │ 623.06  │ 744.29  │ 458.50 │ 829.22  │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\808634733.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_32.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_32_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b190c-d74d-469d-9c79-acc5dfa76aa7",
   "metadata": {},
   "source": [
    "### MLP1L - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e1059e-b6cc-4601-b54f-693cd768098d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\353509645.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -  68 / 1253.2 / 26.7  73 / 1097.3 / 24.9  95 / 1093.9 / 25.1  78 / 1142.4 / 25.8  96 / 1033.7 / 24.8  99 / 1012.6 / 25.1  100 / 794.3 / 24.6  30 / 1239.4 / 25.6   98 / 937.0 / 25.0\n",
      "1             94 / 1186.1 / 26.4                   -  100 / 627.2 / 23.8  100 / 476.3 / 23.5   83 / 983.1 / 25.2  100 / 675.8 / 24.2  100 / 552.1 / 24.0  100 / 373.6 / 23.5  100 / 775.2 / 24.5  100 / 431.5 / 23.6\n",
      "2             74 / 1268.2 / 25.8  67 / 1141.8 / 25.7                   -  100 / 805.0 / 24.4  80 / 1141.7 / 25.7  96 / 1050.5 / 25.0  92 / 1161.5 / 25.4  100 / 787.9 / 25.0  92 / 1138.1 / 25.3  100 / 933.2 / 25.3\n",
      "3             85 / 1210.2 / 25.9  90 / 1108.8 / 25.9  80 / 1130.5 / 25.1                   -  89 / 1172.8 / 25.8   99 / 799.4 / 24.3  63 / 1281.8 / 26.1  100 / 921.7 / 24.9  55 / 1271.6 / 25.6   98 / 899.5 / 25.0\n",
      "4             79 / 1217.1 / 25.9   90 / 938.6 / 25.6   96 / 976.2 / 24.9   93 / 991.2 / 25.2                   -   98 / 801.3 / 24.4  100 / 587.2 / 24.1  100 / 523.6 / 23.8  85 / 1106.3 / 25.2  100 / 692.4 / 24.3\n",
      "5              98 / 943.7 / 25.1  100 / 982.4 / 25.7  88 / 1072.2 / 25.3   98 / 781.9 / 24.4  89 / 1103.8 / 25.5                   -  95 / 1008.4 / 25.3   99 / 864.6 / 25.3  88 / 1087.5 / 25.1  63 / 1128.9 / 25.6\n",
      "6             72 / 1173.9 / 25.5  53 / 1276.2 / 26.1  70 / 1061.1 / 25.0   99 / 910.1 / 24.8  84 / 1161.7 / 25.5   90 / 987.8 / 24.8                   -  100 / 704.1 / 24.7  22 / 1103.8 / 25.2   99 / 862.5 / 24.9\n",
      "7             52 / 1256.2 / 25.7   96 / 976.3 / 25.6  100 / 888.9 / 24.6  80 / 1058.0 / 24.8   3 / 1251.1 / 26.0   97 / 967.8 / 24.8  56 / 1249.3 / 25.8                   -  19 / 1090.7 / 25.2  100 / 947.8 / 24.7\n",
      "8             98 / 1008.2 / 25.5   98 / 857.1 / 25.3  100 / 706.5 / 24.4  100 / 504.4 / 23.9  100 / 973.3 / 25.4   99 / 737.5 / 24.4  100 / 875.5 / 25.1  100 / 716.8 / 25.0                   -  100 / 769.7 / 24.7\n",
      "9             89 / 1195.5 / 26.3   71 / 952.9 / 26.2  78 / 1118.3 / 25.8  100 / 748.1 / 24.6  100 / 500.7 / 24.0  100 / 703.3 / 24.5  100 / 957.9 / 25.5  100 / 586.5 / 23.9  96 / 1033.5 / 25.3                   -\n",
      "\n",
      "Total successful attacks: 7854 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_64_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  68 │  73 │  95 │  78 │  96 │  99 │ 100 │  30 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  94 │   0 │ 100 │ 100 │  83 │ 100 │ 100 │ 100 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  74 │  67 │   0 │ 100 │  80 │  96 │  92 │ 100 │  92 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  85 │  90 │  80 │   0 │  89 │  99 │  63 │ 100 │  55 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  79 │  90 │  96 │  93 │   0 │  98 │ 100 │ 100 │  85 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  98 │ 100 │  88 │  98 │  89 │   0 │  95 │  99 │  88 │  63 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  72 │  53 │  70 │  99 │  84 │  90 │   0 │ 100 │  22 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  52 │  96 │ 100 │  80 │   3 │  97 │  56 │   0 │  19 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  98 │  98 │ 100 │ 100 │ 100 │  99 │ 100 │ 100 │   0 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  89 │  71 │  78 │ 100 │ 100 │ 100 │ 100 │ 100 │  96 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 25.0 │ 24.0 │ 23.0 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ 24.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 24.0 │ 23.0 │ -    │ 24.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 24.0 │ 27.0 │ 25.0 │ 25.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 25.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 25.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.7 │ 24.9 │ 25.1 │ 25.8 │ 24.8 │ 25.1 │ 24.6 │ 25.6 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.4 │ -    │ 23.8 │ 23.5 │ 25.2 │ 24.2 │ 24.0 │ 23.5 │ 24.5 │ 23.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.8 │ 25.7 │ -    │ 24.4 │ 25.7 │ 25.0 │ 25.4 │ 25.0 │ 25.3 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.9 │ 25.9 │ 25.2 │ -    │ 25.8 │ 24.3 │ 26.1 │ 24.9 │ 25.6 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.9 │ 25.6 │ 24.9 │ 25.2 │ -    │ 24.4 │ 24.1 │ 23.8 │ 25.2 │ 24.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.1 │ 25.7 │ 25.3 │ 24.4 │ 25.5 │ -    │ 25.3 │ 25.3 │ 25.1 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.5 │ 26.1 │ 25.0 │ 24.8 │ 25.5 │ 24.8 │ -    │ 24.7 │ 25.2 │ 24.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.7 │ 25.6 │ 24.6 │ 24.8 │ 26.0 │ 24.8 │ 25.8 │ -    │ 25.2 │ 24.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.5 │ 25.3 │ 24.4 │ 23.9 │ 25.4 │ 24.4 │ 25.1 │ 25.0 │ -    │ 24.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.3 │ 26.2 │ 25.8 │ 24.6 │ 24.0 │ 24.5 │ 25.5 │ 23.9 │ 25.3 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤═════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4       │ 5      │ 6      │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪═════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ 713.57 │ 444.87 │ 343.61 │ 656.14  │ 522.44 │ 450.77 │ 269.94 │ 460.41 │ 334.84 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ 851.17 │ -      │ 324.06 │ 332.36 │ 576.12  │ 365.95 │ 288.82 │ 159.23 │ 407.97 │ 212.04 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ 788.83 │ 500.84 │ -      │ 303.10 │ 552.97  │ 157.41 │ 400.32 │ 234.31 │ 614.51 │ 379.11 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ 217.66 │ 476.09 │ 274.78 │ -      │ 650.62  │ 312.97 │ 739.98 │ 287.73 │ 358.60 │ 202.81 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ 259.58 │ 199.99 │ 310.27 │ 190.84 │ -       │ 104.90 │ 174.03 │ 216.13 │ 377.60 │ 199.39 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ 422.57 │ 524.10 │ 478.60 │ 239.45 │ 428.38  │ -      │ 317.71 │ 369.82 │ 504.13 │ 543.16 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ 540.00 │ 646.40 │ 386.37 │ 363.85 │ 661.53  │ 257.04 │ -      │ 419.85 │ 515.15 │ 416.83 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 714.34 │ 366.63 │ 308.65 │ 476.66 │ 1075.23 │ 481.90 │ 757.90 │ -      │ 796.28 │ 471.01 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 407.38 │ 134.16 │ 110.04 │ 134.67 │ 589.48  │ 126.59 │ 189.76 │ 290.48 │ -      │ 219.43 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ 423.75 │ 319.09 │ 580.22 │ 357.14 │ 131.75  │ 18.60  │ 549.03 │ 236.10 │ 513.38 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧═════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1517.24 │ 1515.36 │ 1522.64 │ 1517.19 │ 1513.76 │ 1515.25 │ 1486.27 │ 1521.55 │ 1460.48 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1458.61 │ -       │ 1005.79 │ 749.21  │ 1418.25 │ 1069.09 │ 897.37  │ 743.82  │ 1394.08 │ 768.96  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1515.99 │ 1515.71 │ -       │ 1310.39 │ 1514.23 │ 1499.15 │ 1522.32 │ 1418.31 │ 1518.32 │ 1472.57 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1518.62 │ 1514.06 │ 1521.49 │ -       │ 1518.62 │ 1313.87 │ 1523.71 │ 1507.39 │ 1523.39 │ 1517.28 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1504.30 │ 1508.34 │ 1512.39 │ 1523.00 │ -       │ 1337.80 │ 1043.72 │ 1120.49 │ 1519.72 │ 1313.92 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1483.98 │ 1434.07 │ 1516.76 │ 1499.41 │ 1468.78 │ -       │ 1517.79 │ 1413.91 │ 1495.25 │ 1518.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1521.28 │ 1521.84 │ 1518.32 │ 1523.89 │ 1516.27 │ 1519.62 │ -       │ 989.50  │ 1514.19 │ 1400.72 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1509.29 │ 1518.57 │ 1504.01 │ 1515.37 │ 1425.03 │ 1349.74 │ 1521.44 │ -       │ 1378.63 │ 1466.72 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1519.89 │ 1496.63 │ 1371.06 │ 1307.21 │ 1477.84 │ 1324.76 │ 1371.10 │ 1171.25 │ -       │ 1382.22 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1508.64 │ 1457.21 │ 1524.20 │ 1506.57 │ 1013.65 │ 1312.21 │ 1455.82 │ 1096.65 │ 1479.39 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7      │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1253.20 │ 1097.27 │ 1093.87 │ 1142.39 │ 1033.66 │ 1012.56 │ 794.30 │ 1239.45 │ 937.01  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            1 │ 1186.13 │ -       │ 627.16  │ 476.32  │ 983.06  │ 675.77  │ 552.15  │ 373.64 │ 775.16  │ 431.55  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            2 │ 1268.22 │ 1141.85 │ -       │ 805.00  │ 1141.73 │ 1050.46 │ 1161.51 │ 787.86 │ 1138.11 │ 933.23  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            3 │ 1210.22 │ 1108.81 │ 1130.50 │ -       │ 1172.81 │ 799.41  │ 1281.81 │ 921.68 │ 1271.59 │ 899.53  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            4 │ 1217.10 │ 938.63  │ 976.21  │ 991.24  │ -       │ 801.31  │ 587.20  │ 523.58 │ 1106.32 │ 692.37  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            5 │ 943.73  │ 982.36  │ 1072.16 │ 781.90  │ 1103.80 │ -       │ 1008.43 │ 864.60 │ 1087.51 │ 1128.89 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            6 │ 1173.89 │ 1276.17 │ 1061.07 │ 910.08  │ 1161.71 │ 987.82  │ -       │ 704.08 │ 1103.78 │ 862.53  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            7 │ 1256.16 │ 976.26  │ 888.94  │ 1057.98 │ 1251.09 │ 967.80  │ 1249.33 │ -      │ 1090.72 │ 947.82  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            8 │ 1008.21 │ 857.15  │ 706.53  │ 504.36  │ 973.34  │ 737.49  │ 875.46  │ 716.78 │ -       │ 769.68  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            9 │ 1195.46 │ 952.94  │ 1118.32 │ 748.06  │ 500.71  │ 703.29  │ 957.92  │ 586.50 │ 1033.46 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\353509645.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_64.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_64_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308bc4ae-9df1-432f-821c-3b903284529c",
   "metadata": {},
   "source": [
    "### MLP1L - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91b881df-76b0-44c9-9ac5-10fd89abd45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1533072694.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                    9\n",
      "true_label                                                                                                                                                                                                           \n",
      "0                              -  40 / 1335.2 / 26.8  99 / 1020.4 / 24.8  11 / 1228.5 / 25.4  43 / 1295.4 / 26.3  75 / 1185.6 / 25.2  96 / 1036.1 / 25.2  91 / 1177.7 / 25.4  14 / 1230.3 / 25.6   97 / 1075.1 / 25.3\n",
      "1             93 / 1246.8 / 26.5                   -  100 / 569.4 / 23.9  100 / 601.4 / 23.9   56 / 957.9 / 25.2  82 / 1042.1 / 25.2  100 / 597.7 / 24.1  100 / 461.2 / 23.7   95 / 879.8 / 24.7   100 / 612.5 / 24.2\n",
      "2             66 / 1276.8 / 25.8  14 / 1282.5 / 26.0                   -  59 / 1199.2 / 25.1  10 / 1324.1 / 26.0  24 / 1280.2 / 25.5  79 / 1218.3 / 25.5   99 / 940.1 / 25.3  31 / 1291.4 / 25.7   94 / 1108.4 / 25.7\n",
      "3             95 / 1159.9 / 25.7  99 / 1068.2 / 25.8  100 / 922.3 / 24.7                   -  61 / 1235.0 / 25.8   99 / 793.5 / 24.3  48 / 1323.4 / 26.1  95 / 1098.8 / 25.3  55 / 1202.2 / 25.3    98 / 950.1 / 25.1\n",
      "4             52 / 1252.7 / 26.0  66 / 1039.9 / 25.9   94 / 833.9 / 24.5  49 / 1160.4 / 25.6                   -   93 / 992.9 / 24.9  100 / 700.0 / 24.3  100 / 591.0 / 24.0  76 / 1204.2 / 25.4    99 / 830.9 / 24.5\n",
      "5              98 / 971.1 / 25.2  90 / 1072.6 / 25.9  96 / 1004.4 / 25.1  86 / 1065.9 / 25.0  66 / 1244.0 / 25.8                   -  83 / 1076.1 / 25.4  86 / 1127.6 / 25.7  69 / 1170.5 / 25.4   42 / 1305.5 / 26.0\n",
      "6             68 / 1167.8 / 25.5  29 / 1287.6 / 26.3   97 / 881.2 / 24.5  76 / 1134.4 / 25.2  46 / 1202.0 / 25.6  82 / 1139.9 / 25.2                   -  100 / 893.2 / 25.1  10 / 1213.1 / 25.2   99 / 1083.0 / 25.3\n",
      "7             68 / 1232.3 / 25.7  56 / 1242.5 / 26.1  91 / 1036.6 / 24.8  23 / 1269.3 / 25.3                   -  97 / 1012.5 / 24.9  52 / 1284.4 / 26.0                   -   7 / 1332.1 / 25.7  100 / 1000.4 / 24.9\n",
      "8             91 / 1125.4 / 25.8  74 / 1081.0 / 25.8  100 / 664.0 / 24.2   98 / 684.2 / 24.3  81 / 1159.5 / 25.8  85 / 1011.1 / 25.0  100 / 918.3 / 25.2  100 / 802.3 / 25.1                   -    97 / 954.2 / 25.1\n",
      "9             87 / 1190.5 / 26.3  63 / 1058.1 / 26.2   99 / 823.3 / 24.9   94 / 873.4 / 24.9  100 / 640.8 / 24.3   98 / 796.1 / 24.7  100 / 859.9 / 25.3  100 / 687.2 / 24.2  100 / 936.9 / 25.0                    -\n",
      "\n",
      "Total successful attacks: 6831 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_128_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  40 │  99 │  11 │  43 │  75 │  96 │  91 │  14 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  93 │   0 │ 100 │ 100 │  56 │  82 │ 100 │ 100 │  95 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  66 │  14 │   0 │  59 │  10 │  24 │  79 │  99 │  31 │  94 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  95 │  99 │ 100 │   0 │  61 │  99 │  48 │  95 │  55 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  52 │  66 │  94 │  49 │   0 │  93 │ 100 │ 100 │  76 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  98 │  90 │  96 │  86 │  66 │   0 │  83 │  86 │  69 │  42 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  68 │  29 │  97 │  76 │  46 │  82 │   0 │ 100 │  10 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  68 │  56 │  91 │  23 │   0 │  97 │  52 │   0 │   7 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  91 │  74 │ 100 │  98 │  81 │  85 │ 100 │ 100 │   0 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  87 │  63 │  99 │  94 │ 100 │  98 │ 100 │ 100 │ 100 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 24.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 25.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 24.0 │ 23.0 │ -    │ 25.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 24.0 │ 23.0 │ 25.0 │ -    │ 23.0 │ 25.0 │ -    │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.8 │ 24.8 │ 25.4 │ 26.3 │ 25.2 │ 25.2 │ 25.4 │ 25.6 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.5 │ -    │ 23.9 │ 24.0 │ 25.2 │ 25.2 │ 24.1 │ 23.7 │ 24.7 │ 24.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.8 │ 26.0 │ -    │ 25.1 │ 26.0 │ 25.5 │ 25.5 │ 25.3 │ 25.7 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.7 │ 25.8 │ 24.7 │ -    │ 25.8 │ 24.3 │ 26.1 │ 25.3 │ 25.3 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ 25.9 │ 24.5 │ 25.6 │ -    │ 24.9 │ 24.3 │ 24.0 │ 25.4 │ 24.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.2 │ 25.9 │ 25.1 │ 25.0 │ 25.8 │ -    │ 25.4 │ 25.7 │ 25.4 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.5 │ 26.3 │ 24.5 │ 25.2 │ 25.6 │ 25.2 │ -    │ 25.0 │ 25.2 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.7 │ 26.1 │ 24.8 │ 25.3 │ -    │ 24.9 │ 26.0 │ -    │ 25.7 │ 24.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.8 │ 25.8 │ 24.2 │ 24.3 │ 25.8 │ 25.0 │ 25.2 │ 25.2 │ -    │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.3 │ 26.2 │ 24.9 │ 24.9 │ 24.3 │ 24.7 │ 25.3 │ 24.2 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤═════════╤════════╤════════╤═════════╤════════╤════════╤════════╤═════════╤════════╕\n",
      "│   true_label │ 0      │ 1       │ 2      │ 3      │ 4       │ 5      │ 6      │ 7      │ 8       │ 9      │\n",
      "╞══════════════╪════════╪═════════╪════════╪════════╪═════════╪════════╪════════╪════════╪═════════╪════════╡\n",
      "│            0 │ -      │ 1142.65 │ 352.47 │ 881.36 │ 921.57  │ 444.47 │ 262.97 │ 637.15 │ 782.97  │ 447.77 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            1 │ 882.06 │ -       │ 328.54 │ 384.84 │ 582.28  │ 453.79 │ 253.05 │ 194.47 │ 430.10  │ 377.44 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            2 │ 873.08 │ 853.40  │ -      │ 581.50 │ 1104.38 │ 916.74 │ 560.09 │ 252.72 │ 864.03  │ 641.39 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            3 │ 433.79 │ 467.78  │ 438.81 │ -      │ 815.87  │ 255.22 │ 906.09 │ 426.78 │ 476.13  │ 350.19 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            4 │ 858.39 │ 246.08  │ 275.66 │ 551.89 │ -       │ 261.88 │ 287.43 │ 252.14 │ 620.16  │ 177.83 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            5 │ 593.23 │ 602.44  │ 483.86 │ 444.92 │ 728.16  │ -      │ 409.24 │ 634.87 │ 443.02  │ 945.48 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            6 │ 202.08 │ 664.89  │ 294.33 │ 544.66 │ 631.54  │ 325.72 │ -      │ 480.59 │ 826.99  │ 650.32 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            7 │ 657.13 │ 788.96  │ 399.32 │ 902.23 │ -       │ 450.21 │ 814.37 │ -      │ 1176.97 │ 543.96 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            8 │ 260.93 │ 330.38  │ 290.83 │ 120.74 │ 637.35  │ 247.43 │ 258.40 │ 457.42 │ -       │ 238.99 │\n",
      "├──────────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            9 │ 452.00 │ 387.03  │ 368.70 │ 403.78 │ 258.87  │ 105.80 │ 522.30 │ 336.73 │ 242.01  │ -      │\n",
      "╘══════════════╧════════╧═════════╧════════╧════════╧═════════╧════════╧════════╧════════╧═════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1515.64 │ 1514.55 │ 1516.74 │ 1518.25 │ 1526.37 │ 1520.59 │ 1522.33 │ 1499.24 │ 1517.01 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1518.16 │ -       │ 1126.35 │ 1186.93 │ 1456.31 │ 1520.63 │ 1274.65 │ 752.72  │ 1481.05 │ 910.46  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1518.70 │ 1521.10 │ -       │ 1521.83 │ 1507.31 │ 1517.57 │ 1525.82 │ 1498.45 │ 1520.66 │ 1495.05 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1512.63 │ 1511.46 │ 1490.64 │ -       │ 1514.64 │ 1408.08 │ 1523.71 │ 1498.34 │ 1520.80 │ 1387.01 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1520.49 │ 1519.25 │ 1470.00 │ 1522.84 │ -       │ 1519.29 │ 1177.69 │ 1120.28 │ 1515.93 │ 1378.25 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1512.07 │ 1515.26 │ 1486.17 │ 1522.98 │ 1519.59 │ -       │ 1521.72 │ 1514.86 │ 1520.09 │ 1519.00 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1517.58 │ 1518.39 │ 1521.31 │ 1514.70 │ 1518.34 │ 1516.33 │ -       │ 1347.98 │ 1461.60 │ 1497.76 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1518.63 │ 1517.10 │ 1521.58 │ 1516.57 │ -       │ 1511.18 │ 1503.01 │ -       │ 1471.93 │ 1510.97 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1519.15 │ 1501.80 │ 1506.63 │ 1442.16 │ 1494.19 │ 1505.10 │ 1456.85 │ 1255.20 │ -       │ 1417.14 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1491.39 │ 1472.96 │ 1273.92 │ 1516.84 │ 1158.38 │ 1495.84 │ 1168.08 │ 1389.60 │ 1514.25 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1335.18 │ 1020.39 │ 1228.47 │ 1295.44 │ 1185.64 │ 1036.09 │ 1177.70 │ 1230.30 │ 1075.07 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1246.83 │ -       │ 569.45  │ 601.44  │ 957.88  │ 1042.13 │ 597.69  │ 461.23  │ 879.83  │ 612.55  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1276.77 │ 1282.47 │ -       │ 1199.21 │ 1324.09 │ 1280.17 │ 1218.26 │ 940.05  │ 1291.43 │ 1108.42 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1159.95 │ 1068.20 │ 922.27  │ -       │ 1235.04 │ 793.50  │ 1323.44 │ 1098.78 │ 1202.23 │ 950.10  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1252.75 │ 1039.95 │ 833.87  │ 1160.36 │ -       │ 992.90  │ 700.02  │ 590.95  │ 1204.19 │ 830.92  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 971.08  │ 1072.64 │ 1004.37 │ 1065.86 │ 1244.02 │ -       │ 1076.08 │ 1127.63 │ 1170.51 │ 1305.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1167.84 │ 1287.62 │ 881.16  │ 1134.43 │ 1201.98 │ 1139.92 │ -       │ 893.16  │ 1213.11 │ 1083.05 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1232.30 │ 1242.53 │ 1036.61 │ 1269.29 │ -       │ 1012.47 │ 1284.38 │ -       │ 1332.13 │ 1000.38 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1125.42 │ 1081.02 │ 664.03  │ 684.21  │ 1159.48 │ 1011.08 │ 918.26  │ 802.29  │ -       │ 954.19  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1190.49 │ 1058.08 │ 823.27  │ 873.39  │ 640.84  │ 796.09  │ 859.94  │ 687.21  │ 936.94  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1533072694.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_128.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_128_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7424cc-effb-4fab-9a89-87c590606b12",
   "metadata": {},
   "source": [
    "### MLP1L - 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08c56fe2-5db3-4bb2-b4b5-66be7a0b447e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1233242682.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -   2 / 1185.0 / 26.5   68 / 966.8 / 24.8  13 / 1173.8 / 25.4  25 / 1228.6 / 26.1  54 / 1186.8 / 25.3  80 / 1065.0 / 25.2  90 / 1117.2 / 25.3   2 / 1311.1 / 26.0  77 / 1182.4 / 25.5\n",
      "1             99 / 1158.3 / 26.2                   -  100 / 569.5 / 23.9  100 / 890.2 / 24.5  13 / 1187.2 / 25.8  100 / 870.8 / 24.5  100 / 819.8 / 24.6  100 / 577.3 / 24.0  35 / 1138.6 / 25.5  100 / 632.5 / 24.2\n",
      "2             36 / 1390.8 / 26.1    1 / 500.8 / 24.0                   -  49 / 1203.6 / 25.2                   -  61 / 1185.5 / 25.3  57 / 1326.7 / 25.7  83 / 1157.6 / 25.7  39 / 1297.5 / 25.7  86 / 1221.4 / 25.9\n",
      "3             52 / 1293.3 / 26.1  42 / 1281.9 / 26.1  91 / 1086.8 / 25.0                   -  19 / 1348.0 / 25.9  100 / 868.1 / 24.5  42 / 1340.2 / 26.2  78 / 1208.2 / 25.5  73 / 1262.7 / 25.6  89 / 1131.7 / 25.5\n",
      "4             32 / 1323.6 / 26.1  52 / 1182.1 / 26.2   97 / 845.3 / 24.5  41 / 1103.6 / 25.4                   -  74 / 1094.8 / 25.1  100 / 836.5 / 24.5  100 / 659.9 / 24.1  27 / 1198.0 / 25.5  94 / 1037.2 / 25.3\n",
      "5             97 / 1148.3 / 25.6  29 / 1371.9 / 26.6  82 / 1115.3 / 25.3  66 / 1098.0 / 25.0  46 / 1290.1 / 25.8                   -  82 / 1108.9 / 25.4  57 / 1209.2 / 25.8  52 / 1214.0 / 25.5  17 / 1201.2 / 25.9\n",
      "6             68 / 1162.2 / 25.5  12 / 1355.9 / 26.2   92 / 967.2 / 24.7  60 / 1166.1 / 25.1  26 / 1204.4 / 25.5  87 / 1141.5 / 25.2                   -  99 / 1060.0 / 25.4  25 / 1273.7 / 25.6  93 / 1159.6 / 25.5\n",
      "7             33 / 1354.5 / 26.1  11 / 1348.9 / 26.2  77 / 1148.2 / 25.1  29 / 1205.3 / 25.1                   -  93 / 1092.0 / 25.0  25 / 1315.5 / 26.0                   -                   -  84 / 1191.5 / 25.3\n",
      "8             83 / 1159.3 / 25.9  20 / 1029.7 / 25.6   99 / 721.2 / 24.3   96 / 841.2 / 24.6  31 / 1313.4 / 26.1  86 / 1022.3 / 25.0  93 / 1082.3 / 25.5  100 / 984.0 / 25.4                   -  70 / 1170.1 / 25.7\n",
      "9             66 / 1272.5 / 26.4  32 / 1127.6 / 26.3  100 / 856.9 / 25.0   93 / 838.4 / 24.8   99 / 639.8 / 24.2   98 / 770.7 / 24.6  100 / 974.3 / 25.4  100 / 697.8 / 24.3  90 / 1032.3 / 25.3                   -\n",
      "\n",
      "Total successful attacks: 5671 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_256_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   2 │  68 │  13 │  25 │  54 │  80 │  90 │   2 │  77 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  99 │   0 │ 100 │ 100 │  13 │ 100 │ 100 │ 100 │  35 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  36 │   1 │   0 │  49 │   0 │  61 │  57 │  83 │  39 │  86 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  52 │  42 │  91 │   0 │  19 │ 100 │  42 │  78 │  73 │  89 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  32 │  52 │  97 │  41 │   0 │  74 │ 100 │ 100 │  27 │  94 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  97 │  29 │  82 │  66 │  46 │   0 │  82 │  57 │  52 │  17 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  68 │  12 │  92 │  60 │  26 │  87 │   0 │  99 │  25 │  93 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  33 │  11 │  77 │  29 │   0 │  93 │  25 │   0 │   0 │  84 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  83 │  20 │  99 │  96 │  31 │  86 │  93 │ 100 │   0 │  70 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  66 │  32 │ 100 │  93 │  99 │  98 │ 100 │ 100 │  90 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 26.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 24.0 │ -    │ 24.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.0 │ 24.0 │ 24.0 │ -    │ 25.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ -    │ 24.0 │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ -    │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 24.0 │ 26.0 │ 27.0 │ 26.0 │ 25.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 24.0 │ -    │ 26.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ -    │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.5 │ 24.8 │ 25.4 │ 26.1 │ 25.3 │ 25.2 │ 25.3 │ 26.0 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.2 │ -    │ 23.9 │ 24.5 │ 25.8 │ 24.5 │ 24.6 │ 24.0 │ 25.5 │ 24.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.1 │ 24.0 │ -    │ 25.2 │ -    │ 25.3 │ 25.7 │ 25.7 │ 25.7 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.1 │ 26.1 │ 25.0 │ -    │ 25.9 │ 24.5 │ 26.2 │ 25.5 │ 25.6 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.1 │ 26.2 │ 24.5 │ 25.4 │ -    │ 25.1 │ 24.5 │ 24.2 │ 25.5 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.6 │ 26.6 │ 25.3 │ 25.0 │ 25.8 │ -    │ 25.4 │ 25.8 │ 25.5 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.5 │ 26.2 │ 24.7 │ 25.1 │ 25.5 │ 25.2 │ -    │ 25.4 │ 25.6 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.1 │ 26.2 │ 25.1 │ 25.1 │ -    │ 25.0 │ 26.0 │ -    │ -    │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.9 │ 25.6 │ 24.3 │ 24.6 │ 26.1 │ 25.0 │ 25.5 │ 25.4 │ -    │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.4 │ 26.3 │ 25.0 │ 24.8 │ 24.2 │ 24.6 │ 25.4 │ 24.3 │ 25.3 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤════════╤═════════╤════════╤════════╤════════╤═════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3      │ 4       │ 5      │ 6      │ 7      │ 8       │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪════════╪═════════╪════════╪════════╪════════╪═════════╪════════╡\n",
      "│            0 │ -       │ 851.19  │ 403.21 │ 691.45 │ 806.52  │ 525.91 │ 315.19 │ 495.27 │ 1282.54 │ 121.07 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            1 │ 782.89  │ -       │ 242.08 │ 551.10 │ 754.23  │ 575.08 │ 375.20 │ 314.40 │ 628.14  │ 371.95 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            2 │ 1130.49 │ 500.75  │ -      │ 806.11 │ -       │ 809.02 │ 883.52 │ 604.60 │ 860.59  │ 675.45 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            3 │ 935.64  │ 745.77  │ 419.55 │ -      │ 1063.84 │ 232.04 │ 938.40 │ 494.37 │ 564.91  │ 420.02 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            4 │ 980.98  │ 230.71  │ 247.61 │ 468.00 │ -       │ 384.02 │ 274.25 │ 181.38 │ 608.90  │ 132.66 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            5 │ 742.65  │ 1033.91 │ 651.52 │ 391.34 │ 812.89  │ -      │ 311.47 │ 752.54 │ 749.06  │ 88.36  │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            6 │ 565.40  │ 1068.49 │ 350.37 │ 674.32 │ 685.23  │ 476.64 │ -      │ 576.67 │ 839.43  │ 753.16 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            7 │ 738.11  │ 1157.41 │ 381.13 │ 835.77 │ -       │ 533.09 │ 744.45 │ -      │ -       │ 599.03 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            8 │ 163.43  │ 387.67  │ 219.76 │ 247.34 │ 586.27  │ 487.29 │ 325.57 │ 538.31 │ -       │ 421.92 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┼─────────┼────────┤\n",
      "│            9 │ 574.33  │ 650.34  │ 429.86 │ 372.91 │ 81.41   │ 141.04 │ 449.18 │ 268.46 │ 526.79  │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧════════╧═════════╧════════╧════════╧════════╧═════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1518.72 │ 1522.99 │ 1525.97 │ 1521.99 │ 1521.92 │ 1522.55 │ 1515.97 │ 1339.75 │ 1519.17 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1480.56 │ -       │ 734.31  │ 1230.37 │ 1512.16 │ 1364.71 │ 1134.31 │ 959.58  │ 1477.82 │ 985.95  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1522.24 │ 500.75  │ -       │ 1522.17 │ -       │ 1522.46 │ 1521.91 │ 1521.20 │ 1516.58 │ 1483.01 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1516.14 │ 1521.85 │ 1526.46 │ -       │ 1519.48 │ 1479.72 │ 1522.18 │ 1514.55 │ 1522.89 │ 1512.64 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1518.03 │ 1519.84 │ 1516.21 │ 1523.17 │ -       │ 1520.29 │ 1404.61 │ 1385.92 │ 1506.80 │ 1483.45 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1491.91 │ 1516.82 │ 1524.73 │ 1522.98 │ 1518.06 │ -       │ 1519.73 │ 1520.35 │ 1515.06 │ 1465.40 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1523.44 │ 1511.96 │ 1514.91 │ 1525.32 │ 1523.26 │ 1522.73 │ -       │ 1516.90 │ 1513.26 │ 1441.59 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1519.39 │ 1510.41 │ 1522.34 │ 1508.82 │ -       │ 1488.69 │ 1506.68 │ -       │ -       │ 1522.40 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1523.19 │ 1494.81 │ 1420.52 │ 1513.41 │ 1520.49 │ 1515.91 │ 1522.70 │ 1364.68 │ -       │ 1518.81 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1516.89 │ 1466.74 │ 1496.26 │ 1496.28 │ 1310.40 │ 1371.86 │ 1512.21 │ 1279.98 │ 1516.34 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1184.96 │ 966.79  │ 1173.82 │ 1228.57 │ 1186.76 │ 1064.98 │ 1117.19 │ 1311.14 │ 1182.41 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1158.26 │ -       │ 569.50  │ 890.15  │ 1187.17 │ 870.76  │ 819.83  │ 577.31  │ 1138.55 │ 632.47  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1390.83 │ 500.75  │ -       │ 1203.60 │ -       │ 1185.46 │ 1326.67 │ 1157.59 │ 1297.51 │ 1221.37 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1293.35 │ 1281.87 │ 1086.79 │ -       │ 1347.99 │ 868.10  │ 1340.19 │ 1208.22 │ 1262.68 │ 1131.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1323.64 │ 1182.15 │ 845.33  │ 1103.55 │ -       │ 1094.78 │ 836.52  │ 659.86  │ 1198.02 │ 1037.22 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1148.31 │ 1371.92 │ 1115.29 │ 1097.98 │ 1290.06 │ -       │ 1108.88 │ 1209.18 │ 1214.04 │ 1201.16 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1162.25 │ 1355.94 │ 967.22  │ 1166.10 │ 1204.43 │ 1141.49 │ -       │ 1059.95 │ 1273.70 │ 1159.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1354.51 │ 1348.88 │ 1148.18 │ 1205.30 │ -       │ 1091.98 │ 1315.50 │ -       │ -       │ 1191.46 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1159.27 │ 1029.73 │ 721.23  │ 841.24  │ 1313.39 │ 1022.30 │ 1082.35 │ 983.97  │ -       │ 1170.12 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1272.52 │ 1127.55 │ 856.94  │ 838.37  │ 639.82  │ 770.71  │ 974.30  │ 697.80  │ 1032.28 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1233242682.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_256.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_256_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0404-6999-4376-8e0b-64bb6fe768a7",
   "metadata": {},
   "source": [
    "## -----  MLP2L -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcac6be-1c75-462c-ac56-f5f92a30ae95",
   "metadata": {},
   "source": [
    "### MLP2L - 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a3c842a-684b-4ce9-9050-fe947858f37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1320014381.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                    3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                           \n",
      "0                              -   3 / 1344.2 / 26.3  68 / 1054.6 / 24.9    7 / 1207.0 / 25.3  30 / 1268.0 / 26.3  28 / 1142.8 / 25.1   77 / 995.3 / 25.1  87 / 1162.0 / 25.4  38 / 1000.8 / 25.0  45 / 1167.3 / 25.4\n",
      "1             24 / 1370.7 / 26.8                   -  100 / 784.5 / 24.2  100 / 1039.5 / 25.0   99 / 839.0 / 24.9   77 / 724.7 / 24.2  100 / 937.2 / 24.9  100 / 556.8 / 23.9  100 / 599.7 / 24.0  100 / 790.8 / 24.5\n",
      "2             14 / 1415.2 / 26.1    1 / 344.6 / 24.0                   -   31 / 1240.1 / 25.4  24 / 1281.4 / 26.0  49 / 1223.8 / 25.3  65 / 1252.9 / 25.6  65 / 1201.0 / 25.8  84 / 1179.6 / 25.4  84 / 1188.0 / 25.8\n",
      "3             22 / 1294.1 / 26.0  73 / 1207.6 / 26.1   96 / 981.1 / 24.8                    -  25 / 1299.4 / 26.0  79 / 1127.0 / 25.2  11 / 1350.2 / 26.0  88 / 1218.5 / 25.5   97 / 934.2 / 24.8  91 / 1139.6 / 25.6\n",
      "4             10 / 1382.6 / 26.1  47 / 1344.5 / 26.6  66 / 1091.0 / 25.2   16 / 1395.6 / 26.3                   -  66 / 1197.8 / 25.4   95 / 893.9 / 24.7  100 / 916.3 / 24.7  84 / 1150.8 / 25.3  95 / 1125.3 / 25.5\n",
      "5             93 / 1176.6 / 25.6  44 / 1280.4 / 26.4  56 / 1208.8 / 25.4   72 / 1152.3 / 25.2  53 / 1239.5 / 25.7                   -  53 / 1120.4 / 25.5  78 / 1129.5 / 25.7  87 / 1129.0 / 25.3  32 / 1168.0 / 25.8\n",
      "6             29 / 1220.7 / 25.6  31 / 1331.6 / 26.1  62 / 1061.4 / 25.0   32 / 1265.0 / 25.4  16 / 1224.4 / 25.6  80 / 1095.1 / 25.0                   -  82 / 1130.5 / 25.5  68 / 1061.0 / 25.0  71 / 1132.1 / 25.5\n",
      "7             18 / 1356.8 / 25.9  54 / 1258.0 / 26.2  76 / 1056.6 / 24.8    4 / 1326.8 / 25.2   9 / 1119.7 / 25.6  68 / 1167.7 / 25.5  67 / 1287.2 / 25.9                   -  37 / 1283.5 / 25.7  80 / 1075.4 / 25.0\n",
      "8             29 / 1349.3 / 26.3   7 / 1275.9 / 26.3  76 / 1090.7 / 25.1   23 / 1262.9 / 25.6  76 / 1159.2 / 25.8  16 / 1194.6 / 25.2  11 / 1191.2 / 25.6  96 / 1115.3 / 25.8                   -  54 / 1264.6 / 25.9\n",
      "9             31 / 1325.0 / 26.5   10 / 963.8 / 25.5  61 / 1103.1 / 25.7   83 / 1023.2 / 25.2  100 / 539.5 / 24.1  90 / 1007.7 / 25.1  33 / 1284.7 / 26.1  100 / 768.3 / 24.4  100 / 993.0 / 25.1                   -\n",
      "\n",
      "Total successful attacks: 5209 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_32_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   3 │  68 │   7 │  30 │  28 │  77 │  87 │  38 │  45 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  24 │   0 │ 100 │ 100 │  99 │  77 │ 100 │ 100 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  14 │   1 │   0 │  31 │  24 │  49 │  65 │  65 │  84 │  84 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  22 │  73 │  96 │   0 │  25 │  79 │  11 │  88 │  97 │  91 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  10 │  47 │  66 │  16 │   0 │  66 │  95 │ 100 │  84 │  95 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  93 │  44 │  56 │  72 │  53 │   0 │  53 │  78 │  87 │  32 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  29 │  31 │  62 │  32 │  16 │  80 │   0 │  82 │  68 │  71 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  18 │  54 │  76 │   4 │   9 │  68 │  67 │   0 │  37 │  80 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  29 │   7 │  76 │  23 │  76 │  16 │  11 │  96 │   0 │  54 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  31 │  10 │  61 │  83 │ 100 │  90 │  33 │ 100 │ 100 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 23.0 │ -    │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ -    │ 24.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 25.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 24.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.3 │ 24.9 │ 25.3 │ 26.3 │ 25.1 │ 25.1 │ 25.4 │ 25.0 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.8 │ -    │ 24.2 │ 25.0 │ 24.9 │ 24.2 │ 24.9 │ 23.9 │ 24.0 │ 24.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.1 │ 24.0 │ -    │ 25.4 │ 26.0 │ 25.3 │ 25.6 │ 25.8 │ 25.4 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 26.1 │ 24.8 │ -    │ 26.0 │ 25.2 │ 26.0 │ 25.5 │ 24.8 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.1 │ 26.6 │ 25.2 │ 26.3 │ -    │ 25.4 │ 24.7 │ 24.7 │ 25.3 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.6 │ 26.4 │ 25.4 │ 25.2 │ 25.7 │ -    │ 25.5 │ 25.7 │ 25.3 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.6 │ 26.1 │ 25.0 │ 25.4 │ 25.6 │ 25.0 │ -    │ 25.5 │ 25.0 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.9 │ 26.2 │ 24.8 │ 25.2 │ 25.6 │ 25.5 │ 25.9 │ -    │ 25.7 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.3 │ 26.3 │ 25.1 │ 25.6 │ 25.8 │ 25.2 │ 25.6 │ 25.8 │ -    │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.5 │ 25.5 │ 25.7 │ 25.2 │ 24.1 │ 25.1 │ 26.1 │ 24.4 │ 25.1 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤════════╤════════╤═════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4      │ 5      │ 6       │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪════════╪════════╪═════════╪════════╪════════╪════════╡\n",
      "│            0 │ -       │ 1154.84 │ 338.57 │ 778.79  │ 761.92 │ 525.68 │ 245.13  │ 432.45 │ 137.21 │ 379.10 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            1 │ 1221.25 │ -       │ 345.83 │ 511.37  │ 480.20 │ 314.64 │ 407.68  │ 281.66 │ 198.74 │ 423.71 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            2 │ 1162.95 │ 344.61  │ -      │ 668.42  │ 955.16 │ 834.54 │ 740.66  │ 661.00 │ 438.19 │ 706.75 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            3 │ 683.59  │ 629.70  │ 91.95  │ -       │ 908.98 │ 519.92 │ 1136.97 │ 657.69 │ 248.39 │ 570.50 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            4 │ 1185.31 │ 904.63  │ 336.09 │ 1186.90 │ -      │ 700.07 │ 405.68  │ 404.96 │ 654.36 │ 431.16 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            5 │ 551.14  │ 955.78  │ 731.52 │ 539.53  │ 521.95 │ -      │ 506.65  │ 580.82 │ 625.33 │ 661.32 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            6 │ 681.88  │ 646.14  │ 424.63 │ 853.53  │ 199.57 │ 253.61 │ -       │ 649.04 │ 227.31 │ 651.08 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            7 │ 1072.13 │ 829.53  │ 364.53 │ 1208.25 │ 413.81 │ 623.44 │ 673.51  │ -      │ 734.18 │ 477.97 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            8 │ 792.37  │ 627.81  │ 453.31 │ 672.69  │ 646.63 │ 883.03 │ 541.76  │ 638.10 │ -      │ 685.82 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼─────────┼────────┼────────┼────────┤\n",
      "│            9 │ 871.80  │ 592.56  │ 619.88 │ 484.88  │ 81.41  │ 176.25 │ 696.41  │ 179.17 │ 457.21 │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧════════╧════════╧═════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1513.81 │ 1524.51 │ 1519.25 │ 1515.96 │ 1516.32 │ 1518.53 │ 1515.68 │ 1523.05 │ 1517.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1515.15 │ -       │ 1195.60 │ 1425.63 │ 1433.53 │ 1472.65 │ 1385.81 │ 953.22  │ 874.49  │ 1347.76 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1518.22 │ 344.61  │ -       │ 1513.65 │ 1513.71 │ 1519.86 │ 1517.77 │ 1520.29 │ 1513.89 │ 1520.26 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1521.33 │ 1492.84 │ 1515.08 │ -       │ 1502.25 │ 1523.32 │ 1494.04 │ 1522.53 │ 1515.43 │ 1521.86 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1517.60 │ 1500.57 │ 1483.08 │ 1520.18 │ -       │ 1521.08 │ 1487.55 │ 1447.11 │ 1519.53 │ 1515.50 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1522.37 │ 1505.56 │ 1507.01 │ 1518.82 │ 1517.66 │ -       │ 1516.48 │ 1518.02 │ 1513.36 │ 1512.03 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1518.53 │ 1518.79 │ 1516.21 │ 1515.93 │ 1511.88 │ 1466.99 │ -       │ 1514.27 │ 1514.57 │ 1487.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1504.26 │ 1517.59 │ 1521.67 │ 1519.20 │ 1460.33 │ 1522.22 │ 1524.51 │ -       │ 1521.87 │ 1483.16 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1503.02 │ 1505.59 │ 1518.74 │ 1462.40 │ 1520.04 │ 1507.96 │ 1496.58 │ 1521.83 │ -       │ 1518.92 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1509.50 │ 1431.46 │ 1513.87 │ 1519.96 │ 1135.71 │ 1509.14 │ 1521.32 │ 1452.64 │ 1470.15 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1344.15 │ 1054.62 │ 1207.04 │ 1267.97 │ 1142.78 │ 995.25  │ 1162.03 │ 1000.76 │ 1167.32 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1370.66 │ -       │ 784.52  │ 1039.45 │ 839.03  │ 724.71  │ 937.20  │ 556.84  │ 599.72  │ 790.79  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1415.24 │ 344.61  │ -       │ 1240.11 │ 1281.37 │ 1223.81 │ 1252.93 │ 1201.01 │ 1179.60 │ 1188.00 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1294.14 │ 1207.61 │ 981.06  │ -       │ 1299.37 │ 1126.98 │ 1350.17 │ 1218.50 │ 934.23  │ 1139.64 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1382.60 │ 1344.50 │ 1091.05 │ 1395.58 │ -       │ 1197.80 │ 893.92  │ 916.26  │ 1150.84 │ 1125.28 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1176.63 │ 1280.44 │ 1208.82 │ 1152.35 │ 1239.54 │ -       │ 1120.42 │ 1129.50 │ 1129.05 │ 1168.05 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1220.70 │ 1331.59 │ 1061.42 │ 1265.00 │ 1224.44 │ 1095.09 │ -       │ 1130.46 │ 1061.01 │ 1132.08 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1356.75 │ 1258.05 │ 1056.56 │ 1326.76 │ 1119.69 │ 1167.71 │ 1287.23 │ -       │ 1283.52 │ 1075.36 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1349.33 │ 1275.95 │ 1090.69 │ 1262.93 │ 1159.17 │ 1194.59 │ 1191.18 │ 1115.28 │ -       │ 1264.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1324.99 │ 963.76  │ 1103.09 │ 1023.24 │ 539.51  │ 1007.72 │ 1284.75 │ 768.30  │ 992.99  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1320014381.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_32.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_32_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1a4fd-30c2-482c-94d4-7d8264874c45",
   "metadata": {},
   "source": [
    "### MLP2L - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "509d5b55-a71e-4af0-aea6-35a9aacdbe9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\3871607115.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                    2                    3                   4                   5                    6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                             \n",
      "0                              -   6 / 1331.5 / 26.7   45 / 1213.4 / 25.2    3 / 1228.7 / 25.0  35 / 1312.4 / 26.3  25 / 1230.4 / 25.4   47 / 1263.3 / 25.6  39 / 1266.9 / 25.7  17 / 1185.9 / 25.4  41 / 1232.2 / 25.6\n",
      "1             42 / 1349.9 / 26.7                   -  100 / 1000.4 / 24.7  100 / 1127.7 / 25.3  66 / 1229.0 / 25.9  96 / 1202.7 / 25.6  100 / 1138.5 / 25.3  100 / 841.8 / 24.5  90 / 1191.9 / 25.8  100 / 909.6 / 24.8\n",
      "2             37 / 1337.0 / 25.9   8 / 1260.5 / 25.9                    -   61 / 1187.0 / 25.1  23 / 1277.2 / 26.0  45 / 1228.0 / 25.4   78 / 1186.5 / 25.4  58 / 1149.1 / 25.6  60 / 1212.7 / 25.4  39 / 1210.8 / 26.0\n",
      "3             67 / 1293.5 / 26.1  73 / 1239.0 / 26.1   80 / 1129.7 / 25.1                    -  28 / 1341.9 / 26.0  87 / 1036.4 / 24.9   50 / 1350.5 / 26.1  34 / 1283.5 / 25.6  59 / 1183.6 / 25.4  55 / 1160.5 / 25.5\n",
      "4             26 / 1313.2 / 26.2  64 / 1063.9 / 26.0   70 / 1043.1 / 25.0   27 / 1294.1 / 25.9                   -  70 / 1149.3 / 25.3   94 / 1094.9 / 25.2   99 / 892.4 / 24.6  60 / 1183.8 / 25.4  73 / 1193.8 / 25.7\n",
      "5             96 / 1066.8 / 25.4  74 / 1169.8 / 26.1   61 / 1183.5 / 25.4   70 / 1107.2 / 25.1  38 / 1288.2 / 25.8                   -   57 / 1114.3 / 25.5  73 / 1176.6 / 25.7  70 / 1237.2 / 25.5  12 / 1200.6 / 25.8\n",
      "6             72 / 1126.4 / 25.4  28 / 1279.4 / 26.0   55 / 1186.7 / 25.3   35 / 1262.4 / 25.4  73 / 1175.5 / 25.5  55 / 1169.4 / 25.3                    -  81 / 1176.0 / 25.5  57 / 1157.9 / 25.2  78 / 1160.2 / 25.4\n",
      "7             78 / 1261.6 / 25.7  51 / 1163.9 / 26.0   86 / 1066.9 / 24.9    3 / 1379.6 / 25.7   3 / 1309.3 / 26.0  68 / 1244.8 / 25.8   39 / 1328.1 / 26.0                   -  16 / 1298.0 / 25.9  95 / 1067.0 / 25.0\n",
      "8             56 / 1266.7 / 26.2  49 / 1058.2 / 25.7    88 / 973.3 / 24.9    94 / 963.9 / 24.9  50 / 1322.5 / 26.2  49 / 1224.3 / 25.5   44 / 1274.4 / 26.0  77 / 1203.1 / 26.0                   -  44 / 1240.7 / 25.8\n",
      "9             68 / 1234.6 / 26.4   61 / 966.0 / 26.0   91 / 1002.2 / 25.3   84 / 1005.7 / 25.2  100 / 679.8 / 24.3   93 / 967.5 / 25.0   81 / 1203.8 / 26.0   97 / 844.8 / 24.5   95 / 959.4 / 24.9                   -\n",
      "\n",
      "Total successful attacks: 5422 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_64_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   6 │  45 │   3 │  35 │  25 │  47 │  39 │  17 │  41 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  42 │   0 │ 100 │ 100 │  66 │  96 │ 100 │ 100 │  90 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  37 │   8 │   0 │  61 │  23 │  45 │  78 │  58 │  60 │  39 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  67 │  73 │  80 │   0 │  28 │  87 │  50 │  34 │  59 │  55 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  26 │  64 │  70 │  27 │   0 │  70 │  94 │  99 │  60 │  73 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  96 │  74 │  61 │  70 │  38 │   0 │  57 │  73 │  70 │  12 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  72 │  28 │  55 │  35 │  73 │  55 │   0 │  81 │  57 │  78 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  78 │  51 │  86 │   3 │   3 │  68 │  39 │   0 │  16 │  95 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  56 │  49 │  88 │  94 │  50 │  49 │  44 │  77 │   0 │  44 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  68 │  61 │  91 │  84 │ 100 │  93 │  81 │  97 │  95 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 24.0 │ 25.0 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 24.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 23.0 │ -    │ 25.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 23.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 25.0 │ 23.0 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 25.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.7 │ 25.2 │ 25.0 │ 26.3 │ 25.4 │ 25.6 │ 25.7 │ 25.4 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.7 │ -    │ 24.7 │ 25.3 │ 25.9 │ 25.6 │ 25.3 │ 24.5 │ 25.8 │ 24.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.9 │ 25.9 │ -    │ 25.1 │ 26.0 │ 25.4 │ 25.4 │ 25.6 │ 25.4 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.1 │ 26.1 │ 25.1 │ -    │ 26.0 │ 24.9 │ 26.1 │ 25.6 │ 25.4 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.2 │ 26.0 │ 25.0 │ 25.9 │ -    │ 25.3 │ 25.2 │ 24.6 │ 25.4 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.4 │ 26.1 │ 25.4 │ 25.1 │ 25.8 │ -    │ 25.5 │ 25.7 │ 25.5 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.4 │ 26.0 │ 25.3 │ 25.4 │ 25.5 │ 25.3 │ -    │ 25.5 │ 25.2 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.7 │ 26.0 │ 24.9 │ 25.7 │ 26.0 │ 25.8 │ 26.0 │ -    │ 25.9 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.2 │ 25.7 │ 24.9 │ 24.9 │ 26.2 │ 25.5 │ 26.0 │ 26.0 │ -    │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.4 │ 26.0 │ 25.3 │ 25.2 │ 24.3 │ 25.0 │ 26.0 │ 24.5 │ 24.9 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤═════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4       │ 5      │ 6      │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪═════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -       │ 1113.64 │ 711.66 │ 1109.38 │ 774.32  │ 935.08 │ 780.78 │ 820.99 │ 832.67 │ 224.23 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ 1134.62 │ -       │ 411.66 │ 791.17  │ 956.63  │ 692.74 │ 714.50 │ 475.42 │ 683.84 │ 596.31 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ 888.88  │ 658.76  │ -      │ 636.54  │ 971.84  │ 620.64 │ 592.96 │ 261.48 │ 630.84 │ 641.81 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ 553.91  │ 583.88  │ 420.99 │ -       │ 888.81  │ 394.92 │ 959.50 │ 672.01 │ 477.22 │ 674.39 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ 865.07  │ 292.16  │ 605.23 │ 892.92  │ -       │ 582.47 │ 572.74 │ 324.58 │ 520.29 │ 588.11 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ 554.49  │ 777.89  │ 759.97 │ 581.65  │ 928.12  │ -      │ 539.27 │ 662.26 │ 754.35 │ 838.99 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ 548.93  │ 893.98  │ 629.35 │ 853.68  │ 598.40  │ 643.22 │ -      │ 639.48 │ 669.63 │ 821.08 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 639.92  │ 788.70  │ 363.04 │ 1275.22 │ 1006.12 │ 719.96 │ 966.85 │ -      │ 978.33 │ 593.35 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 391.21  │ 431.29  │ 252.19 │ 482.11  │ 857.07  │ 782.16 │ 587.19 │ 752.56 │ -      │ 623.03 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ 733.61  │ 324.73  │ 539.56 │ 391.24  │ 230.64  │ 281.62 │ 581.46 │ 408.83 │ 603.97 │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧═════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1516.76 │ 1525.22 │ 1351.30 │ 1515.96 │ 1486.14 │ 1520.61 │ 1523.12 │ 1469.91 │ 1523.15 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1517.47 │ -       │ 1269.84 │ 1444.19 │ 1464.85 │ 1517.77 │ 1495.72 │ 1288.93 │ 1516.76 │ 1383.85 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1523.10 │ 1501.51 │ -       │ 1521.09 │ 1513.54 │ 1522.64 │ 1518.32 │ 1525.19 │ 1518.49 │ 1520.48 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1518.17 │ 1521.75 │ 1515.22 │ -       │ 1520.26 │ 1517.34 │ 1522.42 │ 1514.57 │ 1523.72 │ 1515.36 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1516.02 │ 1511.77 │ 1492.77 │ 1516.56 │ -       │ 1501.09 │ 1519.76 │ 1437.98 │ 1511.39 │ 1515.23 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1510.22 │ 1518.46 │ 1511.75 │ 1521.49 │ 1518.58 │ -       │ 1507.77 │ 1513.28 │ 1522.78 │ 1494.33 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1514.25 │ 1511.36 │ 1516.30 │ 1492.16 │ 1516.21 │ 1508.95 │ -       │ 1522.98 │ 1517.67 │ 1519.00 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1511.35 │ 1501.96 │ 1521.96 │ 1519.30 │ 1511.47 │ 1520.18 │ 1524.47 │ -       │ 1515.68 │ 1514.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1517.48 │ 1481.33 │ 1498.34 │ 1514.25 │ 1517.12 │ 1521.09 │ 1523.53 │ 1516.73 │ -       │ 1518.81 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1515.95 │ 1435.55 │ 1461.70 │ 1523.34 │ 1180.80 │ 1462.93 │ 1519.46 │ 1347.34 │ 1476.21 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1331.53 │ 1213.42 │ 1228.74 │ 1312.43 │ 1230.41 │ 1263.32 │ 1266.86 │ 1185.90 │ 1232.18 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1349.91 │ -       │ 1000.40 │ 1127.72 │ 1228.95 │ 1202.73 │ 1138.53 │ 841.81  │ 1191.95 │ 909.62  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1337.03 │ 1260.49 │ -       │ 1186.95 │ 1277.16 │ 1228.01 │ 1186.48 │ 1149.05 │ 1212.71 │ 1210.84 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1293.49 │ 1239.03 │ 1129.69 │ -       │ 1341.94 │ 1036.36 │ 1350.47 │ 1283.52 │ 1183.60 │ 1160.53 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1313.19 │ 1063.91 │ 1043.10 │ 1294.05 │ -       │ 1149.31 │ 1094.92 │ 892.40  │ 1183.84 │ 1193.77 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1066.75 │ 1169.80 │ 1183.52 │ 1107.20 │ 1288.23 │ -       │ 1114.32 │ 1176.62 │ 1237.21 │ 1200.59 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1126.43 │ 1279.36 │ 1186.74 │ 1262.42 │ 1175.52 │ 1169.38 │ -       │ 1176.02 │ 1157.92 │ 1160.19 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1261.57 │ 1163.94 │ 1066.94 │ 1379.56 │ 1309.25 │ 1244.75 │ 1328.09 │ -       │ 1298.04 │ 1067.03 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1266.73 │ 1058.20 │ 973.30  │ 963.93  │ 1322.45 │ 1224.28 │ 1274.42 │ 1203.12 │ -       │ 1240.68 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1234.60 │ 966.02  │ 1002.20 │ 1005.66 │ 679.84  │ 967.51  │ 1203.81 │ 844.76  │ 959.38  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\3871607115.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_64.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_64_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0133466-0148-41a4-9871-a1e3156276e6",
   "metadata": {},
   "source": [
    "### MLP2L - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "51a6abf4-4a16-4889-be65-0deb4f02bc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\2869938583.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                    8                   9\n",
      "true_label                                                                                                                                                                                                           \n",
      "0                              -                   -  36 / 1147.9 / 25.1                   -  16 / 1346.7 / 26.4   9 / 1358.7 / 25.7  36 / 1266.7 / 25.6   1 / 1453.9 / 26.0    5 / 1416.6 / 25.8  18 / 1373.6 / 25.9\n",
      "1             94 / 1106.6 / 26.1                   -  100 / 837.0 / 24.3  99 / 1005.7 / 24.7   78 / 968.1 / 25.1  94 / 1061.6 / 25.1  100 / 869.3 / 24.7  100 / 901.5 / 24.7  100 / 1037.5 / 25.2  100 / 767.9 / 24.5\n",
      "2             45 / 1250.5 / 25.8                   -                   -  20 / 1317.1 / 25.6   6 / 1355.9 / 26.2  20 / 1262.0 / 25.6  83 / 1196.9 / 25.4  21 / 1297.5 / 25.9   70 / 1224.3 / 25.5  59 / 1243.6 / 25.9\n",
      "3             77 / 1180.8 / 25.7  22 / 1291.6 / 26.2  94 / 1041.6 / 24.9                   -   7 / 1302.4 / 26.3  93 / 1131.3 / 25.1  39 / 1344.0 / 26.1  28 / 1313.1 / 25.7   76 / 1130.7 / 25.2  88 / 1140.4 / 25.5\n",
      "4             43 / 1300.2 / 26.1  21 / 1303.6 / 26.3  85 / 1042.2 / 25.0  17 / 1336.7 / 26.1                   -  63 / 1216.5 / 25.6  99 / 1118.3 / 25.2  85 / 1185.6 / 25.4   73 / 1249.0 / 25.6  97 / 1016.5 / 25.2\n",
      "5             99 / 1004.3 / 25.2  34 / 1323.5 / 26.4  66 / 1241.4 / 25.5  70 / 1155.5 / 25.1  50 / 1237.6 / 25.7                   -  53 / 1213.1 / 25.6  25 / 1361.9 / 26.1   32 / 1260.0 / 25.7  23 / 1305.6 / 25.9\n",
      "6             92 / 1144.5 / 25.4   5 / 1396.5 / 26.0  58 / 1082.5 / 25.1   3 / 1291.6 / 26.3  40 / 1299.9 / 25.8  41 / 1232.1 / 25.4                   -  27 / 1327.0 / 25.9   49 / 1191.5 / 25.3  40 / 1262.2 / 25.6\n",
      "7             96 / 1036.3 / 25.2  32 / 1147.4 / 25.8   92 / 877.8 / 24.5  57 / 1196.4 / 25.2  34 / 1250.6 / 25.9  93 / 1034.6 / 24.9  71 / 1255.7 / 25.9                   -   39 / 1120.1 / 25.2   97 / 937.3 / 24.7\n",
      "8             77 / 1121.9 / 25.9  24 / 1080.4 / 25.7   91 / 985.0 / 25.0  71 / 1093.3 / 25.1  28 / 1234.4 / 26.0  74 / 1170.6 / 25.3  45 / 1257.1 / 25.8  43 / 1308.6 / 26.1                    -  35 / 1185.7 / 25.7\n",
      "9             80 / 1153.3 / 26.1  16 / 1077.2 / 26.2  75 / 1157.6 / 25.7  89 / 1131.2 / 25.4  100 / 613.8 / 24.2  88 / 1058.4 / 25.2  64 / 1166.7 / 25.8  88 / 1070.8 / 25.1   91 / 1077.6 / 25.3                   -\n",
      "\n",
      "Total successful attacks: 5014 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_128_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │  36 │   0 │  16 │   9 │  36 │   1 │   5 │  18 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  94 │   0 │ 100 │  99 │  78 │  94 │ 100 │ 100 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  45 │   0 │   0 │  20 │   6 │  20 │  83 │  21 │  70 │  59 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  77 │  22 │  94 │   0 │   7 │  93 │  39 │  28 │  76 │  88 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  43 │  21 │  85 │  17 │   0 │  63 │  99 │  85 │  73 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  99 │  34 │  66 │  70 │  50 │   0 │  53 │  25 │  32 │  23 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  92 │   5 │  58 │   3 │  40 │  41 │   0 │  27 │  49 │  40 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  96 │  32 │  92 │  57 │  34 │  93 │  71 │   0 │  39 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  77 │  24 │  91 │  71 │  28 │  74 │  45 │  43 │   0 │  35 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  80 │  16 │  75 │  89 │ 100 │  88 │  64 │  88 │  91 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 24.0 │ -    │ 26.0 │ 24.0 │ 24.0 │ 26.0 │ 25.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ -    │ -    │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 25.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 25.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 23.0 │ 25.0 │ 24.0 │ 26.0 │ 24.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.1 │ -    │ 26.4 │ 25.7 │ 25.6 │ 26.0 │ 25.8 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.1 │ -    │ 24.3 │ 24.7 │ 25.1 │ 25.1 │ 24.7 │ 24.7 │ 25.2 │ 24.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.8 │ -    │ -    │ 25.6 │ 26.2 │ 25.6 │ 25.4 │ 25.9 │ 25.5 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.7 │ 26.2 │ 24.9 │ -    │ 26.3 │ 25.1 │ 26.1 │ 25.7 │ 25.2 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.1 │ 26.3 │ 25.0 │ 26.1 │ -    │ 25.6 │ 25.2 │ 25.4 │ 25.6 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.2 │ 26.4 │ 25.5 │ 25.1 │ 25.7 │ -    │ 25.6 │ 26.1 │ 25.7 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.4 │ 26.0 │ 25.1 │ 26.3 │ 25.8 │ 25.4 │ -    │ 25.9 │ 25.3 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.2 │ 25.8 │ 24.5 │ 25.2 │ 25.9 │ 24.9 │ 25.9 │ -    │ 25.2 │ 24.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.9 │ 25.7 │ 25.0 │ 25.1 │ 26.0 │ 25.3 │ 25.8 │ 26.1 │ -    │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.2 │ 26.2 │ 25.7 │ 25.4 │ 24.2 │ 25.2 │ 25.8 │ 25.1 │ 25.3 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤═════════╤════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0      │ 1       │ 2      │ 3       │ 4       │ 5      │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪════════╪═════════╪════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -      │ -       │ 718.10 │ -       │ 1025.98 │ 891.29 │ 772.11  │ 1453.93 │ 1179.04 │ 1005.63 │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 508.44 │ -       │ 380.42 │ 567.31  │ 645.07  │ 662.08 │ 424.38  │ 423.95  │ 651.23  │ 554.26  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 776.96 │ -       │ -      │ 930.46  │ 1030.58 │ 781.89 │ 625.58  │ 697.43  │ 610.81  │ 742.95  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 317.87 │ 791.46  │ 540.21 │ -       │ 1063.16 │ 447.37 │ 1044.07 │ 884.12  │ 357.04  │ 468.61  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 852.64 │ 469.41  │ 444.29 │ 800.77  │ -       │ 531.28 │ 349.92  │ 666.68  │ 670.94  │ 441.76  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 441.12 │ 842.56  │ 735.05 │ 221.13  │ 636.25  │ -      │ 589.72  │ 892.67  │ 782.67  │ 750.45  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 353.28 │ 1018.76 │ 500.60 │ 1230.90 │ 451.25  │ 524.83 │ -       │ 896.51  │ 753.41  │ 1015.17 │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 370.71 │ 798.75  │ 148.10 │ 586.95  │ 733.45  │ 448.53 │ 637.50  │ -       │ 567.74  │ 438.72  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 668.86 │ 358.84  │ 110.66 │ 365.44  │ 922.93  │ 651.98 │ 564.59  │ 813.79  │ -       │ 527.45  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 535.83 │ 706.46  │ 661.39 │ 567.49  │ 177.97  │ 413.26 │ 690.45  │ 488.92  │ 634.04  │ -       │\n",
      "╘══════════════╧════════╧═════════╧════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1501.18 │ -       │ 1515.26 │ 1509.62 │ 1516.83 │ 1453.93 │ 1496.89 │ 1517.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1515.79 │ -       │ 1251.51 │ 1278.24 │ 1308.06 │ 1484.70 │ 1207.94 │ 1343.46 │ 1352.12 │ 1036.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1517.51 │ -       │ -       │ 1517.50 │ 1516.71 │ 1505.97 │ 1521.91 │ 1525.19 │ 1518.91 │ 1521.31 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1514.36 │ 1521.75 │ 1514.25 │ -       │ 1479.49 │ 1517.81 │ 1518.88 │ 1512.45 │ 1514.18 │ 1519.31 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1520.49 │ 1517.61 │ 1510.75 │ 1518.43 │ -       │ 1515.31 │ 1519.00 │ 1523.23 │ 1519.99 │ 1460.84 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1448.35 │ 1517.49 │ 1517.88 │ 1526.07 │ 1492.06 │ -       │ 1514.56 │ 1512.20 │ 1518.06 │ 1517.42 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1518.77 │ 1519.83 │ 1513.31 │ 1354.42 │ 1523.84 │ 1519.62 │ -       │ 1526.29 │ 1523.22 │ 1518.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1510.73 │ 1509.38 │ 1515.21 │ 1519.78 │ 1514.96 │ 1524.92 │ 1524.51 │ -       │ 1495.87 │ 1503.29 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1518.64 │ 1517.50 │ 1524.63 │ 1524.25 │ 1516.13 │ 1518.66 │ 1521.32 │ 1501.41 │ -       │ 1518.29 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1515.21 │ 1500.40 │ 1522.07 │ 1507.93 │ 1352.32 │ 1522.63 │ 1516.34 │ 1515.84 │ 1522.71 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1147.85 │ -       │ 1346.66 │ 1358.68 │ 1266.70 │ 1453.93 │ 1416.59 │ 1373.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1106.59 │ -       │ 837.04  │ 1005.66 │ 968.10  │ 1061.62 │ 869.25  │ 901.50  │ 1037.47 │ 767.86  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1250.54 │ -       │ -       │ 1317.12 │ 1355.90 │ 1262.01 │ 1196.90 │ 1297.51 │ 1224.30 │ 1243.61 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1180.76 │ 1291.65 │ 1041.65 │ -       │ 1302.43 │ 1131.27 │ 1344.00 │ 1313.06 │ 1130.70 │ 1140.36 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1300.17 │ 1303.61 │ 1042.22 │ 1336.70 │ -       │ 1216.47 │ 1118.33 │ 1185.64 │ 1249.03 │ 1016.55 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1004.28 │ 1323.48 │ 1241.36 │ 1155.50 │ 1237.59 │ -       │ 1213.09 │ 1361.93 │ 1260.04 │ 1305.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1144.46 │ 1396.53 │ 1082.48 │ 1291.56 │ 1299.90 │ 1232.05 │ -       │ 1326.97 │ 1191.49 │ 1262.21 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1036.28 │ 1147.41 │ 877.83  │ 1196.35 │ 1250.59 │ 1034.60 │ 1255.67 │ -       │ 1120.14 │ 937.28  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1121.92 │ 1080.43 │ 985.03  │ 1093.29 │ 1234.40 │ 1170.61 │ 1257.10 │ 1308.57 │ -       │ 1185.66 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1153.32 │ 1077.17 │ 1157.55 │ 1131.16 │ 613.80  │ 1058.39 │ 1166.71 │ 1070.82 │ 1077.63 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\2869938583.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_128.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_128_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87a1c0-6825-40ea-98d9-b19d14a64775",
   "metadata": {},
   "source": [
    "### MLP2L - 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "458d52fc-7ea4-400e-bb7f-e7c861b34ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1187009171.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -   5 / 1310.7 / 26.8  36 / 1135.8 / 25.1   4 / 1302.1 / 26.2  35 / 1241.5 / 26.1   5 / 1337.1 / 25.6  37 / 1205.7 / 25.4  34 / 1279.7 / 25.8  17 / 1211.7 / 25.5  22 / 1211.5 / 25.5\n",
      "1             84 / 1294.6 / 26.7                   -  100 / 845.5 / 24.3   99 / 912.1 / 24.6  100 / 862.0 / 24.9  92 / 1089.4 / 25.2  100 / 992.6 / 25.0  100 / 979.6 / 24.9  83 / 1034.3 / 25.1   99 / 972.3 / 25.1\n",
      "2             20 / 1344.5 / 26.1                   -                   -  48 / 1235.5 / 25.4                   -  14 / 1312.1 / 25.7  56 / 1282.6 / 25.6  42 / 1174.5 / 25.6  57 / 1201.7 / 25.4  33 / 1288.6 / 26.2\n",
      "3             27 / 1320.3 / 26.1  21 / 1349.4 / 26.4  61 / 1254.0 / 25.4                   -  22 / 1330.0 / 26.1  93 / 1121.1 / 25.1  33 / 1356.6 / 26.1  15 / 1315.6 / 25.5  72 / 1170.3 / 25.4  64 / 1262.3 / 25.7\n",
      "4              5 / 1405.7 / 26.8   2 / 1027.8 / 25.5  71 / 1055.6 / 25.1  15 / 1312.8 / 26.2                   -  24 / 1277.3 / 25.7  66 / 1172.0 / 25.4  92 / 1117.1 / 25.2  55 / 1187.9 / 25.4  87 / 1140.2 / 25.5\n",
      "5             94 / 1176.9 / 25.6  24 / 1380.2 / 26.5  31 / 1308.6 / 25.7  41 / 1219.2 / 25.2  60 / 1249.9 / 25.8                   -  40 / 1243.6 / 25.8  55 / 1280.2 / 25.9  43 / 1260.3 / 25.6  11 / 1292.1 / 25.8\n",
      "6             58 / 1213.4 / 25.5  19 / 1336.8 / 26.1  65 / 1160.9 / 25.2   9 / 1094.3 / 24.9  66 / 1173.0 / 25.5  49 / 1160.6 / 25.2                   -  46 / 1249.3 / 25.8  56 / 1150.2 / 25.2  49 / 1291.5 / 25.7\n",
      "7             75 / 1298.9 / 25.8  22 / 1218.0 / 26.0  94 / 1064.4 / 24.9  37 / 1340.3 / 25.5  23 / 1331.9 / 26.1  33 / 1225.9 / 25.5  89 / 1233.5 / 25.8                   -  59 / 1195.7 / 25.4  90 / 1129.0 / 25.1\n",
      "8             40 / 1310.0 / 26.4   6 / 1139.4 / 25.8  79 / 1139.8 / 25.2  55 / 1147.0 / 25.3  38 / 1239.3 / 26.0  26 / 1266.2 / 25.5  18 / 1275.9 / 25.7  43 / 1341.5 / 26.2                   -  16 / 1286.4 / 25.8\n",
      "9             55 / 1308.4 / 26.5  15 / 1141.0 / 26.4  72 / 1138.3 / 25.6  57 / 1149.8 / 25.4   99 / 789.9 / 24.7  96 / 1011.8 / 25.1  62 / 1226.1 / 26.0  88 / 1089.0 / 25.0  95 / 1062.7 / 25.3                   -\n",
      "\n",
      "Total successful attacks: 4445 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_256_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   5 │  36 │   4 │  35 │   5 │  37 │  34 │  17 │  22 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  84 │   0 │ 100 │  99 │ 100 │  92 │ 100 │ 100 │  83 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  20 │   0 │   0 │  48 │   0 │  14 │  56 │  42 │  57 │  33 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  27 │  21 │  61 │   0 │  22 │  93 │  33 │  15 │  72 │  64 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   5 │   2 │  71 │  15 │   0 │  24 │  66 │  92 │  55 │  87 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  94 │  24 │  31 │  41 │  60 │   0 │  40 │  55 │  43 │  11 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  58 │  19 │  65 │   9 │  66 │  49 │   0 │  46 │  56 │  49 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  75 │  22 │  94 │  37 │  23 │  33 │  89 │   0 │  59 │  90 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  40 │   6 │  79 │  55 │  38 │  26 │  18 │  43 │   0 │  16 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  55 │  15 │  72 │  57 │  99 │  96 │  62 │  88 │  95 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 24.0 │ 25.0 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ -    │ -    │ 24.0 │ -    │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 25.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 23.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 25.0 │ 23.0 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.8 │ 25.1 │ 26.2 │ 26.1 │ 25.6 │ 25.4 │ 25.8 │ 25.5 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.7 │ -    │ 24.3 │ 24.6 │ 24.9 │ 25.2 │ 25.0 │ 24.9 │ 25.1 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.2 │ -    │ -    │ 25.4 │ -    │ 25.7 │ 25.6 │ 25.6 │ 25.4 │ 26.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.1 │ 26.4 │ 25.4 │ -    │ 26.1 │ 25.1 │ 26.1 │ 25.5 │ 25.4 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.8 │ 25.5 │ 25.1 │ 26.2 │ -    │ 25.7 │ 25.4 │ 25.2 │ 25.4 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.6 │ 26.5 │ 25.7 │ 25.2 │ 25.8 │ -    │ 25.8 │ 25.9 │ 25.6 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.5 │ 26.1 │ 25.2 │ 24.9 │ 25.5 │ 25.2 │ -    │ 25.8 │ 25.2 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.8 │ 26.0 │ 24.9 │ 25.5 │ 26.1 │ 25.5 │ 25.8 │ -    │ 25.4 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.4 │ 25.8 │ 25.2 │ 25.3 │ 26.0 │ 25.5 │ 25.7 │ 26.2 │ -    │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.5 │ 26.4 │ 25.6 │ 25.4 │ 24.7 │ 25.1 │ 26.0 │ 25.0 │ 25.3 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╤════════╤═════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4       │ 5       │ 6      │ 7       │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪════════╪═════════╪════════╪════════╡\n",
      "│            0 │ -       │ 1085.09 │ 595.99 │ 1059.27 │ 825.60  │ 1200.14 │ 594.26 │ 848.78  │ 648.69 │ 764.09 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            1 │ 927.92  │ -       │ 537.83 │ 390.27  │ 510.97  │ 671.04  │ 461.31 │ 475.12  │ 627.96 │ 511.57 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            2 │ 1154.25 │ -       │ -      │ 735.25  │ -       │ 1020.49 │ 658.82 │ 639.21  │ 715.05 │ 912.70 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            3 │ 602.21  │ 978.05  │ 701.88 │ -       │ 1023.45 │ 685.51  │ 997.21 │ 1018.86 │ 464.29 │ 820.14 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            4 │ 1315.67 │ 560.19  │ 570.96 │ 959.83  │ -       │ 582.82  │ 472.36 │ 472.16  │ 782.06 │ 324.32 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            5 │ 424.51  │ 919.60  │ 874.02 │ 719.05  │ 667.67  │ -       │ 608.66 │ 895.22  │ 99.88  │ 917.47 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            6 │ 169.01  │ 891.74  │ 485.56 │ 833.75  │ 515.08  │ 624.66  │ -      │ 904.24  │ 680.10 │ 725.31 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            7 │ 818.73  │ 949.95  │ 457.70 │ 902.35  │ 878.61  │ 704.42  │ 722.31 │ -       │ 701.10 │ 560.31 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            8 │ 681.57  │ 502.18  │ 453.31 │ 318.85  │ 718.92  │ 784.39  │ 695.79 │ 878.70  │ -      │ 912.11 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┤\n",
      "│            9 │ 845.19  │ 782.30  │ 665.66 │ 517.85  │ 162.55  │ 316.68  │ 655.56 │ 514.81  │ 639.98 │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╧════════╧═════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1480.72 │ 1522.19 │ 1462.30 │ 1520.20 │ 1496.71 │ 1511.92 │ 1519.86 │ 1513.34 │ 1505.89 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1522.55 │ -       │ 1059.18 │ 1458.73 │ 1325.66 │ 1500.71 │ 1400.23 │ 1456.53 │ 1513.07 │ 1453.72 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1470.78 │ -       │ -       │ 1521.09 │ -       │ 1517.64 │ 1519.54 │ 1519.70 │ 1522.84 │ 1520.98 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1519.70 │ 1515.54 │ 1522.94 │ -       │ 1518.29 │ 1509.99 │ 1513.09 │ 1511.49 │ 1514.78 │ 1513.29 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1437.84 │ 1495.42 │ 1516.88 │ 1508.81 │ -       │ 1523.13 │ 1513.00 │ 1521.03 │ 1520.22 │ 1513.47 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1522.61 │ 1521.70 │ 1523.39 │ 1519.47 │ 1521.00 │ -       │ 1517.04 │ 1521.82 │ 1517.92 │ 1485.41 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1519.83 │ 1511.81 │ 1522.11 │ 1516.53 │ 1513.59 │ 1519.47 │ -       │ 1521.64 │ 1521.10 │ 1516.19 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1523.20 │ 1521.23 │ 1480.10 │ 1525.52 │ 1523.26 │ 1505.57 │ 1519.47 │ -       │ 1511.19 │ 1504.03 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1492.22 │ 1499.26 │ 1524.63 │ 1520.85 │ 1513.47 │ 1519.88 │ 1517.67 │ 1520.07 │ -       │ 1520.65 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1522.16 │ 1481.60 │ 1512.34 │ 1515.96 │ 1518.96 │ 1522.64 │ 1520.04 │ 1511.03 │ 1524.05 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1310.69 │ 1135.84 │ 1302.06 │ 1241.48 │ 1337.14 │ 1205.69 │ 1279.72 │ 1211.73 │ 1211.50 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1294.56 │ -       │ 845.51  │ 912.06  │ 862.00  │ 1089.39 │ 992.60  │ 979.59  │ 1034.32 │ 972.29  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1344.51 │ -       │ -       │ 1235.55 │ -       │ 1312.11 │ 1282.63 │ 1174.52 │ 1201.70 │ 1288.64 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1320.29 │ 1349.44 │ 1254.02 │ -       │ 1329.97 │ 1121.07 │ 1356.57 │ 1315.60 │ 1170.35 │ 1262.28 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1405.68 │ 1027.81 │ 1055.57 │ 1312.79 │ -       │ 1277.27 │ 1172.03 │ 1117.14 │ 1187.87 │ 1140.20 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1176.94 │ 1380.17 │ 1308.64 │ 1219.19 │ 1249.94 │ -       │ 1243.62 │ 1280.21 │ 1260.32 │ 1292.08 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1213.38 │ 1336.78 │ 1160.92 │ 1094.27 │ 1172.98 │ 1160.58 │ -       │ 1249.30 │ 1150.23 │ 1291.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1298.94 │ 1218.00 │ 1064.40 │ 1340.32 │ 1331.94 │ 1225.93 │ 1233.51 │ -       │ 1195.71 │ 1128.97 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1310.00 │ 1139.44 │ 1139.82 │ 1147.04 │ 1239.35 │ 1266.18 │ 1275.85 │ 1341.48 │ -       │ 1286.42 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1308.44 │ 1141.00 │ 1138.29 │ 1149.75 │ 789.87  │ 1011.81 │ 1226.12 │ 1089.03 │ 1062.69 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1187009171.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_256.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_256_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653516b-bc36-4c64-8497-bedfa705df59",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fe090ce7-be01-418a-bd87-7e8763f4d354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1384276042.py:56: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                  0                   1                   2                   3                   4                   5                  6                   7                   8                  9\n",
      "true_label                                                                                                                                                                                                       \n",
      "0                             -                   -  12 / 1464.2 / 25.9    1 / 993.4 / 25.0   5 / 1186.9 / 25.8   5 / 1421.0 / 25.8                  -   3 / 1374.0 / 25.7  23 / 1198.3 / 25.5   1 / 881.8 / 25.0\n",
      "1                             -                   -  75 / 1294.0 / 25.7  10 / 1434.2 / 26.6  19 / 1243.8 / 25.8                   -  3 / 1125.2 / 25.0                   -  42 / 1205.9 / 25.5  1 / 1171.7 / 26.0\n",
      "2                             -    1 / 855.2 / 25.0                   -   5 / 1406.2 / 25.6                   -   1 / 1488.9 / 26.0                  -   1 / 1513.6 / 26.0   4 / 1186.3 / 25.2                  -\n",
      "3              1 / 829.7 / 24.0   3 / 1338.5 / 26.7                   -                   -                   -   1 / 1412.1 / 26.0  2 / 1306.3 / 26.0                   -   9 / 1268.8 / 25.6                  -\n",
      "4                             -   5 / 1432.3 / 26.6  15 / 1459.1 / 26.1   9 / 1387.8 / 26.2                   -   9 / 1311.7 / 25.8                  -  22 / 1328.4 / 25.8  20 / 1393.2 / 25.9  4 / 1446.9 / 26.5\n",
      "5             3 / 1446.2 / 26.3   5 / 1454.0 / 26.6                   -  13 / 1356.7 / 25.8   2 / 1443.7 / 26.0                   -  2 / 1274.6 / 26.0                   -   4 / 1243.4 / 25.2   1 / 629.0 / 24.0\n",
      "6                             -   1 / 1508.8 / 27.0                   -   3 / 1473.1 / 26.0   3 / 1399.0 / 26.0                   -                  -                   -   3 / 1422.4 / 26.0                  -\n",
      "7                             -                   -   2 / 1490.9 / 26.0  22 / 1355.4 / 25.5   1 / 1383.5 / 26.0   2 / 1500.9 / 26.5                  -                   -  10 / 1436.3 / 25.9                  -\n",
      "8                             -   3 / 1135.0 / 25.7   1 / 1298.8 / 26.0  23 / 1235.2 / 25.5   3 / 1310.3 / 26.7   1 / 1439.2 / 27.0                  -                   -                   -                  -\n",
      "9                             -  11 / 1362.6 / 26.7   1 / 1491.4 / 27.0  30 / 1382.1 / 26.0  71 / 1247.0 / 25.9  10 / 1396.5 / 26.1                  -  33 / 1294.2 / 25.6  34 / 1320.9 / 25.8                  -\n",
      "\n",
      "Total successful attacks: 610 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/CNN_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │  12 │   1 │   5 │   5 │   0 │   3 │  23 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   0 │   0 │  75 │  10 │  19 │   0 │   3 │   0 │  42 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │   0 │   1 │   0 │   5 │   0 │   1 │   0 │   1 │   4 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │   1 │   3 │   0 │   0 │   0 │   1 │   2 │   0 │   9 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   0 │   5 │  15 │   9 │   0 │   9 │   0 │  22 │  20 │   4 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │   3 │   5 │   0 │  13 │   2 │   0 │   2 │   0 │   4 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │   0 │   1 │   0 │   3 │   3 │   0 │   0 │   0 │   3 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │   0 │   0 │   2 │  22 │   1 │   2 │   0 │   0 │  10 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   0 │   3 │   1 │  23 │   3 │   1 │   0 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   0 │  11 │   1 │  30 │  71 │  10 │   0 │  33 │  34 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.0 │ 25.0 │ 25.0 │ 25.0 │ -    │ 25.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ 25.0 │ 26.0 │ 25.0 │ -    │ 24.0 │ -    │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ 25.0 │ -    │ 25.0 │ -    │ 26.0 │ -    │ 26.0 │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 26.0 │ -    │ -    │ -    │ 26.0 │ 26.0 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 26.0 │ 26.0 │ 25.0 │ -    │ 24.0 │ -    │ 25.0 │ 25.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ 26.0 │ -    │ 25.0 │ 26.0 │ -    │ 26.0 │ -    │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ 27.0 │ -    │ 26.0 │ 26.0 │ -    │ -    │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ -    │ 26.0 │ 25.0 │ 26.0 │ 26.0 │ -    │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 24.0 │ 26.0 │ 24.0 │ 26.0 │ 27.0 │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ 26.0 │ 27.0 │ 25.0 │ 25.0 │ 25.0 │ -    │ 25.0 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 26.0 │ 25.0 │ 27.0 │ 26.0 │ -    │ 26.0 │ 27.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ 25.0 │ -    │ 26.0 │ -    │ 26.0 │ -    │ 26.0 │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 27.0 │ -    │ -    │ -    │ 26.0 │ 26.0 │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ -    │ 26.0 │ -    │ 26.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ 27.0 │ -    │ 26.0 │ 26.0 │ -    │ -    │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ -    │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.9 │ 25.0 │ 25.8 │ 25.8 │ -    │ 25.7 │ 25.5 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ 25.7 │ 26.6 │ 25.8 │ -    │ 25.0 │ -    │ 25.5 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ 25.0 │ -    │ 25.6 │ -    │ 26.0 │ -    │ 26.0 │ 25.2 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 26.7 │ -    │ -    │ -    │ 26.0 │ 26.0 │ -    │ 25.6 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 26.6 │ 26.1 │ 26.2 │ -    │ 25.8 │ -    │ 25.8 │ 26.0 │ 26.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.3 │ 26.6 │ -    │ 25.8 │ 26.0 │ -    │ 26.0 │ -    │ 25.2 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ 27.0 │ -    │ 26.0 │ 26.0 │ -    │ -    │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ -    │ 26.0 │ 25.5 │ 26.0 │ 26.5 │ -    │ -    │ 25.9 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 25.7 │ 26.0 │ 25.5 │ 26.7 │ 27.0 │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ 26.7 │ 27.0 │ 26.0 │ 25.9 │ 26.1 │ -    │ 25.6 │ 25.8 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1329.24 │ 993.40  │ 861.21  │ 1254.39 │ -       │ 1280.28 │ 835.72  │ 881.80  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ -       │ 930.61  │ 1030.57 │ 996.32  │ -       │ 798.59  │ -       │ 718.68  │ 1171.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ -       │ 855.20  │ -       │ 1282.86 │ -       │ 1488.85 │ -       │ 1513.64 │ 438.48  │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 829.75  │ 1203.47 │ -       │ -       │ -       │ 1412.11 │ 1221.42 │ -       │ 992.15  │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1349.24 │ 1162.74 │ 1217.00 │ -       │ 816.55  │ -       │ 960.83  │ 1144.90 │ 1395.81 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1440.85 │ 1372.88 │ -       │ 1073.22 │ 1409.24 │ -       │ 1227.34 │ -       │ 1184.67 │ 629.00  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ -       │ 1508.82 │ -       │ 1461.11 │ 1375.82 │ -       │ -       │ -       │ 1282.98 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ -       │ 1478.87 │ 986.20  │ 1383.50 │ 1481.54 │ -       │ -       │ 1231.59 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ -       │ 702.70  │ 1298.76 │ 734.72  │ 1057.73 │ 1439.22 │ -       │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ -       │ 1136.36 │ 1491.42 │ 935.97  │ 914.33  │ 1181.24 │ -       │ 989.10  │ 889.97  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1522.75 │ 993.40  │ 1399.53 │ 1525.43 │ -       │ 1474.04 │ 1487.75 │ 881.80  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ -       │ 1513.31 │ 1520.64 │ 1515.35 │ -       │ 1425.53 │ -       │ 1517.64 │ 1171.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ -       │ 855.20  │ -       │ 1516.74 │ -       │ 1488.85 │ -       │ 1513.64 │ 1512.22 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 829.75  │ 1424.31 │ -       │ -       │ -       │ 1412.11 │ 1391.22 │ -       │ 1511.08 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1512.55 │ 1519.45 │ 1506.42 │ -       │ 1516.52 │ -       │ 1513.73 │ 1519.32 │ 1504.81 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1451.87 │ 1503.81 │ -       │ 1511.51 │ 1478.20 │ -       │ 1321.87 │ -       │ 1345.93 │ 629.00  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ -       │ 1508.82 │ -       │ 1494.54 │ 1423.17 │ -       │ -       │ -       │ 1519.82 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ -       │ 1502.98 │ 1515.71 │ 1383.50 │ 1520.23 │ -       │ -       │ 1517.85 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ -       │ 1445.18 │ 1298.76 │ 1518.70 │ 1469.55 │ 1439.22 │ -       │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ -       │ 1494.80 │ 1491.42 │ 1524.18 │ 1513.24 │ 1506.45 │ -       │ 1525.43 │ 1522.06 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1464.16 │ 993.40  │ 1186.87 │ 1421.00 │ -       │ 1374.04 │ 1198.28 │ 881.80  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ -       │ 1293.99 │ 1434.22 │ 1243.77 │ -       │ 1125.18 │ -       │ 1205.91 │ 1171.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ -       │ 855.20  │ -       │ 1406.25 │ -       │ 1488.85 │ -       │ 1513.64 │ 1186.27 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 829.75  │ 1338.49 │ -       │ -       │ -       │ 1412.11 │ 1306.32 │ -       │ 1268.84 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1432.35 │ 1459.12 │ 1387.79 │ -       │ 1311.72 │ -       │ 1328.41 │ 1393.16 │ 1446.91 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1446.17 │ 1453.98 │ -       │ 1356.74 │ 1443.72 │ -       │ 1274.60 │ -       │ 1243.43 │ 629.00  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ -       │ 1508.82 │ -       │ 1473.10 │ 1398.95 │ -       │ -       │ -       │ 1422.37 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ -       │ 1490.93 │ 1355.36 │ 1383.50 │ 1500.88 │ -       │ -       │ 1436.33 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ -       │ 1135.02 │ 1298.76 │ 1235.18 │ 1310.34 │ 1439.22 │ -       │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ -       │ 1362.64 │ 1491.42 │ 1382.13 │ 1246.98 │ 1396.52 │ -       │ 1294.22 │ 1320.86 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1384276042.py:248: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from torchvision import transforms\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_CNN.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/CNN_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "# ──────────────── TRANSFORM FOR CNN INPUT ─────────────────────────────────\n",
    "transform_28x28 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((28, 28), interpolation=Image.BILINEAR),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    if x01.ndim == 1:\n",
    "        x01 = x01.reshape(28, 28)\n",
    "    img = (x01 * 255).astype(np.uint8)\n",
    "    tensor = transform_28x28(img)\n",
    "    return tensor.unsqueeze(0).float()  # (1, 1, 28, 28)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843cc16-a0bf-4335-8f7f-a354f5ecfa22",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "06a54215-8ba3-4579-b0a7-28fd44083603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\3264109635.py:46: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                  0                   2                   3                   4                   5                   6                  7                  8                  9\n",
      "true_label                                                                                                                                                                                  \n",
      "0                             -  18 / 1177.7 / 24.9   1 / 1377.0 / 25.0   3 / 1044.8 / 25.3                   -   8 / 1033.7 / 24.5                  -  24 / 868.4 / 24.7  1 / 1516.4 / 27.0\n",
      "1             3 / 1314.2 / 26.3   96 / 163.9 / 23.1   75 / 446.8 / 23.7   75 / 609.3 / 24.4   57 / 413.8 / 23.7   62 / 551.3 / 24.0  31 / 578.5 / 23.9   99 / 96.2 / 23.1   3 / 614.3 / 24.3\n",
      "2             17 / 915.1 / 24.6                   -  16 / 1016.1 / 25.1    6 / 745.2 / 24.5  10 / 1089.0 / 24.8   31 / 982.5 / 24.8  1 / 1159.5 / 25.0  70 / 730.6 / 24.5  4 / 1322.6 / 25.5\n",
      "3             18 / 914.6 / 25.2   23 / 839.9 / 24.6                   -   3 / 1350.7 / 26.0   38 / 928.7 / 24.8    6 / 814.1 / 24.3                  -  64 / 624.5 / 24.3                  -\n",
      "4             14 / 998.1 / 25.3   75 / 784.0 / 24.4    9 / 901.0 / 24.7                   -   23 / 652.1 / 24.2   52 / 843.9 / 24.7  5 / 1291.4 / 25.6  50 / 720.9 / 24.7  44 / 790.5 / 24.5\n",
      "5             67 / 920.0 / 25.1   33 / 907.8 / 24.9   54 / 903.4 / 24.6  13 / 1100.6 / 25.2                   -   29 / 970.2 / 25.0                  -  79 / 467.1 / 23.7   2 / 959.1 / 25.5\n",
      "6             37 / 797.4 / 24.4   30 / 709.5 / 24.4  15 / 1171.0 / 25.1   12 / 939.6 / 24.6   15 / 673.0 / 24.1                   -                  -  60 / 587.4 / 24.2                  -\n",
      "7             73 / 560.0 / 24.1   84 / 351.1 / 23.5   33 / 874.6 / 24.7   77 / 899.2 / 24.9   55 / 630.5 / 24.2   31 / 864.5 / 25.1                  -  79 / 684.6 / 24.5  69 / 526.5 / 24.0\n",
      "8             5 / 1184.2 / 25.6  13 / 1168.9 / 25.2  15 / 1074.8 / 24.9   1 / 1280.1 / 26.0    4 / 640.6 / 23.8  11 / 1098.1 / 25.4                  -                  -                  -\n",
      "9             27 / 976.0 / 25.3   52 / 821.3 / 25.0   42 / 878.6 / 24.7   75 / 560.3 / 24.3   51 / 408.1 / 23.8   58 / 779.0 / 25.1  9 / 1153.9 / 25.0  86 / 223.3 / 23.7                  -\n",
      "\n",
      "Total successful attacks: 2531 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/RF_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  18 │   1 │   3 │   0 │   8 │   0 │  24 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   3 │  96 │  75 │  75 │  57 │  62 │  31 │  99 │   3 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  17 │   0 │  16 │   6 │  10 │  31 │   1 │  70 │   4 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  18 │  23 │   0 │   3 │  38 │   6 │   0 │  64 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  14 │  75 │   9 │   0 │  23 │  52 │   5 │  50 │  44 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  67 │  33 │  54 │  13 │   0 │  29 │   0 │  79 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  37 │  30 │  15 │  12 │  15 │   0 │   0 │  60 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  73 │  84 │  33 │  77 │  55 │  31 │   0 │  79 │  69 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   5 │  13 │  15 │   1 │   4 │  11 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  27 │  52 │  42 │  75 │  51 │  58 │   9 │  86 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 24.0 │ 25.0 │ 24.0 │ -    │ 23.0 │ -    │ 23.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 23.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 23.0 │ -    │ 25.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ -    │ 23.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.0 │ 24.0 │ 24.0 │ 26.0 │ 23.0 │ 24.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 25.0 │ 26.0 │ -    │ 26.0 │ -    │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 26.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 24.9 │ 25.0 │ 25.3 │ -    │ 24.5 │ -    │ 24.7 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.3 │ 23.1 │ 23.7 │ 24.4 │ 23.7 │ 24.0 │ 23.9 │ 23.1 │ 24.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.6 │ -    │ 25.1 │ 24.5 │ 24.8 │ 24.8 │ 25.0 │ 24.5 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.2 │ 24.6 │ -    │ 26.0 │ 24.8 │ 24.3 │ -    │ 24.3 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.3 │ 24.4 │ 24.7 │ -    │ 24.2 │ 24.7 │ 25.6 │ 24.7 │ 24.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.1 │ 24.9 │ 24.6 │ 25.2 │ -    │ 25.0 │ -    │ 23.7 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.4 │ 24.4 │ 25.1 │ 24.6 │ 24.1 │ -    │ -    │ 24.2 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.1 │ 23.5 │ 24.7 │ 24.9 │ 24.2 │ 25.1 │ -    │ 24.5 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.6 │ 25.2 │ 24.9 │ 26.0 │ 23.8 │ 25.4 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.3 │ 25.0 │ 24.7 │ 24.3 │ 23.8 │ 25.1 │ 25.0 │ 23.7 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤═════════╤═════════╤════════╤════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0      │ 2      │ 3       │ 4       │ 5      │ 6      │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪════════╪════════╪═════════╪═════════╪════════╪════════╪═════════╪════════╪═════════╡\n",
      "│            0 │ -      │ 505.18 │ 1376.96 │ 719.29  │ -      │ 433.16 │ -       │ 33.75  │ 1516.38 │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            1 │ 912.83 │ 36.18  │ 52.95   │ 48.39   │ 50.91  │ 119.42 │ 52.01   │ 46.87  │ 318.52  │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            2 │ 70.21  │ -      │ 55.43   │ 253.39  │ 416.28 │ 104.39 │ 1159.48 │ 34.53  │ 1018.90 │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 50.82  │ 53.58  │ -       │ 1157.10 │ 36.51  │ 298.37 │ -       │ 35.59  │ -       │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ 33.24  │ 125.81 │ 456.49  │ -       │ 53.99  │ 67.08  │ 905.96  │ 85.77  │ 215.69  │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 136.13 │ 128.92 │ 37.87   │ 478.92  │ -      │ 163.21 │ -       │ 108.86 │ 422.56  │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 33.85  │ 256.26 │ 263.94  │ 316.95  │ 124.51 │ -      │ -       │ 65.43  │ -       │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ 48.54  │ 53.30  │ 90.82   │ 137.05  │ 72.42  │ 63.48  │ -       │ 51.40  │ 32.26   │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 886.09 │ 716.05 │ 629.70  │ 1280.11 │ 209.32 │ 626.12 │ -       │ -      │ -       │\n",
      "├──────────────┼────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 68.85  │ 92.83  │ 215.77  │ 64.15   │ 35.01  │ 121.83 │ 749.83  │ 66.31  │ -       │\n",
      "╘══════════════╧════════╧════════╧═════════╧═════════╧════════╧════════╧═════════╧════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1520.90 │ 1376.96 │ 1516.18 │ -       │ 1519.98 │ -       │ 1511.86 │ 1516.38 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1516.22 │ 1041.72 │ 1366.29 │ 1516.36 │ 1520.89 │ 1517.64 │ 1270.91 │ 494.14  │ 1105.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1441.85 │ -       │ 1510.89 │ 998.29  │ 1417.03 │ 1523.45 │ 1159.48 │ 1504.21 │ 1516.41 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1434.72 │ 1523.85 │ -       │ 1513.79 │ 1486.03 │ 1494.36 │ -       │ 1516.73 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1522.59 │ 1514.21 │ 1517.30 │ -       │ 1522.99 │ 1510.34 │ 1524.20 │ 1517.10 │ 1495.99 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1516.62 │ 1521.89 │ 1521.77 │ 1509.61 │ -       │ 1522.57 │ -       │ 1350.92 │ 1495.72 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1515.66 │ 1518.17 │ 1523.27 │ 1480.62 │ 1521.43 │ -       │ -       │ 1509.77 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1463.94 │ 1414.73 │ 1525.58 │ 1521.64 │ 1521.07 │ 1518.58 │ -       │ 1420.04 │ 1524.60 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1519.24 │ 1520.44 │ 1450.51 │ 1280.11 │ 1079.36 │ 1450.78 │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1515.72 │ 1522.07 │ 1501.70 │ 1515.10 │ 1517.00 │ 1505.42 │ 1343.54 │ 894.75  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 1177.71 │ 1376.96 │ 1044.83 │ -       │ 1033.70 │ -       │ 868.35 │ 1516.38 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            1 │ 1314.24 │ 163.90  │ 446.84  │ 609.32  │ 413.81  │ 551.28  │ 578.47  │ 96.18  │ 614.34  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            2 │ 915.07  │ -       │ 1016.15 │ 745.19  │ 1089.04 │ 982.48  │ 1159.48 │ 730.64 │ 1322.60 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 914.63  │ 839.93  │ -       │ 1350.74 │ 928.66  │ 814.12  │ -       │ 624.52 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ 998.06  │ 784.04  │ 901.05  │ -       │ 652.08  │ 843.94  │ 1291.38 │ 720.94 │ 790.54  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 919.97  │ 907.76  │ 903.39  │ 1100.58 │ -       │ 970.16  │ -       │ 467.08 │ 959.14  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 797.39  │ 709.48  │ 1171.03 │ 939.63  │ 673.00  │ -       │ -       │ 587.40 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ 560.05  │ 351.08  │ 874.64  │ 899.24  │ 630.54  │ 864.52  │ -       │ 684.60 │ 526.46  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 1184.17 │ 1168.88 │ 1074.82 │ 1280.11 │ 640.59  │ 1098.10 │ -       │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 975.96  │ 821.26  │ 878.56  │ 560.33  │ 408.10  │ 779.00  │ 1153.90 │ 223.31 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\3264109635.py:230: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_RF.pkl\"  # RF model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/RF_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load RF model\n",
    "rf_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = rf_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return rf_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d25e4e-5cea-42c0-b654-6969e4a59340",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8ccd86c0-aba3-430c-a44c-5dd19f9c41be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1773838255.py:47: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   2                   3                   4                   5                   6                  7                  8                   9\n",
      "true_label                                                                                                                                                                                    \n",
      "0                              -   26 / 832.9 / 24.5  15 / 1145.0 / 25.2   3 / 1393.6 / 26.0                   -  11 / 1096.6 / 24.7   1 / 884.2 / 24.0  80 / 908.9 / 24.9  26 / 1122.5 / 25.5\n",
      "1              1 / 1018.1 / 25.0   86 / 326.5 / 23.6   61 / 483.9 / 23.8   5 / 1219.9 / 25.6   56 / 489.1 / 23.8  21 / 1223.2 / 25.8  27 / 720.1 / 24.3  99 / 132.4 / 23.1   48 / 473.4 / 23.9\n",
      "2             21 / 1171.7 / 25.3                   -  42 / 1037.9 / 25.0    1 / 982.1 / 25.0   8 / 1118.8 / 25.2   3 / 1302.0 / 26.0  1 / 1447.6 / 26.0  95 / 613.8 / 24.1  11 / 1100.3 / 25.7\n",
      "3             36 / 1134.5 / 25.4  17 / 1004.8 / 24.9                   -                   -   13 / 958.4 / 24.9   2 / 1291.9 / 26.5                  -  92 / 824.2 / 24.7  22 / 1232.6 / 25.6\n",
      "4             17 / 1028.6 / 25.5   36 / 946.6 / 24.7   56 / 789.3 / 24.7                   -   19 / 875.7 / 24.9   26 / 874.1 / 24.9  5 / 1280.9 / 25.6  87 / 746.7 / 24.5   89 / 635.2 / 24.2\n",
      "5             53 / 1039.9 / 25.2    9 / 988.7 / 24.4   74 / 788.9 / 24.4  13 / 1145.0 / 25.2                   -   11 / 946.7 / 24.8  2 / 1167.2 / 25.0  96 / 355.2 / 23.6  27 / 1067.7 / 25.4\n",
      "6              43 / 868.9 / 24.7   42 / 862.3 / 24.5  36 / 1031.3 / 25.0   12 / 862.4 / 25.1  11 / 1041.5 / 24.5                   -   1 / 909.2 / 25.0  96 / 728.2 / 24.5  58 / 1081.4 / 25.4\n",
      "7              54 / 775.9 / 24.5   80 / 239.9 / 23.4   90 / 529.4 / 23.8   12 / 963.8 / 25.0   36 / 802.6 / 24.3   23 / 768.7 / 25.0                  -  81 / 440.5 / 23.7   68 / 564.4 / 23.8\n",
      "8              3 / 1350.9 / 25.7   2 / 1445.5 / 26.0   9 / 1138.8 / 25.4                   -                   -    2 / 897.4 / 24.5                  -                  -   1 / 1513.8 / 26.0\n",
      "9               6 / 693.0 / 24.7  16 / 1041.4 / 25.2   79 / 607.1 / 24.4   77 / 947.3 / 24.9   21 / 658.9 / 24.2  16 / 1161.8 / 25.6   8 / 879.6 / 24.4  96 / 326.4 / 23.7                   -\n",
      "\n",
      "Total successful attacks: 2629 / 8991\n",
      "Stats saved to CSV: adversarial_8bit_images/XGB_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  26 │  15 │   3 │   0 │  11 │   1 │  80 │  26 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   1 │  86 │  61 │   5 │  56 │  21 │  27 │  99 │  48 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  21 │   0 │  42 │   1 │   8 │   3 │   1 │  95 │  11 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  36 │  17 │   0 │   0 │  13 │   2 │   0 │  92 │  22 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  17 │  36 │  56 │   0 │  19 │  26 │   5 │  87 │  89 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  53 │   9 │  74 │  13 │   0 │  11 │   2 │  96 │  27 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  43 │  42 │  36 │  12 │  11 │   0 │   1 │  96 │  58 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  54 │  80 │  90 │  12 │  36 │  23 │   0 │  81 │  68 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   3 │   2 │   9 │   0 │   0 │   2 │   0 │   0 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   6 │  16 │  79 │  77 │  21 │  16 │   8 │  96 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 23.0 │ 24.0 │ 25.0 │ -    │ 23.0 │ 24.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ -    │ 23.0 │ 25.0 │ 24.0 │ 25.0 │ 26.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 23.0 │ -    │ -    │ 23.0 │ 26.0 │ -    │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 24.0 │ 24.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 25.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 25.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.0 │ 25.0 │ 24.0 │ -    │ -    │ 24.0 │ -    │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 24.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ 27.0 │ 25.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ -    │ -    │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 25.0 │ 27.0 │ 26.0 │ -    │ 26.0 │ 25.0 │ 25.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 25.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 26.0 │ 25.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 25.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 27.0 │ 27.0 │ -    │ -    │ 25.0 │ -    │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 25.0 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 24.5 │ 25.2 │ 26.0 │ -    │ 24.7 │ 24.0 │ 24.9 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ 23.6 │ 23.8 │ 25.6 │ 23.8 │ 25.8 │ 24.3 │ 23.1 │ 23.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.3 │ -    │ 25.0 │ 25.0 │ 25.2 │ 26.0 │ 26.0 │ 24.1 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.4 │ 24.9 │ -    │ -    │ 24.9 │ 26.5 │ -    │ 24.7 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.5 │ 24.7 │ 24.7 │ -    │ 24.9 │ 24.9 │ 25.6 │ 24.5 │ 24.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.2 │ 24.4 │ 24.4 │ 25.2 │ -    │ 24.8 │ 25.0 │ 23.6 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.7 │ 24.5 │ 25.0 │ 25.1 │ 24.5 │ -    │ 25.0 │ 24.5 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.5 │ 23.4 │ 23.8 │ 25.0 │ 24.3 │ 25.0 │ -    │ 23.7 │ 23.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.7 │ 26.0 │ 25.4 │ -    │ -    │ 24.5 │ -    │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.7 │ 25.2 │ 24.4 │ 24.9 │ 24.2 │ 25.6 │ 24.4 │ 23.7 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤════════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3      │ 4       │ 5      │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪════════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 220.11  │ 711.85 │ 1227.47 │ -      │ 443.74  │ 884.18  │ 198.60 │ 334.84  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            1 │ 1018.07 │ 36.18   │ 53.03  │ 718.49  │ 70.57  │ 319.11  │ 36.06   │ 33.44  │ 98.61   │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            2 │ 564.70  │ -       │ 299.80 │ 982.11  │ 647.43 │ 1078.29 │ 1447.64 │ 45.21  │ 477.42  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 350.90  │ 146.79  │ -      │ -       │ 54.79  │ 1153.97 │ -       │ 53.79  │ 524.62  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ 515.58  │ 444.43  │ 161.50 │ -       │ 121.26 │ 227.52  │ 1057.48 │ 68.96  │ 34.42   │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 309.88  │ 404.99  │ 103.73 │ 569.23  │ -      │ 391.62  │ 1120.97 │ 33.99  │ 174.59  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 34.16   │ 73.53   │ 494.36 │ 331.01  │ 631.94 │ -       │ 909.25  │ 69.10  │ 602.38  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ 52.07   │ 36.57   │ 90.52  │ 51.50   │ 37.42  │ 312.40  │ -       │ 118.68 │ 115.98  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 1185.95 │ 1388.43 │ 312.84 │ -       │ -      │ 757.63  │ -       │ -      │ 1513.80 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 212.79  │ 389.79  │ 74.14  │ 78.47   │ 35.40  │ 681.55  │ 462.48  │ 42.91  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧════════╧═════════╧═════════╧════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1427.28 │ 1523.25 │ 1517.06 │ -       │ 1519.77 │ 884.18  │ 1485.54 │ 1454.05 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1018.07 │ 1512.41 │ 1520.89 │ 1469.19 │ 1513.18 │ 1513.67 │ 1521.29 │ 440.34  │ 1418.84 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1519.59 │ -       │ 1518.89 │ 982.11  │ 1521.41 │ 1512.75 │ 1447.64 │ 1302.21 │ 1469.68 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1515.83 │ 1516.41 │ -       │ -       │ 1522.70 │ 1429.92 │ -       │ 1499.98 │ 1508.15 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1520.97 │ 1515.58 │ 1453.01 │ -       │ 1516.47 │ 1488.89 │ 1418.50 │ 1518.20 │ 1465.80 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1511.96 │ 1361.49 │ 1400.00 │ 1514.49 │ -       │ 1518.09 │ 1213.52 │ 1074.16 │ 1483.55 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1519.16 │ 1479.91 │ 1512.66 │ 1263.44 │ 1403.16 │ -       │ 909.25  │ 1470.11 │ 1520.73 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1465.26 │ 1369.50 │ 1370.19 │ 1522.62 │ 1519.35 │ 1510.85 │ -       │ 1214.08 │ 1505.95 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1493.63 │ 1502.65 │ 1518.70 │ -       │ -       │ 1037.17 │ -       │ -       │ 1513.80 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1358.53 │ 1506.79 │ 1150.05 │ 1519.05 │ 1518.72 │ 1515.94 │ 1308.63 │ 904.93  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 832.88  │ 1145.03 │ 1393.64 │ -       │ 1096.56 │ 884.18  │ 908.89 │ 1122.47 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            1 │ 1018.07 │ 326.55  │ 483.86  │ 1219.92 │ 489.09  │ 1223.24 │ 720.10  │ 132.37 │ 473.35  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            2 │ 1171.69 │ -       │ 1037.95 │ 982.11  │ 1118.80 │ 1302.05 │ 1447.64 │ 613.78 │ 1100.30 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 1134.50 │ 1004.80 │ -       │ -       │ 958.36  │ 1291.95 │ -       │ 824.22 │ 1232.60 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ 1028.57 │ 946.58  │ 789.26  │ -       │ 875.68  │ 874.12  │ 1280.89 │ 746.71 │ 635.16  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 1039.86 │ 988.66  │ 788.92  │ 1144.97 │ -       │ 946.72  │ 1167.24 │ 355.16 │ 1067.65 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 868.88  │ 862.26  │ 1031.35 │ 862.44  │ 1041.50 │ -       │ 909.25  │ 728.24 │ 1081.40 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ 775.92  │ 239.86  │ 529.41  │ 963.79  │ 802.64  │ 768.67  │ -       │ 440.52 │ 564.38  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 1350.89 │ 1445.54 │ 1138.78 │ -       │ -       │ 897.40  │ -       │ -      │ 1513.80 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 693.01  │ 1041.38 │ 607.06  │ 947.29  │ 658.92  │ 1161.77 │ 879.55  │ 326.45 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\1773838255.py:231: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_XGB.pkl\"  # XGBoost model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/XGB_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load XGBoost model\n",
    "xgb_model: XGBClassifier = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = xgb_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return xgb_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee143d-302a-4df3-8713-48b9786cfbc5",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "138a8157-d73b-4953-b528-24a1cf477df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\668049108.py:47: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                  1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                         \n",
      "0                              -                  -  20 / 1346.5 / 25.7   5 / 1326.6 / 25.6   5 / 1422.9 / 26.6   8 / 1297.6 / 25.5  19 / 1296.2 / 25.5                   -   9 / 1357.1 / 25.9   2 / 1257.9 / 25.5\n",
      "1              7 / 1424.1 / 27.0                  -  97 / 1053.5 / 24.9  99 / 1254.2 / 25.9  83 / 1139.9 / 25.5  54 / 1378.2 / 26.0  95 / 1329.0 / 25.8  99 / 1100.5 / 25.3  100 / 842.0 / 24.4  45 / 1256.3 / 26.0\n",
      "2             13 / 1393.3 / 26.0                  -                   -  42 / 1224.8 / 25.3  10 / 1303.2 / 25.7   5 / 1463.6 / 26.0  44 / 1290.1 / 25.5   3 / 1328.4 / 26.0  74 / 1188.7 / 25.5   5 / 1339.5 / 25.8\n",
      "3             28 / 1327.5 / 26.1  3 / 1328.0 / 26.0  20 / 1331.0 / 25.5                   -  15 / 1344.6 / 26.1  52 / 1269.8 / 25.4   5 / 1349.7 / 25.6   3 / 1224.6 / 25.3  91 / 1092.1 / 25.2  16 / 1290.7 / 25.7\n",
      "4             20 / 1369.1 / 26.3  1 / 1417.9 / 26.0  46 / 1332.8 / 25.8  19 / 1440.3 / 26.6                   -  59 / 1310.7 / 25.7  39 / 1346.3 / 25.8  76 / 1159.0 / 25.3  59 / 1334.2 / 25.8  55 / 1248.3 / 25.7\n",
      "5             80 / 1280.5 / 25.9  1 / 1427.4 / 26.0  35 / 1261.8 / 25.5  87 / 1166.6 / 25.2  36 / 1332.0 / 26.0                   -  25 / 1249.0 / 25.6   4 / 1420.3 / 25.8  95 / 1083.0 / 25.2   5 / 1376.4 / 26.0\n",
      "6             36 / 1287.6 / 25.7  1 / 1389.6 / 26.0  36 / 1340.6 / 25.8  42 / 1279.8 / 25.4   9 / 1273.8 / 25.8  23 / 1346.4 / 25.7                   -   6 / 1476.9 / 26.2  49 / 1258.1 / 25.5   4 / 1424.9 / 26.0\n",
      "7             61 / 1361.9 / 26.0  1 / 1157.5 / 25.0  69 / 1288.8 / 25.3  57 / 1356.2 / 25.5  14 / 1334.0 / 25.9  59 / 1304.7 / 25.7  11 / 1364.8 / 26.0                   -  57 / 1377.4 / 25.9  88 / 1174.1 / 25.3\n",
      "8              7 / 1278.8 / 26.0                  -   9 / 1351.0 / 25.7  74 / 1270.4 / 25.5   9 / 1409.2 / 26.4  18 / 1297.2 / 25.5   9 / 1259.7 / 25.6   5 / 1438.3 / 26.8                   -   4 / 1370.9 / 26.2\n",
      "9             23 / 1348.7 / 26.5  4 / 1014.5 / 25.8  35 / 1314.6 / 26.0  73 / 1283.2 / 25.7  100 / 864.2 / 24.9  63 / 1166.3 / 25.5  16 / 1376.6 / 26.2  71 / 1205.5 / 25.3  96 / 1158.4 / 25.5                   -\n",
      "\n",
      "Total successful attacks: 3157 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/SVM_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │  20 │   5 │   5 │   8 │  19 │   0 │   9 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   7 │   0 │  97 │  99 │  83 │  54 │  95 │  99 │ 100 │  45 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  13 │   0 │   0 │  42 │  10 │   5 │  44 │   3 │  74 │   5 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  28 │   3 │  20 │   0 │  15 │  52 │   5 │   3 │  91 │  16 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  20 │   1 │  46 │  19 │   0 │  59 │  39 │  76 │  59 │  55 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  80 │   1 │  35 │  87 │  36 │   0 │  25 │   4 │  95 │   5 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  36 │   1 │  36 │  42 │   9 │  23 │   0 │   6 │  49 │   4 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  61 │   1 │  69 │  57 │  14 │  59 │  11 │   0 │  57 │  88 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   7 │   0 │   9 │  74 │   9 │  18 │   9 │   5 │   0 │   4 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  23 │   4 │  35 │  73 │ 100 │  63 │  16 │  71 │  96 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.0 │ 25.0 │ 26.0 │ 24.0 │ 25.0 │ -    │ 25.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 26.0 │ 25.0 │ 24.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ -    │ -    │ 24.0 │ 25.0 │ 26.0 │ 24.0 │ 25.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 25.0 │ 24.0 │ -    │ 25.0 │ 23.0 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 26.0 │ 24.0 │ 26.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 26.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 26.0 │ 25.0 │ 24.0 │ 25.0 │ 25.0 │ -    │ 26.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.0 │ -    │ 25.0 │ 24.0 │ 26.0 │ 24.0 │ 24.0 │ 26.0 │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 25.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 25.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.7 │ 25.6 │ 26.6 │ 25.5 │ 25.5 │ -    │ 25.9 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 24.9 │ 25.9 │ 25.5 │ 26.0 │ 25.8 │ 25.3 │ 24.4 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.0 │ -    │ -    │ 25.3 │ 25.7 │ 26.0 │ 25.5 │ 26.0 │ 25.5 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.1 │ 26.0 │ 25.5 │ -    │ 26.1 │ 25.4 │ 25.6 │ 25.3 │ 25.2 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.3 │ 26.0 │ 25.8 │ 26.6 │ -    │ 25.7 │ 25.8 │ 25.3 │ 25.8 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ 26.0 │ 25.5 │ 25.2 │ 26.0 │ -    │ 25.6 │ 25.8 │ 25.2 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.7 │ 26.0 │ 25.8 │ 25.4 │ 25.8 │ 25.7 │ -    │ 26.2 │ 25.5 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 25.0 │ 25.3 │ 25.5 │ 25.9 │ 25.7 │ 26.0 │ -    │ 25.9 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ -    │ 25.7 │ 25.5 │ 26.4 │ 25.5 │ 25.6 │ 26.8 │ -    │ 26.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.5 │ 25.8 │ 26.0 │ 25.7 │ 24.9 │ 25.5 │ 26.2 │ 25.3 │ 25.5 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1027.51 │ 1176.30 │ 1372.90 │ 840.35  │ 829.16  │ -       │ 1117.88 │ 1020.96 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1385.84 │ -       │ 667.70  │ 983.27  │ 752.16  │ 1110.08 │ 878.17  │ 747.83  │ 618.68  │ 999.08  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1043.26 │ -       │ -       │ 538.25  │ 1054.22 │ 1410.69 │ 683.88  │ 951.28  │ 441.14  │ 1192.46 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 759.12  │ 1130.52 │ 869.63  │ -       │ 1064.12 │ 346.20  │ 1268.21 │ 1071.83 │ 479.96  │ 854.30  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1020.79 │ 1417.85 │ 871.54  │ 1284.73 │ -       │ 736.91  │ 976.40  │ 578.70  │ 992.05  │ 463.15  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 845.39  │ 1427.39 │ 824.15  │ 471.42  │ 971.47  │ -       │ 840.58  │ 1219.73 │ 508.51  │ 1290.68 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 699.08  │ 1389.61 │ 888.99  │ 925.60  │ 748.02  │ 1034.89 │ -       │ 1385.53 │ 654.68  │ 1383.39 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 919.87  │ 1157.51 │ 706.44  │ 953.99  │ 897.49  │ 704.50  │ 1170.83 │ -       │ 977.86  │ 664.76  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 936.00  │ -       │ 1192.71 │ 420.15  │ 1174.14 │ 520.97  │ 618.13  │ 1281.67 │ -       │ 1218.01 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 820.02  │ 491.19  │ 891.03  │ 562.25  │ 352.85  │ 351.90  │ 1050.80 │ 705.86  │ 544.66  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1525.14 │ 1520.91 │ 1456.96 │ 1520.84 │ 1519.98 │ -       │ 1512.03 │ 1494.90 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1496.35 │ -       │ 1476.26 │ 1493.03 │ 1516.66 │ 1522.28 │ 1522.76 │ 1506.47 │ 1086.56 │ 1510.72 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1523.25 │ -       │ -       │ 1523.59 │ 1498.01 │ 1523.02 │ 1523.45 │ 1521.72 │ 1523.66 │ 1507.20 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1513.01 │ 1479.83 │ 1523.85 │ -       │ 1519.48 │ 1522.07 │ 1490.26 │ 1518.05 │ 1496.17 │ 1490.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1514.21 │ 1417.85 │ 1523.94 │ 1522.20 │ -       │ 1521.96 │ 1524.27 │ 1521.39 │ 1517.94 │ 1517.89 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1519.14 │ 1427.39 │ 1517.56 │ 1516.43 │ 1517.63 │ -       │ 1518.18 │ 1522.67 │ 1491.80 │ 1492.57 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1515.59 │ 1389.61 │ 1521.10 │ 1518.80 │ 1523.73 │ 1520.58 │ -       │ 1510.66 │ 1516.17 │ 1465.52 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1519.96 │ 1157.51 │ 1524.87 │ 1521.18 │ 1523.44 │ 1522.61 │ 1505.92 │ -       │ 1521.87 │ 1515.83 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1485.93 │ -       │ 1522.03 │ 1524.25 │ 1521.43 │ 1522.51 │ 1514.34 │ 1500.97 │ -       │ 1458.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1498.42 │ 1469.88 │ 1517.51 │ 1521.39 │ 1452.01 │ 1516.33 │ 1520.01 │ 1518.73 │ 1512.86 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1346.49 │ 1326.63 │ 1422.93 │ 1297.64 │ 1296.18 │ -       │ 1357.11 │ 1257.93 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1424.10 │ -       │ 1053.53 │ 1254.23 │ 1139.87 │ 1378.24 │ 1329.03 │ 1100.51 │ 841.99  │ 1256.34 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1393.34 │ -       │ -       │ 1224.79 │ 1303.17 │ 1463.57 │ 1290.11 │ 1328.44 │ 1188.73 │ 1339.53 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1327.54 │ 1328.05 │ 1330.96 │ -       │ 1344.62 │ 1269.77 │ 1349.70 │ 1224.64 │ 1092.07 │ 1290.68 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1369.15 │ 1417.85 │ 1332.84 │ 1440.35 │ -       │ 1310.69 │ 1346.26 │ 1158.98 │ 1334.24 │ 1248.30 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1280.52 │ 1427.39 │ 1261.81 │ 1166.56 │ 1332.02 │ -       │ 1249.00 │ 1420.33 │ 1083.00 │ 1376.35 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1287.59 │ 1389.61 │ 1340.63 │ 1279.83 │ 1273.80 │ 1346.40 │ -       │ 1476.95 │ 1258.10 │ 1424.92 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1361.92 │ 1157.51 │ 1288.83 │ 1356.17 │ 1333.96 │ 1304.70 │ 1364.78 │ -       │ 1377.36 │ 1174.10 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1278.80 │ -       │ 1350.96 │ 1270.40 │ 1409.25 │ 1297.18 │ 1259.66 │ 1438.35 │ -       │ 1370.93 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1348.65 │ 1014.47 │ 1314.64 │ 1283.18 │ 864.21  │ 1166.32 │ 1376.64 │ 1205.51 │ 1158.41 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_14700\\668049108.py:231: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_SVM.pkl\"  # SVM model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/SVM_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load SVM model\n",
    "svc_model: SVC = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = svc_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return svc_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdb7ca-f707-4943-9674-5a177aada2a0",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e561b7-0f3b-4768-bb25-6beb84d3cc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_12212\\25403933.py:46: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                  0                  1                  3                  4                 5                  6                  7                  8                  9\n",
      "true_label                                                                                                                                                                            \n",
      "2             1 / 1449.7 / 26.0                  -                  -                  -                 -                  -  1 / 1485.6 / 27.0                  -                  -\n",
      "3                             -  1 / 1340.8 / 27.0                  -                  -                 -                  -  1 / 1442.7 / 26.0  4 / 1181.2 / 25.5  1 / 1328.5 / 26.0\n",
      "4                             -  2 / 1423.2 / 26.0                  -                  -                 -                  -                  -                  -  3 / 1172.0 / 25.3\n",
      "5             2 / 1476.1 / 26.0                  -                  -                  -                 -  2 / 1273.2 / 25.5                  -                  -                  -\n",
      "6             1 / 1088.6 / 25.0                  -                  -                  -                 -                  -                  -                  -                  -\n",
      "7                             -                  -                  -                  -                 -                  -                  -                  -  2 / 1096.6 / 25.5\n",
      "8             1 / 1512.3 / 26.0  2 / 1214.6 / 26.0  4 / 1171.5 / 25.5                  -  4 / 713.0 / 24.2   1 / 906.4 / 25.0                  -                  -  1 / 1080.4 / 25.0\n",
      "9             1 / 1321.4 / 26.0   1 / 707.9 / 24.0                  -  6 / 1239.4 / 25.8                 -                  -  7 / 1200.8 / 25.1                  -                  -\n",
      "\n",
      "Total successful attacks: 49 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/kNN_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            2 │   1 │   0 │   0 │   0 │   0 │   0 │   1 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │   0 │   1 │   0 │   0 │   0 │   0 │   1 │   4 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   0 │   2 │   0 │   0 │   0 │   0 │   0 │   0 │   3 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │   2 │   0 │   0 │   0 │   0 │   2 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │   1 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   1 │   2 │   4 │   0 │   4 │   1 │   0 │   0 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   1 │   1 │   0 │   6 │   0 │   0 │   7 │   0 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            2 │ 26.0 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ -    │ 27.0 │ -    │ -    │ -    │ -    │ 26.0 │ 25.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 26.0 │ -    │ -    │ -    │ -    │ -    │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ -    │ -    │ -    │ -    │ 25.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.0 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 26.0 │ 24.0 │ -    │ 23.0 │ 25.0 │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.0 │ 24.0 │ -    │ 24.0 │ -    │ -    │ 24.0 │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            2 │ 26.0 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ -    │ 27.0 │ -    │ -    │ -    │ -    │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 26.0 │ -    │ -    │ -    │ -    │ -    │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ -    │ -    │ -    │ -    │ 26.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.0 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 26.0 │ 26.0 │ -    │ 26.0 │ 25.0 │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.0 │ 24.0 │ -    │ 27.0 │ -    │ -    │ 26.0 │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            2 │ 26.0 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ -    │ 27.0 │ -    │ -    │ -    │ -    │ 26.0 │ 25.5 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 26.0 │ -    │ -    │ -    │ -    │ -    │ -    │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ -    │ -    │ -    │ -    │ 25.5 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.0 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 26.0 │ 25.5 │ -    │ 24.2 │ 25.0 │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.0 │ 24.0 │ -    │ 25.8 │ -    │ -    │ 25.1 │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤════════╤═══════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 3      │ 4      │ 5     │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪════════╪════════╪═══════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            2 │ 1449.69 │ -       │ -      │ -      │ -     │ -       │ 1485.56 │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ -       │ 1340.76 │ -      │ -      │ -     │ -       │ 1442.70 │ 775.39 │ 1328.54 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ -       │ 1389.36 │ -      │ -      │ -     │ -       │ -       │ -      │ 763.41  │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 1437.60 │ -       │ -      │ -      │ -     │ 1039.53 │ -       │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 1088.59 │ -       │ -      │ -      │ -     │ -       │ -       │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ -       │ -       │ -      │ -      │ -     │ -       │ -       │ -      │ 934.63  │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 1512.31 │ 1113.76 │ 323.72 │ -      │ 55.41 │ 906.35  │ -       │ -      │ 1080.39 │\n",
      "├──────────────┼─────────┼─────────┼────────┼────────┼───────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 1321.45 │ 707.94  │ -      │ 561.78 │ -     │ -       │ 651.26  │ -      │ -       │\n",
      "╘══════════════╧═════════╧═════════╧════════╧════════╧═══════╧═════════╧═════════╧════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            2 │ 1449.69 │ -       │ -       │ -       │ -       │ -       │ 1485.56 │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ -       │ 1340.76 │ -       │ -       │ -       │ -       │ 1442.70 │ 1522.54 │ 1328.54 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1457.11 │ -       │ -       │ -       │ -       │ -       │ -       │ 1403.95 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1514.59 │ -       │ -       │ -       │ -       │ 1506.79 │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1088.59 │ -       │ -       │ -       │ -       │ -       │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ -       │ -       │ -       │ -       │ -       │ -       │ -       │ 1258.50 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1512.31 │ 1315.50 │ 1501.55 │ -       │ 1236.39 │ 906.35  │ -       │ -       │ 1080.39 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1321.45 │ 707.94  │ -       │ 1498.69 │ -       │ -       │ 1477.90 │ -       │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 3       │ 4       │ 5      │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            2 │ 1449.69 │ -       │ -       │ -       │ -      │ -       │ 1485.56 │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ -       │ 1340.76 │ -       │ -       │ -      │ -       │ 1442.70 │ 1181.15 │ 1328.54 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1423.24 │ -       │ -       │ -      │ -       │ -       │ -       │ 1172.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1476.10 │ -       │ -       │ -       │ -      │ 1273.16 │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1088.59 │ -       │ -       │ -       │ -      │ -       │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ -       │ -       │ -       │ -      │ -       │ -       │ -       │ 1096.57 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1512.31 │ 1214.63 │ 1171.48 │ -       │ 713.02 │ 906.35  │ -       │ -       │ 1080.39 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1321.45 │ 707.94  │ -       │ 1239.40 │ -      │ -       │ 1200.76 │ -       │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_12212\\25403933.py:231: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_kNN.pkl\"  # changed model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/kNN_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load kNN model\n",
    "knn_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = knn_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return knn_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eced1cb-1caa-4812-b4fa-afbf52412d48",
   "metadata": {},
   "source": [
    "### MLP1L - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfbc820-d805-4edd-9257-a148742367df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_8396\\901619835.py:51: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                 0                 1                 2                  3                 4                 5                 6                  7                 9\n",
      "true_label                                                                                                                                                                      \n",
      "0                            -                 -                 -                  -                 -  1 / 726.3 / 27.0  1 / 708.9 / 27.0   1 / 689.8 / 27.0                 -\n",
      "1                            -                 -                 -  63 / 531.6 / 26.1                 -  8 / 593.2 / 26.4                 -   6 / 561.3 / 25.8                 -\n",
      "2                            -  4 / 563.2 / 26.8                 -  13 / 522.5 / 25.9                 -                 -  3 / 666.3 / 26.7   2 / 627.0 / 26.0                 -\n",
      "3                            -                 -                 -                  -                 -  3 / 580.0 / 26.3                 -   2 / 593.7 / 26.0                 -\n",
      "4                            -                 -                 -   4 / 634.0 / 26.8                 -  6 / 613.9 / 26.3  6 / 668.4 / 26.5  17 / 568.6 / 25.6                 -\n",
      "5                            -                 -                 -   7 / 534.9 / 25.9                 -                 -                 -   2 / 632.2 / 26.0                 -\n",
      "6                            -                 -                 -   8 / 575.6 / 26.4                 -  7 / 633.4 / 26.4                 -   1 / 530.4 / 25.0                 -\n",
      "7                            -  1 / 446.5 / 26.0                 -   9 / 570.9 / 26.3                 -  4 / 601.8 / 26.2                 -                  -                 -\n",
      "8             1 / 608.4 / 27.0  2 / 495.2 / 26.0  6 / 597.8 / 26.3  36 / 531.8 / 25.8                 -  2 / 501.0 / 25.5  3 / 555.2 / 26.0  15 / 602.3 / 25.8  6 / 426.4 / 25.3\n",
      "9                            -                 -                 -   3 / 489.5 / 25.7  7 / 428.1 / 25.3  6 / 645.7 / 26.7  1 / 737.3 / 27.0  15 / 646.3 / 26.4                 -\n",
      "\n",
      "Total successful attacks: 282 / 8991\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1LSca_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │   0 │   0 │   0 │   1 │   1 │   1 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   0 │   0 │   0 │  63 │   0 │   8 │   0 │   6 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │   0 │   4 │   0 │  13 │   0 │   0 │   3 │   2 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │   0 │   0 │   0 │   0 │   0 │   3 │   0 │   2 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   0 │   0 │   0 │   4 │   0 │   6 │   6 │  17 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │   0 │   0 │   0 │   7 │   0 │   0 │   0 │   2 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │   0 │   0 │   0 │   8 │   0 │   7 │   0 │   1 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │   0 │   1 │   0 │   9 │   0 │   4 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   1 │   2 │   6 │  36 │   0 │   2 │   3 │  15 │   6 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   0 │   0 │   0 │   3 │   7 │   6 │   1 │  15 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ -    │ 25.0 │ -    │ 25.0 │ -    │ 24.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ 26.0 │ -    │ 23.0 │ -    │ -    │ 26.0 │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ -    │ -    │ -    │ -    │ -    │ 25.0 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ -    │ -    │ 26.0 │ -    │ 24.0 │ 26.0 │ 24.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ -    │ -    │ -    │ 24.0 │ -    │ -    │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ -    │ 25.0 │ -    │ 25.0 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 26.0 │ -    │ 26.0 │ -    │ 26.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 25.0 │ 25.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ -    │ -    │ 25.0 │ 24.0 │ 25.0 │ 27.0 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ -    │ 27.0 │ -    │ 27.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ 27.0 │ -    │ 27.0 │ -    │ -    │ 27.0 │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ -    │ -    │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ -    │ -    │ -    │ 27.0 │ -    │ -    │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ -    │ 27.0 │ -    │ 27.0 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 26.0 │ -    │ 27.0 │ -    │ 27.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ -    │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ -    │ -    │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ -    │ 26.1 │ -    │ 26.4 │ -    │ 25.8 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ 26.8 │ -    │ 25.9 │ -    │ -    │ 26.7 │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ -    │ -    │ -    │ -    │ -    │ 26.3 │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ -    │ -    │ 26.8 │ -    │ 26.3 │ 26.5 │ 25.6 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ -    │ -    │ -    │ 25.9 │ -    │ -    │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ -    │ 26.4 │ -    │ 26.4 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 26.0 │ -    │ 26.3 │ -    │ 26.2 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 26.0 │ 26.3 │ 25.8 │ -    │ 25.5 │ 26.0 │ 25.8 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ -    │ -    │ 25.7 │ 25.3 │ 26.7 │ 27.0 │ 26.4 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4      │ 5      │ 6      │ 7      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ -      │ -      │ -      │ -      │ 726.30 │ 708.88 │ 689.79 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ -      │ -      │ -      │ 396.38 │ -      │ 420.13 │ -      │ 326.90 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ -      │ 494.27 │ -      │ 108.76 │ -      │ -      │ 601.02 │ 612.98 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ -      │ -      │ -      │ -      │ -      │ 420.37 │ -      │ 502.18 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ -      │ -      │ -      │ 580.14 │ -      │ 368.25 │ 563.52 │ 312.82 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ -      │ -      │ -      │ 338.45 │ -      │ -      │ -      │ 522.44 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ -      │ -      │ -      │ 423.30 │ -      │ 519.89 │ -      │ 530.36 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ -      │ 446.53 │ -      │ 492.71 │ -      │ 560.40 │ -      │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 608.41 │ 372.90 │ 433.44 │ 263.73 │ -      │ 332.51 │ 382.30 │ 353.55 │ 194.44 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ -      │ -      │ -      │ 423.62 │ 329.11 │ 475.65 │ 737.30 │ 445.49 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4      │ 5      │ 6      │ 7      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ -      │ -      │ -      │ -      │ 726.30 │ 708.88 │ 689.79 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ -      │ -      │ -      │ 626.97 │ -      │ 706.92 │ -      │ 670.17 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ -      │ 588.19 │ -      │ 664.14 │ -      │ -      │ 745.24 │ 640.93 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ -      │ -      │ -      │ -      │ -      │ 672.95 │ -      │ 685.29 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ -      │ -      │ -      │ 671.51 │ -      │ 690.93 │ 736.69 │ 761.51 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ -      │ -      │ -      │ 648.63 │ -      │ -      │ -      │ 741.91 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ -      │ -      │ -      │ 648.23 │ -      │ 715.87 │ -      │ 530.36 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ -      │ 446.53 │ -      │ 666.14 │ -      │ 651.72 │ -      │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 608.41 │ 617.48 │ 665.48 │ 680.67 │ -      │ 669.52 │ 700.39 │ 763.07 │ 611.24 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ -      │ -      │ -      │ 573.30 │ 587.70 │ 707.75 │ 737.30 │ 768.67 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4      │ 5      │ 6      │ 7      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ -      │ -      │ -      │ -      │ 726.30 │ 708.88 │ 689.79 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ -      │ -      │ -      │ 531.64 │ -      │ 593.21 │ -      │ 561.27 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ -      │ 563.21 │ -      │ 522.50 │ -      │ -      │ 666.30 │ 626.95 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ -      │ -      │ -      │ -      │ -      │ 580.00 │ -      │ 593.74 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ -      │ -      │ -      │ 633.98 │ -      │ 613.94 │ 668.42 │ 568.60 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ -      │ -      │ -      │ 534.91 │ -      │ -      │ -      │ 632.18 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ -      │ -      │ -      │ 575.60 │ -      │ 633.38 │ -      │ 530.36 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ -      │ 446.53 │ -      │ 570.90 │ -      │ 601.81 │ -      │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 608.41 │ 495.19 │ 597.80 │ 531.78 │ -      │ 501.02 │ 555.15 │ 602.31 │ 426.40 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ -      │ -      │ -      │ 489.53 │ 428.08 │ 645.74 │ 737.30 │ 646.26 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_8396\\901619835.py:243: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1LSca.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1LSca_test\"\n",
    "SCALER_PATH = r\"Models and Data splits/scaler.pkl\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (standardized domain) ───────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "# ─────────── HELPERS ──────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ─────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X_raw, y, _ = data\n",
    "\n",
    "if X_raw.max() > 1.0:\n",
    "    X_raw = X_raw.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "scaler = joblib.load(SCALER_PATH) if os.path.exists(SCALER_PATH) else StandardScaler().fit(X_raw)\n",
    "X = scaler.transform(X_raw)\n",
    "if not os.path.exists(SCALER_PATH):\n",
    "    joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x_std: np.ndarray) -> torch.Tensor:\n",
    "    flat = x_std.reshape(-1) if x_std.ndim == 2 else x_std\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_scaled: np.ndarray, x_clean_scaled: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = scaler.inverse_transform(x_scaled.reshape(1, -1)).reshape(28, 28) * 255.0\n",
    "    x_orig = scaler.inverse_transform(x_clean_scaled.reshape(1, -1)).reshape(28, 28) * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = x + EPSILON * np.sign(grad.reshape(x.shape))\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = x0 + mid * d\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = x0 + best * d\n",
    "\n",
    "            delta = scaler.inverse_transform((x_best - x0).reshape(1, -1)) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best, x0)\n",
    "            x_uint8_flat = x_uint8.reshape(1, -1).astype(np.float32) / 255.0\n",
    "            x_uint8_std = scaler.transform(x_uint8_flat)\n",
    "\n",
    "            if model_query(to_model(x_uint8_std)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8_std)).argmax().item())\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - scaler.inverse_transform(x0.reshape(1, -1)).reshape(28,28) * 255.0)\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "if not df.empty and all(col in df.columns for col in ['true_label', 'target_label']):\n",
    "    pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "        success_count=('success', 'sum'),\n",
    "        mean_l2=('l2_mag', 'mean'),\n",
    "        mean_queries=('queries', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    pivot_data['cell'] = pivot_data.apply(\n",
    "        lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "    matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "    print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "    print(matrix.to_string())\n",
    "\n",
    "    count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "    plt.title(\"Targeted Attack Success Count\")\n",
    "    plt.xlabel(\"Target Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "    plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21133e-63e4-46c0-b113-57e99a67ad4f",
   "metadata": {},
   "source": [
    "### CNN - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5df684a-0f6b-4b18-bd3b-eede347bdd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_10388\\372572345.py:51: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                 2                  3                 5                 6                 9\n",
      "true_label                                                                                             \n",
      "5                            -  11 / 632.0 / 26.9                 -                 -                 -\n",
      "6                            -                  -  2 / 659.0 / 27.0                 -                 -\n",
      "7             1 / 172.7 / 23.0                  -                 -                 -  1 / 374.6 / 25.0\n",
      "8                            -   1 / 665.5 / 27.0                 -  1 / 166.8 / 23.0                 -\n",
      "9                            -   3 / 564.6 / 26.7                 -                 -                 -\n",
      "\n",
      "Total successful attacks: 20 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/CNNSca_test\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   2 │   3 │   5 │   6 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            5 │   0 │  11 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │   0 │   0 │   2 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │   1 │   0 │   0 │   0 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   0 │   1 │   0 │   1 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   0 │   3 │   0 │   0 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 2    │ 3    │ 5    │ 6    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            5 │ -    │ 26.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ 27.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ -    │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 27.0 │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ 26.0 │ -    │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 2    │ 3    │ 5    │ 6    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            5 │ -    │ 27.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ 27.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ -    │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 27.0 │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ 27.0 │ -    │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 2    │ 3    │ 5    │ 6    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            5 │ -    │ 26.9 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ 27.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ -    │ -    │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 27.0 │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ 26.7 │ -    │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 2      │ 3      │ 5      │ 6      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            5 │ -      │ 553.82 │ -      │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ -      │ -      │ 652.01 │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 172.66 │ -      │ -      │ -      │ 374.63 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ -      │ 665.53 │ -      │ 166.79 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ -      │ 507.32 │ -      │ -      │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 2      │ 3      │ 5      │ 6      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            5 │ -      │ 672.47 │ -      │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ -      │ -      │ 665.92 │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 172.66 │ -      │ -      │ -      │ 374.63 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ -      │ 665.53 │ -      │ 166.79 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ -      │ 598.84 │ -      │ -      │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 2      │ 3      │ 5      │ 6      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            5 │ -      │ 632.04 │ -      │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ -      │ -      │ 658.96 │ -      │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 172.66 │ -      │ -      │ -      │ 374.63 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ -      │ 665.53 │ -      │ 166.79 │ -      │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ -      │ 564.59 │ -      │ -      │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_10388\\372572345.py:243: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_CNNSca.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_test.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/CNNSca_test\"\n",
    "SCALER_PATH = r\"Models and Data splits/scaler.pkl\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (standardized domain) ───────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "# ─────────── HELPERS ──────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ─────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X_raw, y, _ = data\n",
    "\n",
    "if X_raw.max() > 1.0:\n",
    "    X_raw = X_raw.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "scaler = joblib.load(SCALER_PATH) if os.path.exists(SCALER_PATH) else StandardScaler().fit(X_raw)\n",
    "X = scaler.transform(X_raw)\n",
    "if not os.path.exists(SCALER_PATH):\n",
    "    joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x_std: np.ndarray) -> torch.Tensor:\n",
    "    return torch.from_numpy(x_std.reshape(1, 1, 28, 28)).float()\n",
    "\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_scaled: np.ndarray, x_clean_scaled: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = scaler.inverse_transform(x_scaled.reshape(1, -1)).reshape(28, 28) * 255.0\n",
    "    x_orig = scaler.inverse_transform(x_clean_scaled.reshape(1, -1)).reshape(28, 28) * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = x + EPSILON * np.sign(grad.reshape(x.shape))\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = x0 + mid * d\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = x0 + best * d\n",
    "\n",
    "            delta = scaler.inverse_transform((x_best - x0).reshape(1, -1)) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best, x0)\n",
    "            x_uint8_flat = x_uint8.reshape(1, -1).astype(np.float32) / 255.0\n",
    "            x_uint8_std = scaler.transform(x_uint8_flat)\n",
    "\n",
    "            if model_query(to_model(x_uint8_std)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8_std)).argmax().item())\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - scaler.inverse_transform(x0.reshape(1, -1)).reshape(28,28) * 255.0)\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "if not df.empty and all(col in df.columns for col in ['true_label', 'target_label']):\n",
    "    pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "        success_count=('success', 'sum'),\n",
    "        mean_l2=('l2_mag', 'mean'),\n",
    "        mean_queries=('queries', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    pivot_data['cell'] = pivot_data.apply(\n",
    "        lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "    matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "    print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "    print(matrix.to_string())\n",
    "\n",
    "    count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "    plt.title(\"Targeted Attack Success Count\")\n",
    "    plt.xlabel(\"Target Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "    plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPUEnabled]",
   "language": "python",
   "name": "conda-env-GPUEnabled-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
