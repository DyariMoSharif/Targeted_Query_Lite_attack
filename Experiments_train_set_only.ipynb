{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b95dc6-8822-4827-93aa-e4dd25673e8d",
   "metadata": {},
   "source": [
    "# Proposed Approach implementation on the sampled data\n",
    "## -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322a1bb-f1ee-4af2-83b2-f51ca018d26d",
   "metadata": {},
   "source": [
    "## -----  MLP1L -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f1876-defc-4da8-a823-d790b892e8dc",
   "metadata": {},
   "source": [
    "### MLP1L - 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9d9d9a9-a624-4c93-8edd-d5e10779fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\4212413037.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -  66 / 1169.1 / 26.4   99 / 832.8 / 24.4  92 / 1056.1 / 24.9  79 / 1139.9 / 25.8  100 / 780.1 / 24.1  100 / 572.1 / 24.1  100 / 739.2 / 24.5  55 / 1207.0 / 25.5  100 / 795.9 / 24.6\n",
      "1              98 / 966.5 / 25.9                   -  100 / 457.7 / 23.4  100 / 474.1 / 23.5   98 / 820.1 / 24.8  100 / 644.5 / 24.1  100 / 372.5 / 23.6  100 / 322.2 / 23.4  100 / 539.1 / 23.8  100 / 405.9 / 23.6\n",
      "2             78 / 1121.8 / 25.5   3 / 1084.7 / 26.3                   -   76 / 930.0 / 24.6  48 / 1159.3 / 25.7  24 / 1262.0 / 25.8   96 / 824.3 / 24.8   99 / 778.8 / 25.0  56 / 1076.6 / 25.1   96 / 985.2 / 25.4\n",
      "3             90 / 1072.9 / 25.5   98 / 855.8 / 25.2  100 / 735.4 / 24.4                   -  83 / 1151.1 / 25.7  100 / 618.8 / 23.9  97 / 1085.4 / 25.6  100 / 727.5 / 24.4  53 / 1094.2 / 25.2  100 / 721.6 / 24.6\n",
      "4             56 / 1269.6 / 26.0  89 / 1056.1 / 25.9  100 / 708.2 / 24.2   95 / 967.5 / 25.0                   -  100 / 721.5 / 24.3  100 / 413.5 / 23.5  100 / 520.8 / 23.8   97 / 991.0 / 24.9   27 / 980.1 / 25.0\n",
      "5             99 / 1052.3 / 25.3  100 / 771.7 / 25.2  100 / 874.6 / 24.8   98 / 841.1 / 24.5  68 / 1098.5 / 25.4                   -   96 / 975.8 / 25.1   98 / 879.7 / 25.2  55 / 1217.7 / 25.4   93 / 951.6 / 25.1\n",
      "6             14 / 1179.0 / 25.4  31 / 1090.0 / 25.8   99 / 646.6 / 23.9   72 / 865.3 / 24.6   99 / 850.6 / 24.7   97 / 785.4 / 24.4                   -   99 / 671.8 / 24.5  27 / 1131.5 / 25.2  100 / 775.0 / 24.6\n",
      "7             60 / 1190.0 / 25.7  78 / 1058.1 / 25.7  100 / 620.5 / 24.1   52 / 952.3 / 24.6  20 / 1197.0 / 25.4  100 / 752.8 / 24.3  100 / 880.2 / 25.3                   -  20 / 1010.5 / 24.8  100 / 737.2 / 24.2\n",
      "8             100 / 830.2 / 25.2   89 / 785.9 / 25.2   99 / 500.5 / 23.8  100 / 484.5 / 23.9  97 / 1038.0 / 25.5  100 / 705.8 / 24.3  100 / 672.7 / 24.6  100 / 617.3 / 24.6                   -  100 / 599.6 / 24.3\n",
      "9             91 / 1112.2 / 26.0   69 / 913.1 / 26.0  100 / 647.8 / 24.5  100 / 561.1 / 24.1  100 / 421.0 / 23.6  100 / 615.3 / 24.2  100 / 712.5 / 24.9  100 / 454.4 / 23.6  100 / 835.2 / 24.7                   -\n",
      "\n",
      "Total successful attacks: 7668 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_32_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  66 │  99 │  92 │  79 │ 100 │ 100 │ 100 │  55 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  98 │   0 │ 100 │ 100 │  98 │ 100 │ 100 │ 100 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  78 │   3 │   0 │  76 │  48 │  24 │  96 │  99 │  56 │  96 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  90 │  98 │ 100 │   0 │  83 │ 100 │  97 │ 100 │  53 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  56 │  89 │ 100 │  95 │   0 │ 100 │ 100 │ 100 │  97 │  27 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  99 │ 100 │ 100 │  98 │  68 │   0 │  96 │  98 │  55 │  93 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  14 │  31 │  99 │  72 │  99 │  97 │   0 │  99 │  27 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  60 │  78 │ 100 │  52 │  20 │ 100 │ 100 │   0 │  20 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │ 100 │  89 │  99 │ 100 │  97 │ 100 │ 100 │ 100 │   0 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  91 │  69 │ 100 │ 100 │ 100 │ 100 │ 100 │ 100 │ 100 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 25.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 24.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 23.0 │ 26.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 25.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 24.0 │ 26.0 │ 27.0 │ 25.0 │ 25.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 26.0 │ 25.0 │ 25.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 25.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.4 │ 24.4 │ 24.9 │ 25.8 │ 24.1 │ 24.1 │ 24.5 │ 25.5 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.9 │ -    │ 23.4 │ 23.5 │ 24.8 │ 24.1 │ 23.6 │ 23.4 │ 23.8 │ 23.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.5 │ 26.3 │ -    │ 24.6 │ 25.7 │ 25.8 │ 24.8 │ 25.0 │ 25.1 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.5 │ 25.2 │ 24.4 │ -    │ 25.7 │ 23.9 │ 25.6 │ 24.4 │ 25.2 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ 25.9 │ 24.2 │ 25.0 │ -    │ 24.3 │ 23.5 │ 23.8 │ 24.9 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.3 │ 25.2 │ 24.8 │ 24.5 │ 25.4 │ -    │ 25.1 │ 25.2 │ 25.4 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.4 │ 25.8 │ 23.9 │ 24.6 │ 24.7 │ 24.4 │ -    │ 24.5 │ 25.2 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.7 │ 25.7 │ 24.1 │ 24.6 │ 25.4 │ 24.3 │ 25.3 │ -    │ 24.8 │ 24.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.2 │ 25.2 │ 23.8 │ 23.9 │ 25.5 │ 24.3 │ 24.6 │ 24.6 │ -    │ 24.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.0 │ 26.0 │ 24.5 │ 24.1 │ 23.6 │ 24.2 │ 25.0 │ 23.6 │ 24.7 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4      │ 5      │ 6      │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ 647.96 │ 200.98 │ 459.53 │ 599.47 │ 286.79 │ 227.92 │ 233.64 │ 322.48 │ 150.44 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ 629.72 │ -      │ 163.63 │ 212.26 │ 393.57 │ 331.06 │ 118.41 │ 70.96  │ 229.34 │ 113.83 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ 248.31 │ 477.55 │ -      │ 317.48 │ 489.20 │ 471.58 │ 159.48 │ 243.17 │ 506.24 │ 396.75 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ 281.20 │ 179.78 │ 114.83 │ -      │ 172.77 │ 89.76  │ 577.05 │ 109.07 │ 323.99 │ 86.94  │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ 603.93 │ 361.21 │ 127.49 │ 482.65 │ -      │ 269.19 │ 139.77 │ 197.20 │ 461.07 │ 151.69 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ 506.71 │ 225.77 │ 329.68 │ 368.71 │ 297.89 │ -      │ 216.95 │ 296.32 │ 548.28 │ 214.81 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ 816.51 │ 687.68 │ 253.20 │ 417.23 │ 152.43 │ 199.17 │ -      │ 213.45 │ 608.67 │ 313.73 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 685.88 │ 296.81 │ 145.04 │ 239.74 │ 718.46 │ 286.52 │ 426.18 │ -      │ 585.84 │ 221.98 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 308.54 │ 143.63 │ 110.09 │ 110.75 │ 300.42 │ 175.86 │ 157.20 │ 213.80 │ -      │ 128.49 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ 331.79 │ 317.64 │ 199.46 │ 139.75 │ 114.47 │ 107.13 │ 273.90 │ 162.63 │ 407.56 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1513.98 │ 1468.63 │ 1496.60 │ 1517.85 │ 1291.72 │ 1215.44 │ 1230.36 │ 1524.35 │ 1458.50 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1247.89 │ -       │ 785.76  │ 977.29  │ 1419.47 │ 976.68  │ 758.88  │ 692.90  │ 1502.48 │ 799.26  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1517.05 │ 1498.54 │ -       │ 1491.53 │ 1522.75 │ 1523.48 │ 1470.21 │ 1483.03 │ 1521.48 │ 1492.54 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1519.64 │ 1382.95 │ 1260.56 │ -       │ 1517.51 │ 1328.26 │ 1522.04 │ 1251.51 │ 1525.31 │ 1480.36 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1519.15 │ 1518.42 │ 1131.22 │ 1507.94 │ -       │ 1387.56 │ 767.26  │ 920.01  │ 1466.06 │ 1519.18 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1517.12 │ 1250.15 │ 1368.91 │ 1510.52 │ 1522.25 │ -       │ 1518.73 │ 1485.19 │ 1521.55 │ 1476.57 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1492.12 │ 1515.99 │ 1513.76 │ 1504.38 │ 1462.84 │ 1430.60 │ -       │ 1128.55 │ 1469.58 │ 1379.17 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1519.87 │ 1522.55 │ 1456.94 │ 1493.85 │ 1518.67 │ 1374.86 │ 1300.57 │ -       │ 1288.96 │ 1361.42 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1509.54 │ 1520.22 │ 1152.52 │ 1065.90 │ 1497.09 │ 1190.98 │ 1328.92 │ 1024.11 │ -       │ 1455.24 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1492.53 │ 1498.43 │ 1245.49 │ 1085.95 │ 884.86  │ 1027.10 │ 1019.73 │ 805.71  │ 1281.56 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4       │ 5       │ 6       │ 7      │ 8       │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪════════╡\n",
      "│            0 │ -       │ 1169.15 │ 832.75 │ 1056.09 │ 1139.89 │ 780.08  │ 572.08  │ 739.24 │ 1207.04 │ 795.94 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            1 │ 966.49  │ -       │ 457.66 │ 474.12  │ 820.06  │ 644.54  │ 372.47  │ 322.24 │ 539.09  │ 405.90 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            2 │ 1121.76 │ 1084.67 │ -      │ 930.00  │ 1159.33 │ 1262.01 │ 824.35  │ 778.78 │ 1076.58 │ 985.21 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            3 │ 1072.86 │ 855.83  │ 735.41 │ -       │ 1151.14 │ 618.77  │ 1085.36 │ 727.45 │ 1094.17 │ 721.59 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            4 │ 1269.56 │ 1056.10 │ 708.25 │ 967.48  │ -       │ 721.47  │ 413.48  │ 520.76 │ 991.02  │ 980.12 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            5 │ 1052.26 │ 771.75  │ 874.60 │ 841.14  │ 1098.46 │ -       │ 975.84  │ 879.73 │ 1217.71 │ 951.64 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            6 │ 1179.05 │ 1090.01 │ 646.56 │ 865.28  │ 850.63  │ 785.39  │ -       │ 671.76 │ 1131.47 │ 775.03 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            7 │ 1190.01 │ 1058.14 │ 620.49 │ 952.34  │ 1196.96 │ 752.79  │ 880.17  │ -      │ 1010.53 │ 737.20 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            8 │ 830.16  │ 785.90  │ 500.45 │ 484.50  │ 1037.96 │ 705.77  │ 672.65  │ 617.30 │ -       │ 599.57 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼────────┤\n",
      "│            9 │ 1112.20 │ 913.08  │ 647.78 │ 561.06  │ 421.00  │ 615.31  │ 712.48  │ 454.37 │ 835.21  │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\4212413037.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_32.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_32_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b190c-d74d-469d-9c79-acc5dfa76aa7",
   "metadata": {},
   "source": [
    "### MLP1L - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4e1059e-b6cc-4601-b54f-693cd768098d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3267375802.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -  72 / 1254.4 / 26.6  77 / 1084.5 / 24.9  94 / 1121.6 / 25.1  85 / 1168.9 / 25.9  98 / 1048.1 / 24.9   98 / 942.0 / 24.9  100 / 795.8 / 24.6  20 / 1236.4 / 25.4   97 / 940.6 / 24.9\n",
      "1             92 / 1181.7 / 26.4                   -  100 / 642.3 / 23.8  100 / 473.0 / 23.6   87 / 978.0 / 25.2  100 / 676.1 / 24.1  100 / 552.3 / 24.0  100 / 354.4 / 23.5  100 / 749.6 / 24.4  100 / 423.9 / 23.7\n",
      "2             79 / 1239.4 / 25.8  59 / 1187.9 / 26.0                   -  100 / 754.6 / 24.3  86 / 1092.5 / 25.7  98 / 1110.8 / 25.2  91 / 1190.8 / 25.6   98 / 737.3 / 24.8  87 / 1152.7 / 25.4   98 / 903.5 / 25.2\n",
      "3             87 / 1213.3 / 25.8  91 / 1098.1 / 25.8  76 / 1159.2 / 25.3                   -  90 / 1148.7 / 25.7   98 / 811.9 / 24.4  73 / 1252.6 / 25.9  100 / 882.7 / 24.9  55 / 1271.1 / 25.6   98 / 908.3 / 25.0\n",
      "4             78 / 1300.1 / 26.2   91 / 993.2 / 25.7  93 / 1061.9 / 25.0  90 / 1057.4 / 25.3                   -  100 / 905.9 / 24.7  100 / 612.0 / 24.1  100 / 550.0 / 23.8  64 / 1142.1 / 25.2   99 / 757.0 / 24.4\n",
      "5              98 / 988.8 / 25.2  100 / 992.2 / 25.7  88 / 1109.9 / 25.3  100 / 832.4 / 24.5  90 / 1090.1 / 25.4                   -  96 / 1017.7 / 25.2   98 / 908.1 / 25.2  90 / 1127.0 / 25.3  48 / 1064.8 / 25.5\n",
      "6             83 / 1173.7 / 25.5  58 / 1300.6 / 26.1  79 / 1056.3 / 24.9   97 / 864.7 / 24.7  84 / 1132.8 / 25.3   93 / 959.5 / 24.8                   -  100 / 672.9 / 24.6  26 / 1179.6 / 25.4  100 / 817.2 / 24.7\n",
      "7             45 / 1235.9 / 25.8   96 / 941.2 / 25.4   96 / 875.0 / 24.6  83 / 1018.1 / 24.8  10 / 1225.1 / 25.5   93 / 934.5 / 24.7  60 / 1247.3 / 25.8                   -  26 / 1043.9 / 25.0  100 / 893.4 / 24.6\n",
      "8              99 / 999.0 / 25.6   95 / 878.7 / 25.4  100 / 751.7 / 24.4  100 / 519.9 / 23.9   99 / 957.9 / 25.3  100 / 745.9 / 24.4  100 / 890.5 / 25.1  100 / 708.9 / 24.9                   -  100 / 749.3 / 24.6\n",
      "9             89 / 1167.9 / 26.1   73 / 948.9 / 26.1  84 / 1116.0 / 25.6  100 / 712.9 / 24.5  100 / 487.5 / 23.9  100 / 691.4 / 24.4   99 / 938.9 / 25.4  100 / 573.5 / 23.9   93 / 978.8 / 25.0                   -\n",
      "\n",
      "Total successful attacks: 7867 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_64_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  72 │  77 │  94 │  85 │  98 │  98 │ 100 │  20 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  92 │   0 │ 100 │ 100 │  87 │ 100 │ 100 │ 100 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  79 │  59 │   0 │ 100 │  86 │  98 │  91 │  98 │  87 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  87 │  91 │  76 │   0 │  90 │  98 │  73 │ 100 │  55 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  78 │  91 │  93 │  90 │   0 │ 100 │ 100 │ 100 │  64 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  98 │ 100 │  88 │ 100 │  90 │   0 │  96 │  98 │  90 │  48 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  83 │  58 │  79 │  97 │  84 │  93 │   0 │ 100 │  26 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  45 │  96 │  96 │  83 │  10 │  93 │  60 │   0 │  26 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  99 │  95 │ 100 │ 100 │  99 │ 100 │ 100 │ 100 │   0 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  89 │  73 │  84 │ 100 │ 100 │ 100 │  99 │ 100 │  93 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ 23.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 25.0 │ 27.0 │ 25.0 │ 25.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 25.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 25.0 │ 25.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.6 │ 24.9 │ 25.1 │ 25.9 │ 24.9 │ 24.9 │ 24.6 │ 25.4 │ 24.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.4 │ -    │ 23.8 │ 23.6 │ 25.2 │ 24.1 │ 24.0 │ 23.5 │ 24.4 │ 23.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.8 │ 26.0 │ -    │ 24.3 │ 25.7 │ 25.2 │ 25.6 │ 24.8 │ 25.4 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.8 │ 25.8 │ 25.3 │ -    │ 25.7 │ 24.4 │ 25.9 │ 24.8 │ 25.6 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.2 │ 25.7 │ 25.0 │ 25.3 │ -    │ 24.7 │ 24.1 │ 23.8 │ 25.2 │ 24.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.2 │ 25.7 │ 25.3 │ 24.5 │ 25.4 │ -    │ 25.2 │ 25.2 │ 25.3 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.5 │ 26.1 │ 24.9 │ 24.7 │ 25.3 │ 24.8 │ -    │ 24.6 │ 25.4 │ 24.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.8 │ 25.4 │ 24.6 │ 24.8 │ 25.5 │ 24.7 │ 25.8 │ -    │ 25.0 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.6 │ 25.4 │ 24.4 │ 23.9 │ 25.3 │ 24.4 │ 25.0 │ 24.9 │ -    │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.1 │ 26.1 │ 25.6 │ 24.5 │ 23.9 │ 24.4 │ 25.4 │ 23.8 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3      │ 4      │ 5      │ 6      │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -      │ 823.19 │ 344.24 │ 450.99 │ 534.78 │ 197.29 │ 414.03 │ 400.19 │ 777.76 │ 266.80 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ 744.47 │ -      │ 232.79 │ 318.32 │ 542.09 │ 383.14 │ 287.15 │ 124.11 │ 397.60 │ 162.62 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ 453.28 │ 404.06 │ -      │ 208.78 │ 549.25 │ 596.91 │ 404.78 │ 217.22 │ 374.80 │ 357.51 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ 436.55 │ 281.03 │ 417.94 │ -      │ 312.68 │ 184.28 │ 713.97 │ 225.20 │ 717.25 │ 242.21 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ 783.04 │ 376.89 │ 303.57 │ 509.13 │ -      │ 438.57 │ 138.18 │ 233.31 │ 636.70 │ 288.74 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ 447.11 │ 473.39 │ 578.91 │ 275.38 │ 373.01 │ -      │ 293.61 │ 377.24 │ 602.75 │ 519.10 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ 581.35 │ 858.29 │ 541.98 │ 421.45 │ 340.99 │ 169.63 │ -      │ 291.34 │ 694.98 │ 261.39 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 734.98 │ 461.82 │ 182.64 │ 290.39 │ 848.36 │ 482.60 │ 668.99 │ -      │ 736.39 │ 286.60 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 357.14 │ 296.70 │ 200.57 │ 160.47 │ 467.09 │ 253.80 │ 180.62 │ 227.06 │ -      │ 220.70 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ 577.28 │ 381.50 │ 253.99 │ 256.37 │ 180.60 │ 214.22 │ 394.16 │ 161.58 │ 507.85 │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1509.88 │ 1523.83 │ 1515.23 │ 1520.68 │ 1509.26 │ 1491.58 │ 1289.94 │ 1517.65 │ 1480.58 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1517.29 │ -       │ 1069.82 │ 867.53  │ 1522.40 │ 1160.20 │ 891.35  │ 812.07  │ 1471.12 │ 777.58  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1519.53 │ 1503.80 │ -       │ 1216.57 │ 1503.12 │ 1518.91 │ 1521.76 │ 1440.51 │ 1514.92 │ 1514.67 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1517.90 │ 1520.65 │ 1522.65 │ -       │ 1522.10 │ 1240.37 │ 1518.36 │ 1456.92 │ 1516.24 │ 1470.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1518.75 │ 1515.13 │ 1523.11 │ 1511.99 │ -       │ 1521.86 │ 1000.21 │ 1021.90 │ 1513.16 │ 1478.14 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1474.22 │ 1499.56 │ 1497.44 │ 1322.59 │ 1519.58 │ -       │ 1520.00 │ 1485.12 │ 1513.49 │ 1516.41 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1520.56 │ 1516.30 │ 1523.54 │ 1466.99 │ 1521.05 │ 1515.01 │ -       │ 1109.48 │ 1516.52 │ 1484.34 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1514.23 │ 1513.80 │ 1493.91 │ 1522.61 │ 1522.61 │ 1489.55 │ 1519.45 │ -       │ 1478.97 │ 1494.45 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1517.70 │ 1488.79 │ 1458.00 │ 1401.89 │ 1482.64 │ 1475.93 │ 1495.82 │ 1211.13 │ -       │ 1440.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1515.22 │ 1418.95 │ 1501.70 │ 1490.67 │ 950.48  │ 1227.54 │ 1383.89 │ 1072.99 │ 1507.02 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7      │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1254.41 │ 1084.53 │ 1121.61 │ 1168.90 │ 1048.15 │ 941.98  │ 795.77 │ 1236.36 │ 940.59  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            1 │ 1181.68 │ -       │ 642.33  │ 473.04  │ 977.99  │ 676.08  │ 552.27  │ 354.42 │ 749.59  │ 423.93  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            2 │ 1239.42 │ 1187.89 │ -       │ 754.63  │ 1092.52 │ 1110.76 │ 1190.77 │ 737.28 │ 1152.72 │ 903.48  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            3 │ 1213.31 │ 1098.06 │ 1159.18 │ -       │ 1148.66 │ 811.91  │ 1252.56 │ 882.70 │ 1271.14 │ 908.34  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            4 │ 1300.06 │ 993.22  │ 1061.87 │ 1057.36 │ -       │ 905.94  │ 612.00  │ 550.01 │ 1142.12 │ 757.03  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            5 │ 988.84  │ 992.19  │ 1109.88 │ 832.40  │ 1090.06 │ -       │ 1017.72 │ 908.12 │ 1126.99 │ 1064.77 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            6 │ 1173.69 │ 1300.60 │ 1056.31 │ 864.67  │ 1132.83 │ 959.48  │ -       │ 672.87 │ 1179.64 │ 817.22  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            7 │ 1235.91 │ 941.24  │ 874.98  │ 1018.08 │ 1225.05 │ 934.52  │ 1247.33 │ -      │ 1043.87 │ 893.44  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            8 │ 999.01  │ 878.74  │ 751.66  │ 519.89  │ 957.88  │ 745.88  │ 890.51  │ 708.85 │ -       │ 749.27  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┤\n",
      "│            9 │ 1167.92 │ 948.90  │ 1115.96 │ 712.94  │ 487.49  │ 691.41  │ 938.86  │ 573.50 │ 978.82  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3267375802.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_64.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_64_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308bc4ae-9df1-432f-821c-3b903284529c",
   "metadata": {},
   "source": [
    "### MLP1L - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91b881df-76b0-44c9-9ac5-10fd89abd45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3329884493.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -  47 / 1306.9 / 26.7  95 / 1010.0 / 24.7   7 / 1388.4 / 25.6  52 / 1267.4 / 26.2  75 / 1193.3 / 25.1  97 / 1006.2 / 25.1  85 / 1110.6 / 25.3   7 / 1334.9 / 25.7  96 / 1066.1 / 25.2\n",
      "1             87 / 1246.0 / 26.5                   -  100 / 574.8 / 23.9  100 / 593.5 / 23.9   65 / 940.5 / 25.1  91 / 1024.5 / 25.0  100 / 621.0 / 24.1  100 / 448.6 / 23.6   97 / 846.7 / 24.6  100 / 608.2 / 24.1\n",
      "2             71 / 1247.8 / 25.8  11 / 1271.8 / 26.1                   -  54 / 1081.5 / 24.8  18 / 1366.0 / 26.2  11 / 1337.6 / 25.7  76 / 1263.6 / 25.6   96 / 891.6 / 25.2  38 / 1243.1 / 25.5  95 / 1104.6 / 25.7\n",
      "3             91 / 1123.2 / 25.6  95 / 1055.4 / 25.7  100 / 946.7 / 24.7                   -  65 / 1234.9 / 25.9  100 / 798.0 / 24.3  48 / 1277.2 / 25.9  94 / 1071.8 / 25.2  51 / 1242.8 / 25.6   98 / 964.1 / 25.1\n",
      "4             49 / 1350.8 / 26.2  67 / 1118.8 / 26.1   95 / 912.4 / 24.6  38 / 1159.7 / 25.6                   -  90 / 1073.4 / 25.1  100 / 700.5 / 24.3  100 / 609.2 / 24.0  70 / 1235.9 / 25.5   99 / 873.5 / 24.7\n",
      "5             99 / 1010.7 / 25.2  85 / 1051.8 / 25.9  97 / 1020.0 / 25.1  85 / 1118.4 / 25.1  67 / 1236.0 / 25.7                   -  90 / 1097.8 / 25.3  85 / 1160.9 / 25.8  68 / 1218.4 / 25.5  42 / 1252.5 / 25.9\n",
      "6             77 / 1204.9 / 25.6  25 / 1343.3 / 26.3   95 / 827.1 / 24.3  82 / 1163.4 / 25.3  52 / 1170.8 / 25.4  81 / 1117.2 / 25.2                   -  100 / 853.3 / 24.9  13 / 1307.3 / 25.8  98 / 1016.5 / 25.1\n",
      "7             71 / 1228.4 / 25.7  48 / 1218.0 / 26.0  92 / 1011.6 / 24.8  27 / 1097.1 / 24.9   1 / 1177.0 / 25.0   95 / 990.3 / 24.9  57 / 1276.9 / 25.9                   -  13 / 1290.2 / 25.5   99 / 953.0 / 24.8\n",
      "8             94 / 1136.2 / 25.9  71 / 1088.2 / 25.9   99 / 688.1 / 24.3   99 / 693.8 / 24.3  84 / 1140.8 / 25.8  87 / 1022.8 / 25.0   98 / 909.6 / 25.1  100 / 804.4 / 25.1                   -   94 / 923.2 / 25.0\n",
      "9             90 / 1198.1 / 26.1  61 / 1075.0 / 26.2  100 / 814.7 / 24.9   96 / 878.2 / 24.8  100 / 670.2 / 24.3   99 / 821.0 / 24.7  100 / 837.8 / 25.2  100 / 684.1 / 24.1   98 / 937.1 / 24.9                   -\n",
      "\n",
      "Total successful attacks: 6835 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_128_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  47 │  95 │   7 │  52 │  75 │  97 │  85 │   7 │  96 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  87 │   0 │ 100 │ 100 │  65 │  91 │ 100 │ 100 │  97 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  71 │  11 │   0 │  54 │  18 │  11 │  76 │  96 │  38 │  95 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  91 │  95 │ 100 │   0 │  65 │ 100 │  48 │  94 │  51 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  49 │  67 │  95 │  38 │   0 │  90 │ 100 │ 100 │  70 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  99 │  85 │  97 │  85 │  67 │   0 │  90 │  85 │  68 │  42 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  77 │  25 │  95 │  82 │  52 │  81 │   0 │ 100 │  13 │  98 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  71 │  48 │  92 │  27 │   1 │  95 │  57 │   0 │  13 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  94 │  71 │  99 │  99 │  84 │  87 │  98 │ 100 │   0 │  94 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  90 │  61 │ 100 │  96 │ 100 │  99 │ 100 │ 100 │  98 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 23.0 │ 25.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 25.0 │ -    │ 24.0 │ 25.0 │ 25.0 │ 24.0 │ 23.0 │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ -    │ 25.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 24.0 │ 25.0 │ 27.0 │ 27.0 │ 25.0 │ 25.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │ 25.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 25.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.7 │ 24.7 │ 25.6 │ 26.2 │ 25.1 │ 25.1 │ 25.3 │ 25.7 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.5 │ -    │ 23.9 │ 23.9 │ 25.1 │ 25.0 │ 24.1 │ 23.6 │ 24.6 │ 24.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.8 │ 26.1 │ -    │ 24.8 │ 26.2 │ 25.7 │ 25.6 │ 25.2 │ 25.5 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.6 │ 25.7 │ 24.7 │ -    │ 25.9 │ 24.3 │ 25.9 │ 25.2 │ 25.6 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.2 │ 26.1 │ 24.6 │ 25.6 │ -    │ 25.1 │ 24.3 │ 24.0 │ 25.5 │ 24.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.2 │ 25.9 │ 25.1 │ 25.1 │ 25.7 │ -    │ 25.3 │ 25.8 │ 25.5 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.6 │ 26.3 │ 24.3 │ 25.3 │ 25.4 │ 25.2 │ -    │ 24.9 │ 25.8 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.7 │ 26.0 │ 24.8 │ 24.9 │ 25.0 │ 24.9 │ 25.9 │ -    │ 25.5 │ 24.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.9 │ 25.9 │ 24.3 │ 24.3 │ 25.8 │ 25.0 │ 25.1 │ 25.1 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.1 │ 26.2 │ 24.9 │ 24.8 │ 24.3 │ 24.7 │ 25.2 │ 24.1 │ 24.9 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤═════════╤═════════╤═════════╤════════╤════════╤═════════╤════════╕\n",
      "│   true_label │ 0      │ 1      │ 2      │ 3       │ 4       │ 5       │ 6      │ 7      │ 8       │ 9      │\n",
      "╞══════════════╪════════╪════════╪════════╪═════════╪═════════╪═════════╪════════╪════════╪═════════╪════════╡\n",
      "│            0 │ -      │ 930.69 │ 410.02 │ 1138.73 │ 759.06  │ 553.57  │ 276.23 │ 599.98 │ 810.30  │ 464.57 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            1 │ 857.10 │ -      │ 290.63 │ 391.03  │ 517.83  │ 419.35  │ 288.50 │ 227.74 │ 540.42  │ 260.08 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            2 │ 724.95 │ 793.03 │ -      │ 507.96  │ 1118.56 │ 1053.92 │ 689.07 │ 217.36 │ 936.34  │ 563.39 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            3 │ 561.76 │ 436.30 │ 334.42 │ -       │ 420.79  │ 235.15  │ 731.62 │ 343.38 │ 678.43  │ 257.98 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            4 │ 886.58 │ 408.08 │ 291.32 │ 709.88  │ -       │ 485.02  │ 235.12 │ 287.22 │ 739.20  │ 334.08 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            5 │ 521.20 │ 384.04 │ 486.24 │ 440.29  │ 482.42  │ -       │ 343.40 │ 526.66 │ 670.41  │ 440.52 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            6 │ 588.50 │ 820.12 │ 350.32 │ 671.88  │ 676.41  │ 515.45  │ -      │ 407.16 │ 1028.84 │ 383.37 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            7 │ 821.92 │ 662.00 │ 433.99 │ 555.60  │ 1177.02 │ 553.47  │ 732.56 │ -      │ 1014.89 │ 316.79 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            8 │ 507.34 │ 460.16 │ 236.73 │ 264.68  │ 559.22  │ 420.87  │ 348.76 │ 253.17 │ -       │ 312.50 │\n",
      "├──────────────┼────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┼─────────┼────────┤\n",
      "│            9 │ 611.16 │ 586.68 │ 181.55 │ 279.24  │ 180.22  │ 178.71  │ 340.50 │ 231.22 │ 504.15  │ -      │\n",
      "╘══════════════╧════════╧════════╧════════╧═════════╧═════════╧═════════╧════════╧════════╧═════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1515.16 │ 1480.93 │ 1523.92 │ 1515.89 │ 1524.18 │ 1505.81 │ 1493.14 │ 1503.87 │ 1503.31 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1522.33 │ -       │ 910.55  │ 1159.68 │ 1478.55 │ 1518.23 │ 1105.99 │ 893.27  │ 1513.39 │ 1012.14 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1519.15 │ 1514.98 │ -       │ 1518.62 │ 1511.65 │ 1513.56 │ 1524.28 │ 1492.00 │ 1492.00 │ 1517.34 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1513.42 │ 1473.80 │ 1419.79 │ -       │ 1516.22 │ 1334.98 │ 1522.07 │ 1515.07 │ 1513.28 │ 1460.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1521.23 │ 1518.12 │ 1512.27 │ 1523.94 │ -       │ 1505.45 │ 1143.00 │ 1028.38 │ 1517.15 │ 1515.20 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1508.16 │ 1461.09 │ 1448.05 │ 1524.58 │ 1523.03 │ -       │ 1499.81 │ 1519.83 │ 1523.90 │ 1521.40 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1520.88 │ 1519.42 │ 1378.14 │ 1518.48 │ 1517.45 │ 1511.86 │ -       │ 1307.95 │ 1503.46 │ 1435.01 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1520.58 │ 1517.22 │ 1495.61 │ 1520.95 │ 1177.02 │ 1525.31 │ 1522.89 │ -       │ 1514.40 │ 1360.07 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1516.53 │ 1516.72 │ 1446.20 │ 1517.05 │ 1517.80 │ 1489.84 │ 1515.88 │ 1325.97 │ -       │ 1515.92 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1505.44 │ 1482.45 │ 1423.39 │ 1523.15 │ 1236.09 │ 1412.54 │ 1217.10 │ 1376.43 │ 1509.26 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1306.88 │ 1010.02 │ 1388.41 │ 1267.44 │ 1193.27 │ 1006.20 │ 1110.63 │ 1334.94 │ 1066.06 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1245.96 │ -       │ 574.75  │ 593.54  │ 940.48  │ 1024.53 │ 621.04  │ 448.64  │ 846.73  │ 608.22  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1247.80 │ 1271.84 │ -       │ 1081.49 │ 1366.05 │ 1337.64 │ 1263.62 │ 891.57  │ 1243.06 │ 1104.60 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1123.20 │ 1055.42 │ 946.72  │ -       │ 1234.88 │ 797.99  │ 1277.23 │ 1071.82 │ 1242.78 │ 964.13  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1350.78 │ 1118.83 │ 912.41  │ 1159.69 │ -       │ 1073.37 │ 700.48  │ 609.19  │ 1235.87 │ 873.53  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1010.74 │ 1051.76 │ 1019.98 │ 1118.41 │ 1236.02 │ -       │ 1097.78 │ 1160.86 │ 1218.41 │ 1252.53 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1204.87 │ 1343.28 │ 827.09  │ 1163.37 │ 1170.81 │ 1117.23 │ -       │ 853.28  │ 1307.32 │ 1016.55 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1228.43 │ 1217.98 │ 1011.59 │ 1097.10 │ 1177.02 │ 990.27  │ 1276.94 │ -       │ 1290.21 │ 953.03  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1136.25 │ 1088.19 │ 688.12  │ 693.76  │ 1140.83 │ 1022.76 │ 909.59  │ 804.41  │ -       │ 923.18  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1198.15 │ 1074.96 │ 814.72  │ 878.17  │ 670.21  │ 821.04  │ 837.82  │ 684.07  │ 937.07  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3329884493.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_128.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_128_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7424cc-effb-4fab-9a89-87c590606b12",
   "metadata": {},
   "source": [
    "### MLP1L - 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08c56fe2-5db3-4bb2-b4b5-66be7a0b447e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\1662672579.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -   1 / 1519.3 / 27.0  73 / 1022.9 / 24.8   8 / 1392.4 / 25.8  34 / 1262.8 / 26.1  50 / 1169.2 / 25.1  90 / 1077.8 / 25.2  92 / 1098.2 / 25.3   1 / 1486.2 / 26.0  77 / 1193.2 / 25.5\n",
      "1             98 / 1159.8 / 26.2                   -  100 / 547.9 / 23.8  100 / 840.9 / 24.4  14 / 1211.3 / 25.9  100 / 866.2 / 24.6  100 / 813.1 / 24.6  100 / 558.9 / 23.9   32 / 996.1 / 25.2  100 / 611.8 / 24.1\n",
      "2             29 / 1358.4 / 26.4                   -                   -  47 / 1079.5 / 24.9   2 / 1508.4 / 26.5  55 / 1229.9 / 25.5  46 / 1338.1 / 25.9  85 / 1106.5 / 25.6  37 / 1273.0 / 25.6  86 / 1206.7 / 25.8\n",
      "3             56 / 1297.1 / 26.1  50 / 1261.6 / 26.1  90 / 1105.6 / 25.2                   -  20 / 1301.0 / 25.9   99 / 865.7 / 24.5  50 / 1307.5 / 26.1  80 / 1165.1 / 25.4  69 / 1278.1 / 25.6  89 / 1127.7 / 25.5\n",
      "4             22 / 1340.9 / 26.3  42 / 1254.0 / 26.4   97 / 916.6 / 24.7  34 / 1100.1 / 25.2                   -  70 / 1194.4 / 25.4  100 / 846.3 / 24.6  100 / 694.8 / 24.2  26 / 1241.7 / 25.6  91 / 1079.7 / 25.4\n",
      "5             95 / 1122.5 / 25.5  31 / 1281.0 / 26.4  86 / 1113.1 / 25.3  62 / 1105.6 / 25.1  52 / 1236.1 / 25.6                   -  83 / 1075.7 / 25.4  56 / 1203.7 / 25.7  48 / 1210.5 / 25.5   8 / 1259.9 / 26.2\n",
      "6             71 / 1161.1 / 25.5  14 / 1405.7 / 26.3   91 / 856.8 / 24.4  68 / 1205.4 / 25.3  35 / 1075.2 / 25.1  81 / 1085.8 / 25.1                   -  99 / 1002.5 / 25.2  29 / 1278.2 / 25.7  91 / 1062.2 / 25.2\n",
      "7             35 / 1385.7 / 26.1  14 / 1279.5 / 25.9  81 / 1122.6 / 25.1  35 / 1165.6 / 25.1                   -  95 / 1091.9 / 25.1  36 / 1337.7 / 26.1                   -   3 / 1225.9 / 25.3  83 / 1140.6 / 25.2\n",
      "8             85 / 1196.9 / 26.1  24 / 1128.1 / 26.0   98 / 770.4 / 24.4   95 / 852.9 / 24.7  36 / 1197.1 / 25.8   85 / 992.9 / 24.9  86 / 1050.8 / 25.5  100 / 943.1 / 25.3                   -  68 / 1131.7 / 25.6\n",
      "9             69 / 1246.6 / 26.3  30 / 1106.3 / 26.3  100 / 828.5 / 24.9   92 / 795.2 / 24.6  100 / 665.9 / 24.3   97 / 762.4 / 24.5   97 / 937.0 / 25.4  100 / 699.5 / 24.2  87 / 1012.4 / 25.1                   -\n",
      "\n",
      "Total successful attacks: 5673 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP1L_256_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   1 │  73 │   8 │  34 │  50 │  90 │  92 │   1 │  77 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  98 │   0 │ 100 │ 100 │  14 │ 100 │ 100 │ 100 │  32 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  29 │   0 │   0 │  47 │   2 │  55 │  46 │  85 │  37 │  86 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  56 │  50 │  90 │   0 │  20 │  99 │  50 │  80 │  69 │  89 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  22 │  42 │  97 │  34 │   0 │  70 │ 100 │ 100 │  26 │  91 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  95 │  31 │  86 │  62 │  52 │   0 │  83 │  56 │  48 │   8 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  71 │  14 │  91 │  68 │  35 │  81 │   0 │  99 │  29 │  91 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  35 │  14 │  81 │  35 │   0 │  95 │  36 │   0 │   3 │  83 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  85 │  24 │  98 │  95 │  36 │  85 │  86 │ 100 │   0 │  68 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  69 │  30 │ 100 │  92 │ 100 │  97 │  97 │ 100 │  87 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 23.0 │ 25.0 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ 26.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ -    │ -    │ 24.0 │ 26.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 25.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ -    │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 25.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 24.8 │ 25.8 │ 26.1 │ 25.1 │ 25.2 │ 25.3 │ 26.0 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.2 │ -    │ 23.8 │ 24.4 │ 25.9 │ 24.6 │ 24.6 │ 24.0 │ 25.2 │ 24.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.4 │ -    │ -    │ 24.9 │ 26.5 │ 25.5 │ 25.9 │ 25.6 │ 25.6 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.1 │ 26.1 │ 25.2 │ -    │ 25.8 │ 24.5 │ 26.1 │ 25.4 │ 25.6 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.3 │ 26.4 │ 24.7 │ 25.2 │ -    │ 25.4 │ 24.6 │ 24.2 │ 25.6 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.5 │ 26.4 │ 25.3 │ 25.1 │ 25.6 │ -    │ 25.4 │ 25.7 │ 25.5 │ 26.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.5 │ 26.3 │ 24.4 │ 25.3 │ 25.1 │ 25.1 │ -    │ 25.2 │ 25.7 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.1 │ 25.9 │ 25.1 │ 25.1 │ -    │ 25.1 │ 26.1 │ -    │ 25.3 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.1 │ 26.0 │ 24.4 │ 24.7 │ 25.8 │ 24.9 │ 25.5 │ 25.3 │ -    │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.3 │ 26.3 │ 24.9 │ 24.6 │ 24.3 │ 24.5 │ 25.4 │ 24.2 │ 25.1 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤═════════╤════════╤════════╤════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4       │ 5      │ 6      │ 7      │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪═════════╪════════╪════════╪════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1519.34 │ 330.55 │ 1052.54 │ 770.05  │ 474.76 │ 333.05 │ 273.48 │ 1486.24 │ 448.21  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            1 │ 713.09  │ -       │ 268.53 │ 460.98  │ 727.40  │ 529.35 │ 439.07 │ 265.47 │ 591.80  │ 178.88  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            2 │ 554.96  │ -       │ -      │ 440.40  │ 1503.77 │ 794.91 │ 813.96 │ 290.42 │ 794.54  │ 675.84  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            3 │ 625.48  │ 282.89  │ 599.70 │ -       │ 793.26  │ 197.39 │ 788.04 │ 289.39 │ 539.38  │ 257.98  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            4 │ 1050.52 │ 772.24  │ 364.04 │ 663.81  │ -       │ 522.31 │ 226.80 │ 326.08 │ 896.76  │ 336.55  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            5 │ 509.63  │ 885.88  │ 670.64 │ 446.71  │ 373.11  │ -      │ 390.86 │ 561.73 │ 768.41  │ 1067.28 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            6 │ 404.45  │ 1159.15 │ 239.31 │ 724.26  │ 316.58  │ 338.45 │ -      │ 526.96 │ 830.51  │ 406.99  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            7 │ 1062.74 │ 882.49  │ 346.77 │ 560.03  │ -       │ 519.36 │ 804.66 │ -      │ 1077.28 │ 510.01  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            8 │ 541.71  │ 438.83  │ 303.13 │ 317.74  │ 401.98  │ 530.93 │ 209.52 │ 283.09 │ -       │ 522.62  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼────────┼─────────┼─────────┤\n",
      "│            9 │ 611.16  │ 671.42  │ 235.73 │ 309.74  │ 132.18  │ 196.43 │ 576.20 │ 144.74 │ 671.90  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧═════════╧════════╧════════╧════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1519.34 │ 1520.50 │ 1523.50 │ 1519.81 │ 1521.19 │ 1522.63 │ 1520.65 │ 1486.24 │ 1510.70 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1468.19 │ -       │ 773.82  │ 1428.41 │ 1480.20 │ 1272.66 │ 1253.76 │ 1099.66 │ 1510.54 │ 1132.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1518.87 │ -       │ -       │ 1514.81 │ 1512.95 │ 1524.15 │ 1524.23 │ 1508.58 │ 1499.14 │ 1482.49 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1516.20 │ 1514.07 │ 1513.38 │ -       │ 1513.77 │ 1434.32 │ 1518.41 │ 1515.58 │ 1521.11 │ 1519.05 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1496.35 │ 1513.71 │ 1518.08 │ 1524.00 │ -       │ 1516.90 │ 1407.39 │ 1136.78 │ 1515.98 │ 1518.25 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1515.77 │ 1512.13 │ 1525.78 │ 1518.96 │ 1517.84 │ -       │ 1502.52 │ 1503.95 │ 1520.83 │ 1487.63 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1520.37 │ 1514.68 │ 1513.94 │ 1518.72 │ 1518.28 │ 1522.80 │ -       │ 1516.45 │ 1518.68 │ 1498.34 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1520.58 │ 1519.21 │ 1518.26 │ 1506.78 │ -       │ 1512.49 │ 1520.06 │ -       │ 1456.15 │ 1521.94 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1517.39 │ 1478.89 │ 1512.87 │ 1521.27 │ 1518.68 │ 1496.21 │ 1502.64 │ 1513.93 │ -       │ 1522.21 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1520.19 │ 1411.27 │ 1302.88 │ 1494.94 │ 1283.37 │ 1469.77 │ 1415.23 │ 1283.32 │ 1390.48 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1519.34 │ 1022.91 │ 1392.41 │ 1262.78 │ 1169.20 │ 1077.75 │ 1098.20 │ 1486.24 │ 1193.17 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1159.78 │ -       │ 547.92  │ 840.89  │ 1211.26 │ 866.21  │ 813.07  │ 558.93  │ 996.07  │ 611.83  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1358.41 │ -       │ -       │ 1079.50 │ 1508.36 │ 1229.92 │ 1338.13 │ 1106.49 │ 1273.05 │ 1206.71 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1297.05 │ 1261.59 │ 1105.64 │ -       │ 1301.01 │ 865.71  │ 1307.54 │ 1165.12 │ 1278.09 │ 1127.71 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1340.94 │ 1253.98 │ 916.60  │ 1100.10 │ -       │ 1194.44 │ 846.25  │ 694.77  │ 1241.67 │ 1079.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1122.54 │ 1281.02 │ 1113.05 │ 1105.57 │ 1236.14 │ -       │ 1075.73 │ 1203.72 │ 1210.50 │ 1259.95 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1161.10 │ 1405.72 │ 856.80  │ 1205.37 │ 1075.24 │ 1085.76 │ -       │ 1002.47 │ 1278.22 │ 1062.16 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1385.70 │ 1279.47 │ 1122.60 │ 1165.55 │ -       │ 1091.92 │ 1337.72 │ -       │ 1225.91 │ 1140.55 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1196.88 │ 1128.07 │ 770.39  │ 852.92  │ 1197.06 │ 992.86  │ 1050.83 │ 943.07  │ -       │ 1131.70 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1246.64 │ 1106.30 │ 828.47  │ 795.16  │ 665.92  │ 762.41  │ 937.02  │ 699.46  │ 1012.41 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\1662672579.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP1L_256.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP1L_256_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0404-6999-4376-8e0b-64bb6fe768a7",
   "metadata": {},
   "source": [
    "## -----  MLP2L -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcac6be-1c75-462c-ac56-f5f92a30ae95",
   "metadata": {},
   "source": [
    "### MLP2L - 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a3c842a-684b-4ce9-9050-fe947858f37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3960752919.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                    3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                           \n",
      "0                              -   8 / 1349.4 / 26.6  61 / 1023.3 / 24.9    3 / 1168.7 / 25.3  26 / 1259.7 / 26.2  28 / 1160.6 / 25.1  89 / 1053.0 / 25.2  85 / 1108.4 / 25.3  30 / 1131.9 / 25.3  47 / 1183.3 / 25.5\n",
      "1             21 / 1370.0 / 26.7                   -  100 / 781.3 / 24.2  100 / 1003.3 / 24.8   98 / 830.8 / 24.8   81 / 737.5 / 24.2  100 / 946.8 / 24.9  100 / 534.7 / 23.9   99 / 608.0 / 24.0  100 / 764.0 / 24.4\n",
      "2             19 / 1411.2 / 26.1   1 / 1472.8 / 27.0                   -   29 / 1202.2 / 25.2  30 / 1286.3 / 26.0  36 / 1279.4 / 25.6  54 / 1258.2 / 25.6  64 / 1169.7 / 25.7  84 / 1182.3 / 25.4  86 / 1152.0 / 25.6\n",
      "3             30 / 1258.2 / 26.0  71 / 1169.9 / 25.9  93 / 1034.5 / 24.9                    -  23 / 1269.0 / 26.0  78 / 1096.6 / 24.9   9 / 1179.6 / 25.6  80 / 1138.3 / 25.3   99 / 913.1 / 24.7  84 / 1132.5 / 25.5\n",
      "4              6 / 1329.6 / 26.3  35 / 1353.5 / 26.4  60 / 1194.8 / 25.3   11 / 1379.4 / 26.1                   -  47 / 1226.2 / 25.6   96 / 953.3 / 24.8  100 / 980.1 / 24.8  71 / 1165.2 / 25.3  93 / 1145.8 / 25.5\n",
      "5             88 / 1188.7 / 25.7  46 / 1303.8 / 26.5  54 / 1268.4 / 25.6   64 / 1183.0 / 25.2  49 / 1271.3 / 25.7                   -  60 / 1156.1 / 25.6  80 / 1178.4 / 25.8  89 / 1167.4 / 25.4  24 / 1114.3 / 25.5\n",
      "6             31 / 1251.7 / 25.7  29 / 1400.4 / 26.4  75 / 1050.9 / 25.0   45 / 1288.9 / 25.5  23 / 1173.3 / 25.3  87 / 1065.9 / 24.9                   -  83 / 1096.2 / 25.4  80 / 1072.7 / 25.1  84 / 1067.6 / 25.1\n",
      "7             19 / 1284.8 / 25.9  54 / 1216.0 / 26.0  69 / 1018.3 / 24.8   13 / 1211.3 / 25.2  19 / 1041.1 / 25.2  70 / 1163.9 / 25.5  76 / 1315.3 / 26.0                   -  35 / 1087.2 / 25.2  87 / 1053.4 / 24.9\n",
      "8             26 / 1339.7 / 26.4   6 / 1254.1 / 26.2  74 / 1149.9 / 25.2   21 / 1368.9 / 25.8  68 / 1100.0 / 25.6  21 / 1291.6 / 25.6  14 / 1193.9 / 25.6  97 / 1115.7 / 25.7                   -  50 / 1239.1 / 25.8\n",
      "9             29 / 1334.4 / 26.4   11 / 949.1 / 25.8  81 / 1172.6 / 25.8   85 / 1010.4 / 25.1  100 / 574.1 / 24.1   90 / 967.5 / 24.9  26 / 1279.2 / 26.3  100 / 778.5 / 24.4   99 / 987.8 / 25.0                   -\n",
      "\n",
      "Total successful attacks: 5196 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_32_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   8 │  61 │   3 │  26 │  28 │  89 │  85 │  30 │  47 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  21 │   0 │ 100 │ 100 │  98 │  81 │ 100 │ 100 │  99 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  19 │   1 │   0 │  29 │  30 │  36 │  54 │  64 │  84 │  86 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  30 │  71 │  93 │   0 │  23 │  78 │   9 │  80 │  99 │  84 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   6 │  35 │  60 │  11 │   0 │  47 │  96 │ 100 │  71 │  93 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  88 │  46 │  54 │  64 │  49 │   0 │  60 │  80 │  89 │  24 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  31 │  29 │  75 │  45 │  23 │  87 │   0 │  83 │  80 │  84 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  19 │  54 │  69 │  13 │  19 │  70 │  76 │   0 │  35 │  87 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  26 │   6 │  74 │  21 │  68 │  21 │  14 │  97 │   0 │  50 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  29 │  11 │  81 │  85 │ 100 │  90 │  26 │ 100 │  99 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 23.0 │ 25.0 │ 25.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 27.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 23.0 │ -    │ 24.0 │ 23.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 26.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ 23.0 │ 25.0 │ 25.0 │ 24.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 25.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.6 │ 24.9 │ 25.3 │ 26.2 │ 25.1 │ 25.2 │ 25.3 │ 25.3 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.7 │ -    │ 24.2 │ 24.8 │ 24.8 │ 24.2 │ 24.9 │ 23.9 │ 24.0 │ 24.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.1 │ 27.0 │ -    │ 25.2 │ 26.0 │ 25.6 │ 25.6 │ 25.7 │ 25.4 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 25.9 │ 24.9 │ -    │ 26.0 │ 24.9 │ 25.6 │ 25.3 │ 24.7 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.3 │ 26.4 │ 25.3 │ 26.1 │ -    │ 25.6 │ 24.8 │ 24.8 │ 25.3 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.7 │ 26.5 │ 25.6 │ 25.2 │ 25.7 │ -    │ 25.6 │ 25.8 │ 25.4 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.7 │ 26.4 │ 25.0 │ 25.5 │ 25.3 │ 24.9 │ -    │ 25.4 │ 25.1 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.9 │ 26.0 │ 24.8 │ 25.2 │ 25.2 │ 25.5 │ 26.0 │ -    │ 25.2 │ 24.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.4 │ 26.2 │ 25.2 │ 25.8 │ 25.6 │ 25.6 │ 25.6 │ 25.7 │ -    │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.4 │ 25.8 │ 25.8 │ 25.1 │ 24.1 │ 24.9 │ 26.3 │ 24.4 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤════════╤════════╤════════╤════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4      │ 5      │ 6      │ 7      │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│            0 │ -       │ 1167.17 │ 247.47 │ 1123.74 │ 527.22 │ 109.69 │ 359.99 │ 267.17 │ 85.96  │ 552.80 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            1 │ 1211.32 │ -       │ 376.03 │ 681.42  │ 418.28 │ 347.81 │ 449.72 │ 262.75 │ 374.69 │ 373.80 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            2 │ 1004.06 │ 1472.76 │ -      │ 674.24  │ 749.13 │ 885.77 │ 759.84 │ 594.05 │ 562.30 │ 540.56 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            3 │ 752.84  │ 690.53  │ 324.74 │ -       │ 684.18 │ 89.76  │ 817.24 │ 355.37 │ 35.79  │ 542.86 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            4 │ 1121.42 │ 1081.46 │ 573.32 │ 1134.54 │ -      │ 549.71 │ 247.59 │ 552.49 │ 657.84 │ 440.19 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            5 │ 743.92  │ 687.19  │ 816.57 │ 606.66  │ 631.47 │ -      │ 357.40 │ 649.65 │ 629.96 │ 610.04 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            6 │ 669.53  │ 1154.16 │ 350.32 │ 723.84  │ 628.83 │ 485.62 │ -      │ 450.22 │ 395.36 │ 261.57 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            7 │ 946.49  │ 732.48  │ 182.64 │ 888.71  │ 325.63 │ 293.17 │ 832.86 │ -      │ 170.54 │ 441.00 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            8 │ 1027.24 │ 826.17  │ 612.79 │ 1065.18 │ 385.29 │ 769.75 │ 828.08 │ 371.78 │ -      │ 652.09 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼────────┤\n",
      "│            9 │ 737.65  │ 617.36  │ 365.38 │ 337.23  │ 99.76  │ 302.83 │ 514.55 │ 178.64 │ 197.41 │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧════════╧════════╧════════╧════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1435.90 │ 1525.83 │ 1242.13 │ 1518.39 │ 1496.10 │ 1526.10 │ 1518.06 │ 1518.03 │ 1522.19 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1518.84 │ -       │ 1238.42 │ 1470.98 │ 1137.13 │ 1259.51 │ 1306.91 │ 877.53  │ 897.06  │ 1407.00 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1520.32 │ 1472.76 │ -       │ 1523.49 │ 1519.35 │ 1523.63 │ 1524.28 │ 1523.24 │ 1514.42 │ 1523.65 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1521.51 │ 1515.78 │ 1519.49 │ -       │ 1516.22 │ 1519.89 │ 1521.48 │ 1518.09 │ 1524.01 │ 1514.98 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1469.10 │ 1518.54 │ 1518.17 │ 1524.00 │ -       │ 1524.16 │ 1520.89 │ 1392.39 │ 1519.55 │ 1523.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1512.78 │ 1522.75 │ 1519.31 │ 1520.25 │ 1512.93 │ -       │ 1523.56 │ 1523.09 │ 1512.04 │ 1501.38 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1518.54 │ 1520.33 │ 1520.76 │ 1523.04 │ 1521.53 │ 1516.50 │ -       │ 1520.80 │ 1523.53 │ 1492.72 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1511.98 │ 1519.37 │ 1488.45 │ 1522.61 │ 1454.71 │ 1492.67 │ 1522.89 │ -       │ 1518.23 │ 1503.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1513.17 │ 1472.36 │ 1523.12 │ 1519.05 │ 1518.68 │ 1524.51 │ 1524.15 │ 1501.64 │ -       │ 1489.73 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1517.78 │ 1509.21 │ 1521.66 │ 1494.62 │ 1274.16 │ 1520.31 │ 1519.17 │ 1463.09 │ 1504.44 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1349.37 │ 1023.27 │ 1168.70 │ 1259.72 │ 1160.62 │ 1053.02 │ 1108.43 │ 1131.88 │ 1183.33 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1370.02 │ -       │ 781.32  │ 1003.30 │ 830.83  │ 737.53  │ 946.76  │ 534.67  │ 607.99  │ 764.00  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1411.22 │ 1472.76 │ -       │ 1202.22 │ 1286.30 │ 1279.37 │ 1258.15 │ 1169.74 │ 1182.26 │ 1151.97 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1258.18 │ 1169.90 │ 1034.52 │ -       │ 1268.97 │ 1096.56 │ 1179.55 │ 1138.28 │ 913.08  │ 1132.46 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1329.60 │ 1353.49 │ 1194.81 │ 1379.39 │ -       │ 1226.21 │ 953.34  │ 980.09  │ 1165.20 │ 1145.82 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1188.66 │ 1303.85 │ 1268.42 │ 1182.96 │ 1271.31 │ -       │ 1156.15 │ 1178.45 │ 1167.41 │ 1114.26 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1251.67 │ 1400.44 │ 1050.85 │ 1288.90 │ 1173.30 │ 1065.89 │ -       │ 1096.24 │ 1072.74 │ 1067.63 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1284.80 │ 1215.96 │ 1018.28 │ 1211.28 │ 1041.15 │ 1163.87 │ 1315.35 │ -       │ 1087.15 │ 1053.36 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1339.68 │ 1254.09 │ 1149.92 │ 1368.93 │ 1099.95 │ 1291.60 │ 1193.92 │ 1115.68 │ -       │ 1239.12 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1334.44 │ 949.07  │ 1172.64 │ 1010.39 │ 574.07  │ 967.49  │ 1279.15 │ 778.52  │ 987.80  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3960752919.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_32.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_32_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1a4fd-30c2-482c-94d4-7d8264874c45",
   "metadata": {},
   "source": [
    "### MLP2L - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "509d5b55-a71e-4af0-aea6-35a9aacdbe9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\1602348056.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                    6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                           \n",
      "0                              -  11 / 1370.7 / 26.6  44 / 1222.0 / 25.3   3 / 1384.0 / 25.7  30 / 1279.9 / 26.2  17 / 1210.8 / 25.3   51 / 1211.7 / 25.4  39 / 1265.9 / 25.7   4 / 1224.2 / 25.2  38 / 1295.4 / 25.8\n",
      "1             49 / 1335.2 / 26.7                   -  100 / 958.6 / 24.6  99 / 1076.4 / 25.2  68 / 1205.7 / 25.9  94 / 1172.1 / 25.6  100 / 1130.6 / 25.3  100 / 811.1 / 24.5  92 / 1170.2 / 25.8   99 / 889.6 / 24.8\n",
      "2             36 / 1279.2 / 25.9   4 / 1246.9 / 25.8                   -  57 / 1100.0 / 25.0  37 / 1262.5 / 25.8  40 / 1311.7 / 25.6   74 / 1253.0 / 25.6  61 / 1149.5 / 25.7  70 / 1212.4 / 25.4  52 / 1245.3 / 25.9\n",
      "3             60 / 1277.3 / 25.9  71 / 1198.2 / 26.0  81 / 1167.7 / 25.3                   -  33 / 1272.5 / 25.8  90 / 1042.9 / 24.9   50 / 1304.9 / 25.9  37 / 1189.8 / 25.4  59 / 1219.7 / 25.5  64 / 1157.0 / 25.5\n",
      "4             26 / 1339.8 / 26.2  63 / 1132.0 / 26.0  66 / 1138.0 / 25.1  26 / 1278.1 / 25.8                   -  72 / 1216.6 / 25.4   93 / 1123.1 / 25.1   99 / 946.0 / 24.7  56 / 1255.7 / 25.6  73 / 1248.1 / 25.9\n",
      "5             96 / 1077.2 / 25.4  83 / 1208.5 / 26.3  62 / 1238.9 / 25.5  64 / 1165.1 / 25.1  31 / 1280.5 / 25.7                   -   60 / 1123.9 / 25.4  76 / 1221.4 / 25.8  63 / 1299.6 / 25.7   8 / 1377.2 / 26.5\n",
      "6             83 / 1134.7 / 25.4  25 / 1313.3 / 26.1  65 / 1166.6 / 25.2  41 / 1288.2 / 25.4  78 / 1114.5 / 25.2  66 / 1179.6 / 25.3                    -  83 / 1147.1 / 25.4  66 / 1157.2 / 25.3  91 / 1135.6 / 25.4\n",
      "7             71 / 1246.4 / 25.8  51 / 1108.8 / 25.8  85 / 1057.9 / 25.0   5 / 1205.6 / 24.8   9 / 1219.3 / 25.4  72 / 1208.9 / 25.7   41 / 1305.0 / 26.0                   -  32 / 1217.0 / 25.5  91 / 1016.1 / 24.9\n",
      "8             49 / 1294.1 / 26.2  46 / 1074.8 / 25.8  81 / 1023.4 / 24.9   90 / 994.3 / 25.0  52 / 1301.4 / 26.1  54 / 1222.4 / 25.5   46 / 1224.6 / 25.8  73 / 1180.4 / 25.8                   -  43 / 1237.0 / 25.8\n",
      "9             73 / 1203.7 / 26.1   59 / 977.7 / 26.1   92 / 973.8 / 25.2   83 / 976.5 / 24.9  100 / 705.5 / 24.4   94 / 948.6 / 24.9   82 / 1197.0 / 25.9   97 / 833.4 / 24.5   95 / 974.2 / 25.0                   -\n",
      "\n",
      "Total successful attacks: 5495 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_64_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  11 │  44 │   3 │  30 │  17 │  51 │  39 │   4 │  38 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  49 │   0 │ 100 │  99 │  68 │  94 │ 100 │ 100 │  92 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  36 │   4 │   0 │  57 │  37 │  40 │  74 │  61 │  70 │  52 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  60 │  71 │  81 │   0 │  33 │  90 │  50 │  37 │  59 │  64 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  26 │  63 │  66 │  26 │   0 │  72 │  93 │  99 │  56 │  73 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  96 │  83 │  62 │  64 │  31 │   0 │  60 │  76 │  63 │   8 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  83 │  25 │  65 │  41 │  78 │  66 │   0 │  83 │  66 │  91 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  71 │  51 │  85 │   5 │   9 │  72 │  41 │   0 │  32 │  91 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  49 │  46 │  81 │  90 │  52 │  54 │  46 │  73 │   0 │  43 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  73 │  59 │  92 │  83 │ 100 │  94 │  82 │  97 │  95 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ 24.0 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ 25.0 │ -    │ 24.0 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 25.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.6 │ 25.3 │ 25.7 │ 26.2 │ 25.3 │ 25.4 │ 25.7 │ 25.2 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.7 │ -    │ 24.6 │ 25.2 │ 25.9 │ 25.6 │ 25.3 │ 24.5 │ 25.8 │ 24.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.9 │ 25.8 │ -    │ 25.0 │ 25.8 │ 25.6 │ 25.6 │ 25.7 │ 25.4 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.9 │ 26.0 │ 25.3 │ -    │ 25.8 │ 24.9 │ 25.9 │ 25.4 │ 25.5 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.2 │ 26.0 │ 25.1 │ 25.8 │ -    │ 25.4 │ 25.1 │ 24.7 │ 25.6 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.4 │ 26.3 │ 25.5 │ 25.1 │ 25.7 │ -    │ 25.4 │ 25.8 │ 25.7 │ 26.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.4 │ 26.1 │ 25.2 │ 25.4 │ 25.2 │ 25.3 │ -    │ 25.4 │ 25.3 │ 25.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.8 │ 25.8 │ 25.0 │ 24.8 │ 25.4 │ 25.7 │ 26.0 │ -    │ 25.5 │ 24.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.2 │ 25.8 │ 24.9 │ 25.0 │ 26.1 │ 25.5 │ 25.8 │ 25.8 │ -    │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.1 │ 26.1 │ 25.2 │ 24.9 │ 24.4 │ 24.9 │ 25.9 │ 24.5 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤════════╤════════╤════════╤════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4      │ 5      │ 6      │ 7      │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪════════╪════════╪════════╪════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 1202.71 │ 378.81 │ 1224.25 │ 670.76 │ 723.11 │ 697.80 │ 801.36 │ 715.14 │ 746.78  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            1 │ 1000.15 │ -       │ 593.40 │ 739.45  │ 757.01 │ 784.33 │ 782.87 │ 420.30 │ 707.04 │ 373.80  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            2 │ 813.50  │ 1016.82 │ -      │ 380.87  │ 924.84 │ 945.50 │ 760.26 │ 460.67 │ 663.36 │ 738.66  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            3 │ 875.67  │ 267.84  │ 672.61 │ -       │ 685.41 │ 328.53 │ 829.08 │ 449.88 │ 683.56 │ 533.42  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            4 │ 951.91  │ 759.74  │ 573.24 │ 753.71  │ -      │ 758.50 │ 512.66 │ 465.92 │ 780.14 │ 437.22  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            5 │ 513.28  │ 746.29  │ 701.32 │ 668.60  │ 631.42 │ -      │ 464.29 │ 521.14 │ 780.01 │ 1000.89 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            6 │ 463.85  │ 798.85  │ 498.16 │ 847.89  │ 333.16 │ 451.04 │ -      │ 557.03 │ 609.08 │ 402.75  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            7 │ 919.98  │ 541.31  │ 499.79 │ 818.01  │ 814.60 │ 650.50 │ 935.29 │ -      │ 772.27 │ 547.36  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            8 │ 700.00  │ 447.22  │ 371.35 │ 492.84  │ 756.80 │ 690.49 │ 600.16 │ 660.29 │ -      │ 673.86  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            9 │ 769.48  │ 431.37  │ 471.36 │ 279.24  │ 252.78 │ 301.71 │ 727.48 │ 391.13 │ 394.69 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧════════╧════════╧════════╧════════╧════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1512.33 │ 1523.62 │ 1517.36 │ 1520.28 │ 1520.48 │ 1513.53 │ 1525.02 │ 1501.43 │ 1520.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1519.87 │ -       │ 1271.91 │ 1471.23 │ 1519.56 │ 1519.32 │ 1498.02 │ 1347.54 │ 1511.99 │ 1356.11 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1517.04 │ 1516.23 │ -       │ 1517.22 │ 1519.63 │ 1522.59 │ 1522.97 │ 1517.52 │ 1520.69 │ 1518.59 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1519.21 │ 1516.74 │ 1501.92 │ -       │ 1518.98 │ 1522.30 │ 1521.50 │ 1518.37 │ 1518.23 │ 1521.47 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1518.75 │ 1520.02 │ 1520.52 │ 1525.03 │ -       │ 1515.73 │ 1523.75 │ 1379.73 │ 1520.69 │ 1520.52 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1512.42 │ 1521.98 │ 1522.62 │ 1522.81 │ 1512.76 │ -       │ 1522.31 │ 1521.34 │ 1517.70 │ 1519.19 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1517.57 │ 1516.82 │ 1473.58 │ 1519.18 │ 1518.66 │ 1523.46 │ -       │ 1523.18 │ 1511.91 │ 1524.14 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1516.38 │ 1440.60 │ 1526.00 │ 1380.90 │ 1468.65 │ 1522.69 │ 1518.30 │ -       │ 1511.08 │ 1511.19 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1514.29 │ 1519.69 │ 1469.71 │ 1513.92 │ 1519.66 │ 1521.19 │ 1517.38 │ 1517.60 │ -       │ 1519.14 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1511.56 │ 1446.18 │ 1516.68 │ 1521.15 │ 1420.74 │ 1470.95 │ 1516.02 │ 1429.84 │ 1510.83 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1370.68 │ 1222.04 │ 1383.96 │ 1279.89 │ 1210.76 │ 1211.73 │ 1265.87 │ 1224.17 │ 1295.40 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1335.15 │ -       │ 958.59  │ 1076.36 │ 1205.65 │ 1172.07 │ 1130.58 │ 811.09  │ 1170.17 │ 889.60  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1279.23 │ 1246.92 │ -       │ 1100.04 │ 1262.54 │ 1311.70 │ 1253.01 │ 1149.46 │ 1212.40 │ 1245.33 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1277.33 │ 1198.23 │ 1167.68 │ -       │ 1272.45 │ 1042.89 │ 1304.86 │ 1189.81 │ 1219.67 │ 1157.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1339.82 │ 1131.97 │ 1138.00 │ 1278.10 │ -       │ 1216.63 │ 1123.08 │ 945.99  │ 1255.68 │ 1248.07 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1077.15 │ 1208.51 │ 1238.87 │ 1165.06 │ 1280.53 │ -       │ 1123.90 │ 1221.41 │ 1299.58 │ 1377.16 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1134.69 │ 1313.30 │ 1166.65 │ 1288.22 │ 1114.46 │ 1179.63 │ -       │ 1147.07 │ 1157.17 │ 1135.60 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1246.35 │ 1108.83 │ 1057.93 │ 1205.56 │ 1219.31 │ 1208.95 │ 1305.01 │ -       │ 1217.02 │ 1016.10 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1294.10 │ 1074.78 │ 1023.45 │ 994.27  │ 1301.41 │ 1222.38 │ 1224.60 │ 1180.39 │ -       │ 1236.95 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1203.70 │ 977.67  │ 973.83  │ 976.55  │ 705.50  │ 948.58  │ 1196.97 │ 833.38  │ 974.24  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\1602348056.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_64.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_64_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0133466-0148-41a4-9871-a1e3156276e6",
   "metadata": {},
   "source": [
    "### MLP2L - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "51a6abf4-4a16-4889-be65-0deb4f02bc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3067401887.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                    8                   9\n",
      "true_label                                                                                                                                                                                                           \n",
      "0                              -                   -  39 / 1246.1 / 25.4                   -  18 / 1376.3 / 26.5   3 / 1492.3 / 26.0  40 / 1236.9 / 25.5   4 / 1438.1 / 25.8    1 / 1517.3 / 26.0  22 / 1362.2 / 25.9\n",
      "1             93 / 1134.5 / 26.2                   -  100 / 837.3 / 24.3  100 / 980.3 / 24.8   78 / 953.7 / 25.1  97 / 1028.3 / 25.0  100 / 856.9 / 24.7   98 / 852.3 / 24.5  100 / 1017.6 / 25.1  100 / 755.4 / 24.4\n",
      "2             42 / 1259.7 / 25.9                   -                   -  23 / 1297.2 / 25.4   6 / 1254.9 / 26.0  16 / 1311.9 / 25.8  76 / 1284.3 / 25.7  25 / 1297.2 / 26.0   78 / 1242.3 / 25.5  59 / 1195.4 / 25.7\n",
      "3             77 / 1205.3 / 25.8  30 / 1305.4 / 26.2  91 / 1078.3 / 25.1                   -   6 / 1206.6 / 25.7  88 / 1118.9 / 25.0  45 / 1306.6 / 25.9  31 / 1257.1 / 25.5   68 / 1128.0 / 25.3  78 / 1142.4 / 25.5\n",
      "4             38 / 1333.3 / 26.2  15 / 1284.2 / 26.1  77 / 1105.4 / 25.2  11 / 1373.2 / 26.2                   -  45 / 1234.7 / 25.5  96 / 1136.3 / 25.2  76 / 1232.9 / 25.4   66 / 1241.6 / 25.5  95 / 1050.0 / 25.2\n",
      "5             99 / 1023.4 / 25.3  39 / 1329.7 / 26.5  62 / 1249.7 / 25.5  69 / 1249.6 / 25.3  45 / 1231.1 / 25.6                   -  50 / 1157.4 / 25.4  28 / 1372.6 / 26.0   31 / 1370.0 / 25.9  18 / 1334.8 / 25.9\n",
      "6             92 / 1175.2 / 25.6   8 / 1415.6 / 26.4  66 / 1094.2 / 25.0   2 / 1427.0 / 26.0  43 / 1272.8 / 25.6  47 / 1225.1 / 25.2                   -  36 / 1276.5 / 25.8   59 / 1225.8 / 25.5  50 / 1243.6 / 25.6\n",
      "7             92 / 1026.6 / 25.3  40 / 1103.3 / 25.7   87 / 872.5 / 24.6  60 / 1185.6 / 25.1  36 / 1154.0 / 25.6   87 / 970.6 / 24.8  70 / 1223.6 / 25.9                   -   47 / 1130.3 / 25.3   99 / 911.6 / 24.6\n",
      "8             78 / 1141.5 / 25.8  24 / 1177.1 / 25.8   84 / 980.9 / 24.9  67 / 1125.7 / 25.2  38 / 1259.0 / 26.0  71 / 1163.5 / 25.3  51 / 1227.2 / 25.9  42 / 1242.8 / 25.9                    -  41 / 1236.6 / 25.8\n",
      "9             87 / 1171.8 / 26.1  11 / 1088.8 / 26.1  76 / 1134.7 / 25.6  91 / 1154.4 / 25.5   99 / 644.8 / 24.3  95 / 1079.1 / 25.2  65 / 1134.7 / 25.8  89 / 1100.5 / 25.1   91 / 1090.5 / 25.3                   -\n",
      "\n",
      "Total successful attacks: 5013 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_128_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │  39 │   0 │  18 │   3 │  40 │   4 │   1 │  22 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  93 │   0 │ 100 │ 100 │  78 │  97 │ 100 │  98 │ 100 │ 100 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  42 │   0 │   0 │  23 │   6 │  16 │  76 │  25 │  78 │  59 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  77 │  30 │  91 │   0 │   6 │  88 │  45 │  31 │  68 │  78 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  38 │  15 │  77 │  11 │   0 │  45 │  96 │  76 │  66 │  95 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  99 │  39 │  62 │  69 │  45 │   0 │  50 │  28 │  31 │  18 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  92 │   8 │  66 │   2 │  43 │  47 │   0 │  36 │  59 │  50 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  92 │  40 │  87 │  60 │  36 │  87 │  70 │   0 │  47 │  99 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  78 │  24 │  84 │  67 │  38 │  71 │  51 │  42 │   0 │  41 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  87 │  11 │  76 │  91 │  99 │  95 │  65 │  89 │  91 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 24.0 │ -    │ 26.0 │ 26.0 │ 24.0 │ 25.0 │ 26.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ -    │ -    │ 24.0 │ 26.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 24.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 25.0 │ 23.0 │ 25.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 25.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 26.0 │ 24.0 │ 26.0 │ 24.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.4 │ -    │ 26.5 │ 26.0 │ 25.5 │ 25.8 │ 26.0 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.2 │ -    │ 24.3 │ 24.8 │ 25.1 │ 25.0 │ 24.7 │ 24.5 │ 25.1 │ 24.4 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.9 │ -    │ -    │ 25.4 │ 26.0 │ 25.8 │ 25.7 │ 26.0 │ 25.5 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.8 │ 26.2 │ 25.1 │ -    │ 25.7 │ 25.0 │ 25.9 │ 25.5 │ 25.3 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.2 │ 26.1 │ 25.2 │ 26.2 │ -    │ 25.5 │ 25.2 │ 25.4 │ 25.5 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.3 │ 26.5 │ 25.5 │ 25.3 │ 25.6 │ -    │ 25.4 │ 26.0 │ 25.9 │ 25.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.6 │ 26.4 │ 25.0 │ 26.0 │ 25.6 │ 25.2 │ -    │ 25.8 │ 25.5 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.3 │ 25.7 │ 24.6 │ 25.1 │ 25.6 │ 24.8 │ 25.9 │ -    │ 25.3 │ 24.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 25.8 │ 25.8 │ 24.9 │ 25.2 │ 26.0 │ 25.3 │ 25.9 │ 25.9 │ -    │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.1 │ 26.1 │ 25.6 │ 25.5 │ 24.3 │ 25.2 │ 25.8 │ 25.1 │ 25.3 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤═════════╤════════╤═════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0      │ 1       │ 2      │ 3       │ 4       │ 5       │ 6      │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪════════╪═════════╪════════╪═════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -      │ -       │ 610.64 │ -       │ 1054.17 │ 1460.92 │ 680.67 │ 1320.75 │ 1517.34 │ 1155.83 │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 781.64 │ -       │ 376.09 │ 601.09  │ 630.93  │ 667.65  │ 499.74 │ 428.73  │ 609.32  │ 390.05  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 540.70 │ -       │ -      │ 697.83  │ 1046.69 │ 948.32  │ 550.48 │ 615.28  │ 783.60  │ 671.28  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 465.48 │ 563.62  │ 388.17 │ -       │ 1060.38 │ 528.67  │ 729.76 │ 612.16  │ 658.78  │ 457.37  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 717.14 │ 1068.92 │ 473.01 │ 1065.60 │ -       │ 655.94  │ 433.54 │ 584.79  │ 658.64  │ 283.99  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 460.82 │ 781.61  │ 734.51 │ 458.64  │ 532.10  │ -       │ 498.61 │ 1068.09 │ 986.04  │ 995.79  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 330.63 │ 1311.37 │ 589.59 │ 1344.53 │ 779.13  │ 818.34  │ -      │ 878.48  │ 681.17  │ 402.69  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 51.52  │ 525.42  │ 200.91 │ 491.06  │ 499.53  │ 296.63  │ 732.56 │ -       │ 588.71  │ 200.85  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 607.27 │ 662.14  │ 423.57 │ 648.06  │ 690.67  │ 632.99  │ 666.86 │ 732.59  │ -       │ 519.63  │\n",
      "├──────────────┼────────┼─────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 545.01 │ 770.31  │ 442.95 │ 425.91  │ 49.99   │ 357.01  │ 609.82 │ 384.21  │ 473.90  │ -       │\n",
      "╘══════════════╧════════╧═════════╧════════╧═════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1526.00 │ -       │ 1517.43 │ 1510.54 │ 1522.32 │ 1503.08 │ 1517.34 │ 1507.99 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1468.89 │ -       │ 1272.04 │ 1275.24 │ 1394.22 │ 1493.32 │ 1165.19 │ 1407.21 │ 1519.93 │ 1260.73 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1518.65 │ -       │ -       │ 1523.96 │ 1436.31 │ 1516.55 │ 1522.74 │ 1513.43 │ 1517.58 │ 1518.37 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1520.09 │ 1517.61 │ 1512.13 │ -       │ 1510.54 │ 1525.56 │ 1522.07 │ 1520.44 │ 1521.11 │ 1519.26 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1521.48 │ 1521.02 │ 1519.88 │ 1517.06 │ -       │ 1521.79 │ 1522.44 │ 1524.46 │ 1518.01 │ 1520.31 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1509.57 │ 1518.94 │ 1523.61 │ 1519.77 │ 1519.79 │ -       │ 1511.67 │ 1520.59 │ 1518.28 │ 1514.23 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1519.21 │ 1481.86 │ 1520.01 │ 1509.57 │ 1521.31 │ 1511.60 │ -       │ 1524.23 │ 1503.93 │ 1519.13 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1506.72 │ 1501.28 │ 1467.81 │ 1525.38 │ 1496.03 │ 1480.35 │ 1519.14 │ -       │ 1512.57 │ 1519.87 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1517.73 │ 1499.24 │ 1411.34 │ 1499.41 │ 1518.59 │ 1519.08 │ 1515.36 │ 1514.92 │ -       │ 1520.40 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1517.60 │ 1342.27 │ 1518.01 │ 1524.57 │ 1518.44 │ 1524.98 │ 1513.91 │ 1525.35 │ 1520.78 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1246.13 │ -       │ 1376.30 │ 1492.27 │ 1236.90 │ 1438.13 │ 1517.34 │ 1362.24 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1134.45 │ -       │ 837.30  │ 980.30  │ 953.67  │ 1028.33 │ 856.87  │ 852.32  │ 1017.64 │ 755.38  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1259.73 │ -       │ -       │ 1297.15 │ 1254.91 │ 1311.93 │ 1284.33 │ 1297.24 │ 1242.27 │ 1195.43 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1205.28 │ 1305.42 │ 1078.32 │ -       │ 1206.57 │ 1118.89 │ 1306.59 │ 1257.09 │ 1128.00 │ 1142.42 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1333.27 │ 1284.16 │ 1105.41 │ 1373.21 │ -       │ 1234.72 │ 1136.26 │ 1232.90 │ 1241.57 │ 1050.04 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1023.42 │ 1329.74 │ 1249.74 │ 1249.56 │ 1231.10 │ -       │ 1157.43 │ 1372.57 │ 1369.95 │ 1334.77 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1175.17 │ 1415.60 │ 1094.16 │ 1427.05 │ 1272.81 │ 1225.11 │ -       │ 1276.51 │ 1225.77 │ 1243.55 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1026.57 │ 1103.26 │ 872.49  │ 1185.57 │ 1154.03 │ 970.63  │ 1223.64 │ -       │ 1130.33 │ 911.56  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1141.55 │ 1177.15 │ 980.90  │ 1125.65 │ 1259.01 │ 1163.52 │ 1227.21 │ 1242.77 │ -       │ 1236.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1171.85 │ 1088.79 │ 1134.72 │ 1154.41 │ 644.83  │ 1079.14 │ 1134.74 │ 1100.54 │ 1090.45 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3067401887.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_128.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_128_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87a1c0-6825-40ea-98d9-b19d14a64775",
   "metadata": {},
   "source": [
    "### MLP2L - 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "458d52fc-7ea4-400e-bb7f-e7c861b34ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3263113702.py:49: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                          \n",
      "0                              -   4 / 1400.0 / 27.0  39 / 1214.3 / 25.2   1 / 1488.3 / 26.0  36 / 1206.9 / 26.0   2 / 1395.0 / 25.5  45 / 1230.6 / 25.5  37 / 1265.7 / 25.7   8 / 1161.9 / 25.2  19 / 1292.4 / 25.8\n",
      "1             82 / 1285.8 / 26.7                   -  100 / 842.8 / 24.3   97 / 872.8 / 24.4   97 / 845.5 / 24.8  93 / 1053.1 / 25.1  100 / 973.0 / 25.0  100 / 924.0 / 24.8  93 / 1028.3 / 25.1   97 / 924.2 / 24.9\n",
      "2             18 / 1328.5 / 25.9                   -                   -  48 / 1227.0 / 25.4   5 / 1336.3 / 26.2  10 / 1404.2 / 25.8  49 / 1295.5 / 25.7  46 / 1177.8 / 25.7  63 / 1183.5 / 25.5  35 / 1223.4 / 25.7\n",
      "3             30 / 1325.8 / 26.0  16 / 1278.7 / 26.3  52 / 1265.6 / 25.4                   -  22 / 1286.8 / 26.0  90 / 1139.3 / 25.1  43 / 1339.6 / 26.0  24 / 1267.8 / 25.6  67 / 1197.6 / 25.4  61 / 1213.1 / 25.6\n",
      "4              1 / 1411.3 / 26.0                   -  66 / 1079.7 / 25.1  10 / 1256.8 / 25.8                   -  24 / 1338.3 / 25.9  68 / 1174.1 / 25.4  89 / 1169.6 / 25.3  53 / 1251.9 / 25.6  83 / 1152.9 / 25.6\n",
      "5             95 / 1201.9 / 25.7  22 / 1366.8 / 26.5  27 / 1323.2 / 25.6  30 / 1198.2 / 25.1  56 / 1230.4 / 25.6                   -  34 / 1228.0 / 25.6  50 / 1282.3 / 26.0  32 / 1231.1 / 25.5   7 / 1418.1 / 26.3\n",
      "6             61 / 1205.2 / 25.6  20 / 1341.6 / 26.1  69 / 1108.9 / 25.0   9 / 1248.5 / 25.2  82 / 1153.8 / 25.4  51 / 1201.3 / 25.2                   -  54 / 1213.1 / 25.6  70 / 1138.9 / 25.2  60 / 1246.7 / 25.6\n",
      "7             68 / 1324.6 / 25.9  30 / 1243.4 / 26.0  92 / 1080.7 / 25.1  36 / 1189.5 / 25.1  29 / 1159.1 / 25.6  33 / 1199.8 / 25.4  90 / 1203.4 / 25.8                   -  59 / 1185.1 / 25.4  90 / 1089.0 / 25.1\n",
      "8             31 / 1285.3 / 26.2   6 / 1262.5 / 26.2  73 / 1172.6 / 25.3  50 / 1188.9 / 25.3  41 / 1245.9 / 26.0  32 / 1229.2 / 25.5  24 / 1380.8 / 26.1  44 / 1290.2 / 26.0                   -  19 / 1269.7 / 25.8\n",
      "9             62 / 1296.6 / 26.3  15 / 1171.4 / 26.3  79 / 1117.8 / 25.6  67 / 1139.5 / 25.4   97 / 808.2 / 24.7  92 / 1043.8 / 25.1  60 / 1223.7 / 26.0  91 / 1069.4 / 24.9  92 / 1038.9 / 25.2                   -\n",
      "\n",
      "Total successful attacks: 4454 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/MLP2L_256_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   4 │  39 │   1 │  36 │   2 │  45 │  37 │   8 │  19 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │  82 │   0 │ 100 │  97 │  97 │  93 │ 100 │ 100 │  93 │  97 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  18 │   0 │   0 │  48 │   5 │  10 │  49 │  46 │  63 │  35 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  30 │  16 │  52 │   0 │  22 │  90 │  43 │  24 │  67 │  61 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   1 │   0 │  66 │  10 │   0 │  24 │  68 │  89 │  53 │  83 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  95 │  22 │  27 │  30 │  56 │   0 │  34 │  50 │  32 │   7 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  61 │  20 │  69 │   9 │  82 │  51 │   0 │  54 │  70 │  60 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  68 │  30 │  92 │  36 │  29 │  33 │  90 │   0 │  59 │  90 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  31 │   6 │  73 │  50 │  41 │  32 │  24 │  44 │   0 │  19 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  62 │  15 │  79 │  67 │  97 │  92 │  60 │  91 │  92 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 23.0 │ 26.0 │ 24.0 │ 25.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ -    │ -    │ 24.0 │ 25.0 │ 25.0 │ 25.0 │ 23.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 25.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ -    │ 24.0 │ 24.0 │ -    │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ 25.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.0 │ 25.0 │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 25.0 │ 24.0 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 25.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ -    │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 25.2 │ 26.0 │ 26.0 │ 25.5 │ 25.5 │ 25.7 │ 25.2 │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.7 │ -    │ 24.3 │ 24.4 │ 24.8 │ 25.1 │ 25.0 │ 24.8 │ 25.1 │ 24.9 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.9 │ -    │ -    │ 25.4 │ 26.2 │ 25.8 │ 25.7 │ 25.7 │ 25.5 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 26.3 │ 25.4 │ -    │ 26.0 │ 25.1 │ 26.0 │ 25.6 │ 25.4 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ -    │ 25.1 │ 25.8 │ -    │ 25.9 │ 25.4 │ 25.3 │ 25.6 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.7 │ 26.5 │ 25.6 │ 25.1 │ 25.6 │ -    │ 25.6 │ 26.0 │ 25.5 │ 26.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.6 │ 26.0 │ 25.0 │ 25.2 │ 25.4 │ 25.2 │ -    │ 25.6 │ 25.2 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.9 │ 26.0 │ 25.1 │ 25.1 │ 25.6 │ 25.4 │ 25.8 │ -    │ 25.4 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.2 │ 26.2 │ 25.3 │ 25.3 │ 26.0 │ 25.5 │ 26.1 │ 26.0 │ -    │ 25.8 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.3 │ 26.3 │ 25.6 │ 25.4 │ 24.7 │ 25.1 │ 26.0 │ 24.9 │ 25.2 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤════════╤═════════╤═════════╤════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2      │ 3       │ 4      │ 5       │ 6       │ 7      │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪════════╪═════════╪═════════╪════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 1244.58 │ 396.05 │ 1488.32 │ 544.01 │ 1308.05 │ 453.69  │ 599.98 │ 628.91 │ 846.23  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            1 │ 783.25  │ -       │ 618.15 │ 550.51  │ 501.68 │ 654.43  │ 549.56  │ 424.62 │ 518.48 │ 243.84  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            2 │ 843.15  │ -       │ -      │ 674.11  │ 944.44 │ 1169.40 │ 852.67  │ 238.15 │ 456.15 │ 686.55  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            3 │ 801.44  │ 860.13  │ 816.62 │ -       │ 684.62 │ 487.83  │ 745.55  │ 524.59 │ 382.98 │ 559.41  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            4 │ 1411.26 │ -       │ 555.41 │ 768.39  │ -      │ 683.95  │ 363.26  │ 713.33 │ 829.69 │ 580.32  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            5 │ 629.35  │ 1018.67 │ 885.93 │ 635.23  │ 565.22 │ -       │ 673.46  │ 789.56 │ 481.77 │ 1175.04 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            6 │ 609.82  │ 1067.94 │ 409.51 │ 852.73  │ 550.79 │ 571.29  │ -       │ 635.89 │ 542.37 │ 423.94  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            7 │ 801.45  │ 724.83  │ 433.52 │ 640.26  │ 543.20 │ 774.50  │ 698.45  │ -      │ 604.73 │ 497.89  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            8 │ 610.89  │ 897.24  │ 474.92 │ 418.18  │ 658.02 │ 689.80  │ 1038.42 │ 417.61 │ -      │ 868.86  │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┼─────────┤\n",
      "│            9 │ 737.18  │ 833.73  │ 473.44 │ 629.62  │ 294.94 │ 428.20  │ 648.97  │ 250.26 │ 698.70 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧════════╧═════════╧═════════╧════════╧════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1514.52 │ 1525.38 │ 1488.32 │ 1505.81 │ 1481.97 │ 1518.79 │ 1521.56 │ 1516.30 │ 1516.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1516.19 │ -       │ 1142.26 │ 1518.26 │ 1365.34 │ 1499.26 │ 1463.64 │ 1462.40 │ 1492.70 │ 1496.75 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1511.26 │ -       │ -       │ 1526.17 │ 1521.55 │ 1522.80 │ 1523.47 │ 1523.30 │ 1521.17 │ 1515.77 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1514.73 │ 1514.01 │ 1522.63 │ -       │ 1511.21 │ 1522.14 │ 1520.04 │ 1520.18 │ 1512.52 │ 1521.47 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1411.26 │ -       │ 1523.30 │ 1521.68 │ -       │ 1515.59 │ 1510.94 │ 1522.43 │ 1522.24 │ 1504.74 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1523.87 │ 1501.47 │ 1517.58 │ 1506.36 │ 1519.70 │ -       │ 1521.78 │ 1523.49 │ 1518.54 │ 1519.87 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1512.93 │ 1514.68 │ 1508.33 │ 1476.76 │ 1503.48 │ 1457.14 │ -       │ 1512.43 │ 1511.31 │ 1515.17 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1521.43 │ 1517.48 │ 1508.77 │ 1498.03 │ 1515.49 │ 1521.29 │ 1522.57 │ -       │ 1516.84 │ 1520.75 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1517.64 │ 1492.40 │ 1523.12 │ 1520.73 │ 1521.80 │ 1522.81 │ 1513.28 │ 1523.98 │ -       │ 1519.15 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1522.03 │ 1455.80 │ 1493.16 │ 1512.23 │ 1437.46 │ 1517.41 │ 1520.86 │ 1514.08 │ 1522.63 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1399.98 │ 1214.32 │ 1488.32 │ 1206.89 │ 1395.01 │ 1230.56 │ 1265.70 │ 1161.87 │ 1292.41 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1285.76 │ -       │ 842.83  │ 872.79  │ 845.47  │ 1053.08 │ 973.00  │ 924.01  │ 1028.29 │ 924.24  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1328.51 │ -       │ -       │ 1226.97 │ 1336.30 │ 1404.17 │ 1295.52 │ 1177.78 │ 1183.55 │ 1223.41 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1325.78 │ 1278.70 │ 1265.64 │ -       │ 1286.77 │ 1139.33 │ 1339.56 │ 1267.79 │ 1197.57 │ 1213.11 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1411.26 │ -       │ 1079.70 │ 1256.83 │ -       │ 1338.26 │ 1174.12 │ 1169.59 │ 1251.94 │ 1152.94 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1201.90 │ 1366.79 │ 1323.23 │ 1198.22 │ 1230.42 │ -       │ 1228.02 │ 1282.34 │ 1231.14 │ 1418.10 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1205.24 │ 1341.57 │ 1108.86 │ 1248.54 │ 1153.84 │ 1201.28 │ -       │ 1213.06 │ 1138.88 │ 1246.69 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1324.56 │ 1243.45 │ 1080.69 │ 1189.46 │ 1159.12 │ 1199.78 │ 1203.35 │ -       │ 1185.11 │ 1089.03 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1285.25 │ 1262.46 │ 1172.62 │ 1188.92 │ 1245.87 │ 1229.22 │ 1380.83 │ 1290.20 │ -       │ 1269.65 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1296.59 │ 1171.41 │ 1117.83 │ 1139.48 │ 808.17  │ 1043.81 │ 1223.69 │ 1069.40 │ 1038.86 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_3412\\3263113702.py:239: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_MLP2L_256.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/MLP2L_256_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1     # FGSM step size\n",
    "MAX_ITERS  = 5       # FGSM iterations\n",
    "BIN_STEPS  = 20      # binary-search iterations\n",
    "MAX_L2     = 1500    # maximum allowed L2 magnitude in pixel space\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning,\n",
    "                        message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    flat = x01.reshape(-1) if x01.ndim == 2 else x01\n",
    "    return torch.from_numpy(flat[None]).float()\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# Round and format L2 magnitude stats to 2 decimal places\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653516b-bc36-4c64-8497-bedfa705df59",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe090ce7-be01-418a-bd87-7e8763f4d354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_2912\\1560704599.py:56: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                  0                  1                   2                   3                   4                   5                  6                   7                   8                  9\n",
      "true_label                                                                                                                                                                                                      \n",
      "0                             -                  -   9 / 1398.3 / 25.7                   -   3 / 1294.0 / 26.0  11 / 1389.6 / 25.6                  -                   -  20 / 1250.3 / 25.4  2 / 1308.2 / 26.0\n",
      "1                             -                  -  70 / 1309.3 / 25.8  15 / 1430.7 / 26.5  15 / 1224.5 / 25.8   1 / 1480.9 / 26.0  6 / 1340.2 / 25.7                   -  42 / 1219.9 / 25.6                  -\n",
      "2                             -                  -                   -   9 / 1279.6 / 25.6                   -   1 / 1520.3 / 26.0                  -    1 / 984.9 / 25.0   6 / 1406.4 / 25.8                  -\n",
      "3             1 / 1389.6 / 26.0  6 / 1436.6 / 26.7    1 / 973.1 / 25.0                   -                   -   1 / 1299.5 / 25.0  1 / 1120.1 / 26.0                   -   8 / 1272.8 / 25.8                  -\n",
      "4                             -  1 / 1424.4 / 27.0  19 / 1409.2 / 25.9   8 / 1443.0 / 26.2                   -   7 / 1424.0 / 26.0                  -  11 / 1416.3 / 26.1   7 / 1489.6 / 26.3  3 / 1475.1 / 26.7\n",
      "5             1 / 1496.2 / 26.0  8 / 1419.5 / 26.6                   -  13 / 1368.8 / 25.7   1 / 1487.5 / 27.0                   -  1 / 1357.1 / 26.0                   -   3 / 1359.2 / 25.7                  -\n",
      "6                             -                  -                   -   4 / 1503.9 / 26.0   7 / 1321.5 / 25.7                   -                  -                   -   3 / 1346.6 / 25.7                  -\n",
      "7                             -  6 / 1416.3 / 26.7   5 / 1262.4 / 25.6  18 / 1382.0 / 25.6                   -                   -                  -                   -  15 / 1390.5 / 25.9                  -\n",
      "8                             -  1 / 1094.6 / 26.0                   -  18 / 1374.9 / 25.8   4 / 1122.3 / 25.8   3 / 1364.5 / 25.7   1 / 671.5 / 25.0                   -                   -                  -\n",
      "9             3 / 1345.9 / 26.0  8 / 1321.5 / 26.9   1 / 1063.1 / 25.0  34 / 1355.6 / 25.9  73 / 1262.5 / 25.8  17 / 1437.1 / 26.4                  -  34 / 1271.3 / 25.4  43 / 1357.2 / 25.9                  -\n",
      "\n",
      "Total successful attacks: 610 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/CNN_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │   9 │   0 │   3 │  11 │   0 │   0 │  20 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   0 │   0 │  70 │  15 │  15 │   1 │   6 │   0 │  42 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │   0 │   0 │   0 │   9 │   0 │   1 │   0 │   1 │   6 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │   1 │   6 │   1 │   0 │   0 │   1 │   1 │   0 │   8 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   0 │   1 │  19 │   8 │   0 │   7 │   0 │  11 │   7 │   3 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │   1 │   8 │   0 │  13 │   1 │   0 │   1 │   0 │   3 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │   0 │   0 │   0 │   4 │   7 │   0 │   0 │   0 │   3 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │   0 │   6 │   5 │  18 │   0 │   0 │   0 │   0 │  15 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   0 │   1 │   0 │  18 │   4 │   3 │   1 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   3 │   8 │   1 │  34 │  73 │  17 │   0 │  34 │  43 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.0 │ -    │ 26.0 │ 25.0 │ -    │ -    │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ 25.0 │ 25.0 │ 25.0 │ 26.0 │ 25.0 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ -    │ -    │ 25.0 │ -    │ 26.0 │ -    │ 25.0 │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 26.0 │ 25.0 │ -    │ -    │ 25.0 │ 26.0 │ -    │ 24.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 27.0 │ 25.0 │ 26.0 │ -    │ 25.0 │ -    │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ 26.0 │ -    │ 25.0 │ 27.0 │ -    │ 26.0 │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ -    │ 26.0 │ 25.0 │ -    │ -    │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 26.0 │ 25.0 │ 25.0 │ -    │ -    │ -    │ -    │ 25.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 26.0 │ -    │ 25.0 │ 24.0 │ 25.0 │ 25.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 26.0 │ 25.0 │ 24.0 │ 24.0 │ 26.0 │ -    │ 24.0 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 26.0 │ -    │ 26.0 │ 26.0 │ -    │ -    │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ -    │ -    │ 27.0 │ -    │ 26.0 │ -    │ 25.0 │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 27.0 │ 25.0 │ -    │ -    │ 25.0 │ 26.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ -    │ 26.0 │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ -    │ 26.0 │ 26.0 │ -    │ -    │ -    │ 26.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 27.0 │ 26.0 │ 26.0 │ -    │ -    │ -    │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 26.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ 25.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 25.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.7 │ -    │ 26.0 │ 25.6 │ -    │ -    │ 25.4 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ -    │ 25.8 │ 26.5 │ 25.8 │ 26.0 │ 25.7 │ -    │ 25.6 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ -    │ -    │ -    │ 25.6 │ -    │ 26.0 │ -    │ 25.0 │ 25.8 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 26.7 │ 25.0 │ -    │ -    │ 25.0 │ 26.0 │ -    │ 25.8 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ -    │ 27.0 │ 25.9 │ 26.2 │ -    │ 26.0 │ -    │ 26.1 │ 26.3 │ 26.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ 26.6 │ -    │ 25.7 │ 27.0 │ -    │ 26.0 │ -    │ 25.7 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ -    │ -    │ -    │ 26.0 │ 25.7 │ -    │ -    │ -    │ 25.7 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 26.7 │ 25.6 │ 25.6 │ -    │ -    │ -    │ -    │ 25.9 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ 26.0 │ -    │ 25.8 │ 25.8 │ 25.7 │ 25.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.0 │ 26.9 │ 25.0 │ 25.9 │ 25.8 │ 26.4 │ -    │ 25.4 │ 25.9 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1089.84 │ -       │ 1241.10 │ 1206.92 │ -       │ -       │ 700.03  │ 1146.81 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ -       │ 1018.46 │ 1093.71 │ 1015.50 │ 1480.95 │ 906.75  │ -       │ 916.98  │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ -       │ -       │ -       │ 974.32  │ -       │ 1520.29 │ -       │ 984.93  │ 1225.43 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1389.59 │ 1294.47 │ 973.14  │ -       │ -       │ 1299.50 │ 1120.14 │ -       │ 594.26  │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1424.40 │ 1058.85 │ 1350.68 │ -       │ 1244.09 │ -       │ 1261.28 │ 1404.41 │ 1450.76 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1496.21 │ 1312.24 │ -       │ 1042.00 │ 1487.48 │ -       │ 1357.08 │ -       │ 1293.94 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ -       │ -       │ -       │ 1452.81 │ 1016.40 │ -       │ -       │ -       │ 1155.18 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ 1346.85 │ 1048.98 │ 1034.71 │ -       │ -       │ -       │ -       │ 1064.67 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ -       │ 1094.57 │ -       │ 1100.07 │ 799.73  │ 1214.05 │ 671.46  │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1008.08 │ 1126.38 │ 1063.14 │ 869.04  │ 740.28  │ 1280.35 │ -       │ 841.27  │ 1066.74 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1526.00 │ -       │ 1377.90 │ 1516.87 │ -       │ -       │ 1519.88 │ 1469.60 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ -       │ 1519.15 │ 1521.25 │ 1453.20 │ 1480.95 │ 1521.05 │ -       │ 1516.34 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ -       │ -       │ -       │ 1520.45 │ -       │ 1520.29 │ -       │ 984.93  │ 1517.11 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1389.59 │ 1511.03 │ 973.14  │ -       │ -       │ 1299.50 │ 1120.14 │ -       │ 1511.47 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1424.40 │ 1521.04 │ 1521.77 │ -       │ 1520.46 │ -       │ 1504.87 │ 1521.15 │ 1512.53 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1496.21 │ 1511.73 │ -       │ 1523.21 │ 1487.48 │ -       │ 1357.08 │ -       │ 1440.55 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ -       │ -       │ -       │ 1523.50 │ 1504.16 │ -       │ -       │ -       │ 1510.19 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ 1513.64 │ 1442.94 │ 1525.38 │ -       │ -       │ -       │ -       │ 1520.97 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ -       │ 1094.57 │ -       │ 1516.51 │ 1398.24 │ 1460.68 │ 671.46  │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1517.18 │ 1434.37 │ 1063.14 │ 1523.15 │ 1522.50 │ 1518.28 │ -       │ 1523.27 │ 1523.84 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1398.32 │ -       │ 1293.97 │ 1389.65 │ -       │ -       │ 1250.30 │ 1308.21 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ -       │ 1309.26 │ 1430.74 │ 1224.45 │ 1480.95 │ 1340.16 │ -       │ 1219.86 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ -       │ -       │ -       │ 1279.59 │ -       │ 1520.29 │ -       │ 984.93  │ 1406.43 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1389.59 │ 1436.64 │ 973.14  │ -       │ -       │ 1299.50 │ 1120.14 │ -       │ 1272.82 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ -       │ 1424.40 │ 1409.18 │ 1443.04 │ -       │ 1423.97 │ -       │ 1416.29 │ 1489.57 │ 1475.10 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1496.21 │ 1419.47 │ -       │ 1368.83 │ 1487.48 │ -       │ 1357.08 │ -       │ 1359.16 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ -       │ -       │ -       │ 1503.87 │ 1321.54 │ -       │ -       │ -       │ 1346.55 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ -       │ 1416.31 │ 1262.43 │ 1381.98 │ -       │ -       │ -       │ -       │ 1390.54 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ -       │ 1094.57 │ -       │ 1374.91 │ 1122.27 │ 1364.48 │ 671.46  │ -       │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1345.94 │ 1321.52 │ 1063.14 │ 1355.61 │ 1262.45 │ 1437.12 │ -       │ 1271.29 │ 1357.23 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_2912\\1560704599.py:248: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from torchvision import transforms\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_CNN.pt\"\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/CNN_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "# ──────────────── TRANSFORM FOR CNN INPUT ─────────────────────────────────\n",
    "transform_28x28 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((28, 28), interpolation=Image.BILINEAR),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos]  = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez        = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "model = torch.jit.load(MODEL_PATH, map_location=\"cpu\").eval()\n",
    "\n",
    "def to_model(x01: np.ndarray) -> torch.Tensor:\n",
    "    if x01.ndim == 1:\n",
    "        x01 = x01.reshape(28, 28)\n",
    "    img = (x01 * 255).astype(np.uint8)\n",
    "    tensor = transform_28x28(img)\n",
    "    return tensor.unsqueeze(0).float()  # (1, 1, 28, 28)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32),\n",
    "                            s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix  = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi     = np.rint(x_pix).astype(np.int16)\n",
    "    sign   = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total   = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = model(to_model(x0)).argmax().item()\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_tensor: torch.Tensor):\n",
    "                query_count[0] += 1\n",
    "                return model(x_tensor)\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "                if model_query(to_model(x)).argmax().item() == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm  = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)).argmax().item() == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)).argmax().item() != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)).argmax().item())\n",
    "            l2_final = np.linalg.norm(\n",
    "                x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28)\n",
    "            )\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\") \\\n",
    "                 .save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── build DataFrame & save CSV ──────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ─────────── enhanced summary matrix ──────────────────────────────────────\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843cc16-a0bf-4335-8f7f-a354f5ecfa22",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a54215-8ba3-4579-b0a7-28fd44083603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\837802935.py:46: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                  2                   3                  4                  5                   6                  7                  8                  9\n",
      "true_label                                                                                                                                                                                \n",
      "0                              -  19 / 964.1 / 24.6                   -  4 / 1079.6 / 25.2                  -   11 / 958.4 / 24.5                  -  13 / 878.0 / 24.8                  -\n",
      "1              2 / 1039.8 / 25.5  95 / 163.5 / 23.1   75 / 319.6 / 23.5  78 / 481.0 / 24.1  70 / 423.1 / 23.6   64 / 500.8 / 24.0  41 / 379.0 / 23.6  98 / 113.4 / 23.1  2 / 1311.1 / 26.0\n",
      "2              15 / 987.0 / 24.9                  -  12 / 1132.2 / 25.1   6 / 867.2 / 25.0  5 / 1067.4 / 24.8   23 / 998.7 / 25.0                  -  63 / 748.1 / 24.5  4 / 1098.0 / 25.2\n",
      "3              34 / 924.1 / 25.1  15 / 910.4 / 24.8                   -  7 / 1057.5 / 25.3  41 / 759.1 / 24.3   16 / 995.7 / 25.0   1 / 819.8 / 24.0  62 / 657.4 / 24.5  1 / 1495.2 / 26.0\n",
      "4             11 / 1127.3 / 25.7  71 / 845.7 / 24.6    7 / 633.2 / 24.3                  -  17 / 707.0 / 24.4   41 / 990.3 / 24.9   3 / 974.3 / 24.7  50 / 784.1 / 24.6  43 / 772.5 / 24.5\n",
      "5              66 / 876.3 / 24.8  27 / 885.2 / 24.7  50 / 1001.5 / 24.7  11 / 889.5 / 24.6                  -   25 / 805.4 / 24.6                  -  89 / 464.4 / 23.8                  -\n",
      "6              38 / 903.2 / 24.7  28 / 675.7 / 23.9  12 / 1189.9 / 25.0  16 / 904.4 / 24.5  19 / 781.9 / 24.0                   -  2 / 1066.0 / 25.0  64 / 649.1 / 24.1   3 / 465.3 / 23.3\n",
      "7              66 / 496.8 / 24.0  86 / 400.7 / 23.7   45 / 944.3 / 24.9  80 / 824.7 / 24.9  51 / 456.7 / 23.7   34 / 907.4 / 25.5                  -  77 / 633.0 / 24.5  74 / 517.2 / 23.7\n",
      "8               4 / 954.8 / 24.8  14 / 963.7 / 25.1  16 / 1172.5 / 25.1   2 / 870.7 / 24.5  4 / 1029.0 / 25.0  15 / 1087.7 / 25.3   2 / 935.6 / 25.5                  -   1 / 706.8 / 24.0\n",
      "9              32 / 858.5 / 25.0  61 / 784.3 / 24.9   51 / 840.5 / 24.6  82 / 655.0 / 24.5  54 / 442.2 / 23.9   63 / 921.1 / 25.3   9 / 983.2 / 24.4  90 / 269.1 / 23.7                  -\n",
      "\n",
      "Total successful attacks: 2583 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/RF_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  19 │   0 │   4 │   0 │  11 │   0 │  13 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   2 │  95 │  75 │  78 │  70 │  64 │  41 │  98 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  15 │   0 │  12 │   6 │   5 │  23 │   0 │  63 │   4 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  34 │  15 │   0 │   7 │  41 │  16 │   1 │  62 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  11 │  71 │   7 │   0 │  17 │  41 │   3 │  50 │  43 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  66 │  27 │  50 │  11 │   0 │  25 │   0 │  89 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  38 │  28 │  12 │  16 │  19 │   0 │   2 │  64 │   3 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  66 │  86 │  45 │  80 │  51 │  34 │   0 │  77 │  74 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   4 │  14 │  16 │   2 │   4 │  15 │   2 │   0 │   1 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  32 │  61 │  51 │  82 │  54 │  63 │   9 │  90 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 24.0 │ -    │ 24.0 │ -    │ 23.0 │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 23.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 23.0 │ -    │ 23.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 23.0 │ 23.0 │ -    │ 24.0 │ 23.0 │ 24.0 │ 24.0 │ 23.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 24.0 │ 23.0 │ 23.0 │ -    │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ -    │ 23.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ -    │ 25.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 23.0 │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 26.0 │ -    │ 27.0 │ -    │ 26.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 24.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.0 │ -    │ 26.0 │ 26.0 │ 25.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 26.0 │ 24.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ 27.0 │ 26.0 │ -    │ 26.0 │ 26.0 │ 25.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ -    │ 27.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 25.0 │ -    │ 25.0 │ 27.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 27.0 │ 26.0 │ 25.0 │ 26.0 │ 26.0 │ 26.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 24.6 │ -    │ 25.2 │ -    │ 24.5 │ -    │ 24.8 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 25.5 │ 23.1 │ 23.5 │ 24.1 │ 23.6 │ 24.0 │ 23.6 │ 23.1 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.9 │ -    │ 25.1 │ 25.0 │ 24.8 │ 25.0 │ -    │ 24.5 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.1 │ 24.8 │ -    │ 25.3 │ 24.3 │ 25.0 │ 24.0 │ 24.5 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.7 │ 24.6 │ 24.3 │ -    │ 24.4 │ 24.9 │ 24.7 │ 24.6 │ 24.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.8 │ 24.7 │ 24.7 │ 24.6 │ -    │ 24.6 │ -    │ 23.8 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.7 │ 23.9 │ 25.0 │ 24.5 │ 24.0 │ -    │ 25.0 │ 24.1 │ 23.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.0 │ 23.7 │ 24.9 │ 24.8 │ 23.7 │ 25.5 │ -    │ 24.5 │ 23.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 24.8 │ 25.1 │ 25.1 │ 24.5 │ 25.0 │ 25.3 │ 25.5 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 25.0 │ 24.9 │ 24.6 │ 24.5 │ 23.9 │ 25.3 │ 24.4 │ 23.7 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤═════════╕\n",
      "│   true_label │ 0      │ 2      │ 3      │ 4      │ 5      │ 6      │ 7      │ 8      │ 9       │\n",
      "╞══════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪═════════╡\n",
      "│            0 │ -      │ 427.10 │ -      │ 709.71 │ -      │ 335.42 │ -      │ 78.01  │ -       │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            1 │ 843.69 │ 36.12  │ 35.65  │ 48.14  │ 51.27  │ 84.40  │ 35.69  │ 48.74  │ 1126.11 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            2 │ 253.06 │ -      │ 603.75 │ 167.29 │ 725.20 │ 253.31 │ -      │ 61.08  │ 955.93  │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            3 │ 182.12 │ 130.17 │ -      │ 252.14 │ 53.67  │ 452.07 │ 819.82 │ 52.21  │ 1495.16 │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            4 │ 243.99 │ 84.68  │ 207.10 │ -      │ 124.69 │ 415.35 │ 714.10 │ 96.68  │ 187.34  │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            5 │ 66.35  │ 193.53 │ 258.57 │ 433.06 │ -      │ 211.84 │ -      │ 104.31 │ -       │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            6 │ 236.86 │ 91.01  │ 325.06 │ 50.36  │ 253.88 │ -      │ 958.17 │ 68.18  │ 191.48  │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            7 │ 49.88  │ 53.67  │ 50.72  │ 63.48  │ 107.89 │ 147.71 │ -      │ 52.64  │ 81.78   │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            8 │ 389.35 │ 344.30 │ 647.77 │ 734.35 │ 696.50 │ 204.30 │ 683.30 │ -      │ 706.82  │\n",
      "├──────────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│            9 │ 46.71  │ 88.88  │ 174.27 │ 59.85  │ 51.97  │ 86.24  │ 261.96 │ 63.97  │ -       │\n",
      "╘══════════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1472.78 │ -       │ 1512.56 │ -       │ 1505.54 │ -       │ 1518.90 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1235.97 │ 1098.73 │ 1495.18 │ 1412.73 │ 1482.55 │ 1496.11 │ 1517.21 │ 431.64  │ 1496.13 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1518.79 │ -       │ 1521.24 │ 1291.36 │ 1375.82 │ 1520.54 │ -       │ 1523.18 │ 1355.58 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1470.07 │ 1520.69 │ -       │ 1518.75 │ 1514.42 │ 1521.96 │ 819.82  │ 1520.46 │ 1495.16 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1519.34 │ 1523.31 │ 1516.44 │ -       │ 1436.20 │ 1519.21 │ 1304.07 │ 1521.37 │ 1523.56 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1511.52 │ 1454.67 │ 1502.08 │ 1514.19 │ -       │ 1514.86 │ -       │ 1316.49 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1521.26 │ 1519.27 │ 1456.37 │ 1404.38 │ 1269.84 │ -       │ 1173.82 │ 1473.48 │ 751.67  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1522.72 │ 1437.78 │ 1514.51 │ 1514.09 │ 1264.83 │ 1518.36 │ -       │ 1461.64 │ 1520.94 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1465.79 │ 1522.90 │ 1516.33 │ 1006.96 │ 1442.38 │ 1516.07 │ 1187.81 │ -       │ 706.82  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1497.21 │ 1517.97 │ 1523.47 │ 1521.14 │ 1221.39 │ 1522.64 │ 1365.62 │ 1378.86 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 2      │ 3       │ 4       │ 5       │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 964.09 │ -       │ 1079.65 │ -       │ 958.41  │ -       │ 878.04 │ -       │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            1 │ 1039.83 │ 163.45 │ 319.63  │ 480.96  │ 423.05  │ 500.75  │ 378.98  │ 113.36 │ 1311.12 │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            2 │ 987.03  │ -      │ 1132.19 │ 867.19  │ 1067.36 │ 998.67  │ -       │ 748.12 │ 1098.01 │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 924.12  │ 910.37 │ -       │ 1057.52 │ 759.08  │ 995.72  │ 819.82  │ 657.44 │ 1495.16 │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ 1127.28 │ 845.73 │ 633.22  │ -       │ 706.96  │ 990.35  │ 974.26  │ 784.11 │ 772.50  │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 876.30  │ 885.20 │ 1001.51 │ 889.50  │ -       │ 805.39  │ -       │ 464.45 │ -       │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 903.23  │ 675.69 │ 1189.90 │ 904.42  │ 781.88  │ -       │ 1066.00 │ 649.07 │ 465.26  │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ 496.84  │ 400.74 │ 944.33  │ 824.70  │ 456.67  │ 907.40  │ -       │ 632.98 │ 517.22  │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 954.82  │ 963.74 │ 1172.50 │ 870.66  │ 1029.03 │ 1087.72 │ 935.56  │ -      │ 706.82  │\n",
      "├──────────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 858.48  │ 784.25 │ 840.51  │ 655.03  │ 442.22  │ 921.06  │ 983.20  │ 269.11 │ -       │\n",
      "╘══════════════╧═════════╧════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\837802935.py:230: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_RF.pkl\"  # RF model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/RF_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load RF model\n",
    "rf_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = rf_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return rf_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d25e4e-5cea-42c0-b654-6969e4a59340",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ccd86c0-aba3-430c-a44c-5dd19f9c41be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\4187095252.py:47: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                   2                   3                  4                   5                   6                  7                  8                   9\n",
      "true_label                                                                                                                                                                                   \n",
      "0                              -   39 / 990.6 / 24.9  21 / 1014.2 / 24.7  6 / 1107.2 / 25.5    2 / 973.7 / 24.5   7 / 1138.2 / 25.1  3 / 1057.2 / 25.3  76 / 877.1 / 24.9  32 / 1150.2 / 25.5\n",
      "1                              -   77 / 269.9 / 23.4   61 / 467.7 / 23.9  1 / 1321.1 / 26.0   66 / 554.1 / 24.0  29 / 1128.9 / 25.3  25 / 624.2 / 24.4  98 / 151.5 / 23.1   49 / 592.4 / 24.1\n",
      "2             22 / 1169.8 / 25.5                   -   39 / 896.1 / 24.6  1 / 1054.8 / 25.0   6 / 1464.7 / 26.0   3 / 1156.2 / 25.3  1 / 1426.6 / 26.0  95 / 605.6 / 24.1   11 / 982.4 / 25.3\n",
      "3             48 / 1142.6 / 25.5   9 / 1059.2 / 25.1                   -   1 / 610.1 / 27.0  23 / 1041.0 / 25.1   2 / 1391.1 / 26.0                  -  87 / 824.2 / 24.8  25 / 1160.0 / 25.3\n",
      "4               7 / 830.4 / 25.0  26 / 1014.1 / 25.0  55 / 1021.5 / 25.2                  -   8 / 1053.3 / 25.0   22 / 905.9 / 24.7   2 / 978.5 / 24.5  93 / 796.4 / 24.5   83 / 680.1 / 24.2\n",
      "5             60 / 1044.9 / 25.1  13 / 1073.7 / 24.8   75 / 837.0 / 24.5  9 / 1113.8 / 25.2                   -   16 / 964.1 / 25.0                  -  96 / 337.7 / 23.5  14 / 1142.1 / 25.1\n",
      "6              32 / 832.6 / 24.7   47 / 878.7 / 24.4   34 / 966.1 / 24.9  22 / 983.7 / 24.8  15 / 1100.8 / 24.8                   -  3 / 1215.6 / 25.3  87 / 723.9 / 24.5  62 / 1041.2 / 25.2\n",
      "7              45 / 684.8 / 24.3   77 / 282.1 / 23.6   80 / 529.0 / 23.9  17 / 736.6 / 24.5   32 / 872.3 / 24.4  19 / 1142.2 / 25.7                  -  89 / 412.9 / 23.6   75 / 670.9 / 24.2\n",
      "8              3 / 1397.7 / 26.0   2 / 1445.3 / 26.0    3 / 973.4 / 24.7                  -                   -   1 / 1220.7 / 25.0  1 / 1443.3 / 26.0                  -                   -\n",
      "9              11 / 708.9 / 24.6  14 / 1119.7 / 25.4   83 / 593.3 / 24.3  77 / 933.6 / 24.9   24 / 787.7 / 24.4   13 / 965.2 / 25.2  12 / 950.2 / 24.4  91 / 328.9 / 23.6                   -\n",
      "\n",
      "Total successful attacks: 2615 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/XGB_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │  39 │  21 │   6 │   2 │   7 │   3 │  76 │  32 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   0 │  77 │  61 │   1 │  66 │  29 │  25 │  98 │  49 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  22 │   0 │  39 │   1 │   6 │   3 │   1 │  95 │  11 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  48 │   9 │   0 │   1 │  23 │   2 │   0 │  87 │  25 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │   7 │  26 │  55 │   0 │   8 │  22 │   2 │  93 │  83 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  60 │  13 │  75 │   9 │   0 │  16 │   0 │  96 │  14 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  32 │  47 │  34 │  22 │  15 │   0 │   3 │  87 │  62 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  45 │  77 │  80 │  17 │  32 │  19 │   0 │  89 │  75 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   3 │   2 │   3 │   0 │   0 │   1 │   1 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  11 │  14 │  83 │  77 │  24 │  13 │  12 │  91 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 23.0 │ 24.0 │ 24.0 │ 24.0 │ 23.0 │ 25.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ 23.0 │ 23.0 │ 26.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 24.0 │ -    │ 23.0 │ 25.0 │ 25.0 │ 25.0 │ 26.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 24.0 │ 23.0 │ -    │ 27.0 │ 23.0 │ 26.0 │ -    │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 24.0 │ 23.0 │ 24.0 │ -    │ 24.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ -    │ 23.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │ 24.0 │ 23.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ -    │ 23.0 │ 23.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 26.0 │ 24.0 │ -    │ -    │ 25.0 │ 26.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 23.0 │ 24.0 │ 23.0 │ 23.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 25.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ 27.0 │ 25.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 27.0 │ -    │ 27.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ -    │ 25.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 26.0 │ 25.0 │ -    │ -    │ 25.0 │ 26.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 25.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ 24.9 │ 24.7 │ 25.5 │ 24.5 │ 25.1 │ 25.3 │ 24.9 │ 25.5 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ -    │ 23.4 │ 23.9 │ 26.0 │ 24.0 │ 25.3 │ 24.4 │ 23.1 │ 24.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.5 │ -    │ 24.6 │ 25.0 │ 26.0 │ 25.3 │ 26.0 │ 24.1 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.5 │ 25.1 │ -    │ 27.0 │ 25.1 │ 26.0 │ -    │ 24.8 │ 25.3 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ 25.0 │ 25.2 │ -    │ 25.0 │ 24.7 │ 24.5 │ 24.5 │ 24.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.2 │ 24.8 │ 24.5 │ 25.2 │ -    │ 25.0 │ -    │ 23.5 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.7 │ 24.4 │ 24.9 │ 24.8 │ 24.8 │ -    │ 25.3 │ 24.5 │ 25.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 24.3 │ 23.6 │ 23.8 │ 24.5 │ 24.4 │ 25.7 │ -    │ 23.6 │ 24.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ 26.0 │ 24.7 │ -    │ -    │ 25.0 │ 26.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.6 │ 25.4 │ 24.3 │ 24.9 │ 24.4 │ 25.2 │ 24.4 │ 23.6 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤════════╤═════════╤═════════╤═════════╤═════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 2       │ 3      │ 4       │ 5       │ 6       │ 7       │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪════════╪═════════╪═════════╪═════════╪═════════╪════════╪════════╡\n",
      "│            0 │ -       │ 255.26  │ 550.88 │ 643.74  │ 740.82  │ 314.63  │ 664.51  │ 152.61 │ 227.17 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            1 │ -       │ 36.00   │ 49.94  │ 1321.05 │ 69.97   │ 320.36  │ 35.55   │ 49.83  │ 146.33 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            2 │ 532.98  │ -       │ 37.35  │ 1054.76 │ 1360.04 │ 841.54  │ 1426.63 │ 106.00 │ 259.08 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            3 │ 619.76  │ 185.91  │ -      │ 610.06  │ 325.35  │ 1347.60 │ -       │ 125.88 │ 397.46 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            4 │ 267.38  │ 84.85   │ 372.39 │ -       │ 637.23  │ 261.50  │ 466.01  │ 278.47 │ 203.88 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            5 │ 461.94  │ 404.45  │ 148.03 │ 597.00  │ -       │ 166.71  │ -       │ 85.22  │ 775.20 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            6 │ 68.33   │ 186.31  │ 586.23 │ 200.72  │ 314.15  │ -       │ 969.55  │ 68.18  │ 407.27 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            7 │ 51.29   │ 36.54   │ 55.09  │ 47.32   │ 55.54   │ 416.69  │ -       │ 103.96 │ 219.27 │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            8 │ 1341.98 │ 1370.27 │ 794.85 │ -       │ -       │ 1220.73 │ 1443.25 │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼────────┼─────────┼─────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            9 │ 166.02  │ 127.05  │ 73.12  │ 198.82  │ 53.40   │ 509.46  │ 214.66  │ 34.68  │ -      │\n",
      "╘══════════════╧═════════╧═════════╧════════╧═════════╧═════════╧═════════╧═════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ 1521.16 │ 1522.91 │ 1503.88 │ 1206.58 │ 1448.88 │ 1253.70 │ 1473.64 │ 1491.98 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ -       │ 1416.59 │ 1422.77 │ 1321.05 │ 1515.84 │ 1519.91 │ 1521.83 │ 540.58  │ 1467.86 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1519.22 │ -       │ 1422.12 │ 1054.76 │ 1521.55 │ 1348.20 │ 1426.63 │ 1517.40 │ 1463.23 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1517.74 │ 1524.55 │ -       │ 610.06  │ 1524.64 │ 1434.50 │ -       │ 1509.78 │ 1501.25 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1400.99 │ 1521.99 │ 1521.76 │ -       │ 1511.64 │ 1519.36 │ 1490.91 │ 1467.74 │ 1494.63 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1520.73 │ 1523.21 │ 1526.08 │ 1472.52 │ -       │ 1521.68 │ -       │ 744.17  │ 1471.75 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1505.43 │ 1521.26 │ 1515.67 │ 1516.83 │ 1524.13 │ -       │ 1518.78 │ 1511.78 │ 1521.32 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1499.38 │ 1521.41 │ 1522.77 │ 1519.77 │ 1522.40 │ 1510.34 │ -       │ 1259.82 │ 1516.46 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1501.84 │ 1520.40 │ 1199.07 │ -       │ -       │ 1220.73 │ 1443.25 │ -       │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1234.15 │ 1512.81 │ 1483.85 │ 1504.78 │ 1491.18 │ 1496.54 │ 1516.26 │ 997.88  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            0 │ -       │ 990.64  │ 1014.24 │ 1107.18 │ 973.70  │ 1138.18 │ 1057.22 │ 877.06 │ 1150.18 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            1 │ -       │ 269.86  │ 467.70  │ 1321.05 │ 554.05  │ 1128.86 │ 624.22  │ 151.48 │ 592.36  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            2 │ 1169.77 │ -       │ 896.15  │ 1054.76 │ 1464.65 │ 1156.22 │ 1426.63 │ 605.57 │ 982.38  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 1142.60 │ 1059.18 │ -       │ 610.06  │ 1040.99 │ 1391.05 │ -       │ 824.19 │ 1160.02 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            4 │ 830.44  │ 1014.08 │ 1021.46 │ -       │ 1053.31 │ 905.90  │ 978.46  │ 796.41 │ 680.10  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 1044.87 │ 1073.75 │ 837.04  │ 1113.75 │ -       │ 964.11  │ -       │ 337.68 │ 1142.15 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 832.64  │ 878.66  │ 966.12  │ 983.71  │ 1100.77 │ -       │ 1215.56 │ 723.91 │ 1041.22 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ 684.81  │ 282.10  │ 528.97  │ 736.61  │ 872.28  │ 1142.15 │ -       │ 412.89 │ 670.88  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ 1397.67 │ 1445.33 │ 973.37  │ -       │ -       │ 1220.73 │ 1443.25 │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ 708.88  │ 1119.73 │ 593.32  │ 933.56  │ 787.73  │ 965.16  │ 950.16  │ 328.91 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\4187095252.py:231: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_XGB.pkl\"  # XGBoost model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/XGB_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load XGBoost model\n",
    "xgb_model: XGBClassifier = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = xgb_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return xgb_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee143d-302a-4df3-8713-48b9786cfbc5",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "138a8157-d73b-4953-b528-24a1cf477df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\3048279987.py:47: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                   0                  1                   2                   3                   4                   5                   6                   7                   8                   9\n",
      "true_label                                                                                                                                                                                                         \n",
      "0                              -                  -  19 / 1291.6 / 25.4   6 / 1478.4 / 26.0   7 / 1283.2 / 26.0   4 / 1326.9 / 25.5  23 / 1294.0 / 25.6                   -   4 / 1248.3 / 25.5   6 / 1405.3 / 26.2\n",
      "1              6 / 1443.6 / 26.8                  -  99 / 1066.2 / 24.9  99 / 1243.9 / 25.8  90 / 1123.6 / 25.5  63 / 1337.5 / 26.0  91 / 1314.9 / 25.8  97 / 1051.6 / 25.1  100 / 828.0 / 24.4  55 / 1209.9 / 26.0\n",
      "2             15 / 1384.2 / 26.0                  -                   -  41 / 1239.3 / 25.3  18 / 1338.1 / 25.9   4 / 1368.4 / 26.0  36 / 1275.3 / 25.6   5 / 1323.6 / 25.6  65 / 1179.3 / 25.4   3 / 1404.4 / 26.0\n",
      "3             36 / 1306.5 / 26.1   1 / 343.1 / 23.0  15 / 1356.7 / 25.7                   -  23 / 1281.6 / 25.9  52 / 1167.7 / 25.1   9 / 1279.0 / 26.0   2 / 1112.9 / 25.0  87 / 1101.8 / 25.2  18 / 1259.5 / 25.7\n",
      "4             11 / 1347.9 / 26.1                  -  37 / 1360.5 / 26.0   9 / 1434.6 / 26.7                   -  38 / 1341.4 / 25.8  39 / 1353.1 / 25.8  77 / 1221.6 / 25.3  47 / 1348.8 / 25.8  45 / 1326.6 / 26.0\n",
      "5             77 / 1288.2 / 25.8  1 / 1439.4 / 26.0  24 / 1257.5 / 25.5  76 / 1181.7 / 25.2  28 / 1365.5 / 25.9                   -  20 / 1138.8 / 25.1   4 / 1385.9 / 25.8  95 / 1134.7 / 25.3   2 / 1439.7 / 26.0\n",
      "6             35 / 1311.3 / 25.8                  -  39 / 1304.5 / 25.8  44 / 1319.7 / 25.5  20 / 1284.1 / 25.6  24 / 1284.4 / 25.4                   -  16 / 1326.1 / 25.9  48 / 1239.4 / 25.5  10 / 1264.3 / 25.6\n",
      "7             61 / 1359.8 / 26.0  6 / 1382.4 / 26.2  66 / 1263.6 / 25.3  64 / 1317.7 / 25.4  29 / 1271.6 / 25.7  64 / 1304.9 / 25.7  12 / 1429.3 / 26.1                   -  61 / 1331.2 / 25.7  95 / 1127.2 / 25.1\n",
      "8             10 / 1400.9 / 26.4                  -   5 / 1408.1 / 25.8  73 / 1301.0 / 25.5  29 / 1303.4 / 26.2  20 / 1391.1 / 25.9  10 / 1141.0 / 25.2  10 / 1320.3 / 26.2                   -   6 / 1292.6 / 26.0\n",
      "9             26 / 1305.6 / 26.3  1 / 1072.9 / 26.0  48 / 1335.2 / 26.0  77 / 1292.3 / 25.7   99 / 850.4 / 24.8  76 / 1216.3 / 25.6  22 / 1400.2 / 26.4  74 / 1196.4 / 25.1  98 / 1171.0 / 25.5                   -\n",
      "\n",
      "Total successful attacks: 3207 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/SVM_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   2 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            0 │   0 │   0 │  19 │   6 │   7 │   4 │  23 │   0 │   4 │   6 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            1 │   6 │   0 │  99 │  99 │  90 │  63 │  91 │  97 │ 100 │  55 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            2 │  15 │   0 │   0 │  41 │  18 │   4 │  36 │   5 │  65 │   3 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │  36 │   1 │  15 │   0 │  23 │  52 │   9 │   2 │  87 │  18 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            4 │  11 │   0 │  37 │   9 │   0 │  38 │  39 │  77 │  47 │  45 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │  77 │   1 │  24 │  76 │  28 │   0 │  20 │   4 │  95 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │  35 │   0 │  39 │  44 │  20 │  24 │   0 │  16 │  48 │  10 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │  61 │   6 │  66 │  64 │  29 │  64 │  12 │   0 │  61 │  95 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │  10 │   0 │   5 │  73 │  29 │  20 │  10 │  10 │   0 │   6 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │  26 │   1 │  48 │  77 │  99 │  76 │  22 │  74 │  98 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 24.0 │ 26.0 │ 25.0 │ 25.0 │ 25.0 │ -    │ 25.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ 25.0 │ 24.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 25.0 │ -    │ -    │ 24.0 │ 25.0 │ 26.0 │ 24.0 │ 25.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 25.0 │ 23.0 │ 25.0 │ -    │ 24.0 │ 23.0 │ 25.0 │ 24.0 │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 25.0 │ -    │ 25.0 │ 26.0 │ -    │ 25.0 │ 25.0 │ 24.0 │ 25.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 24.0 │ 26.0 │ 24.0 │ 24.0 │ 25.0 │ -    │ 23.0 │ 25.0 │ 24.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 24.0 │ -    │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 24.0 │ 24.0 │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 25.0 │ 26.0 │ 24.0 │ 24.0 │ 24.0 │ 24.0 │ 26.0 │ -    │ 24.0 │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.0 │ -    │ 25.0 │ 24.0 │ 24.0 │ 25.0 │ 24.0 │ 25.0 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 24.0 │ 26.0 │ 24.0 │ 24.0 │ 23.0 │ 24.0 │ 25.0 │ 24.0 │ 24.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 26.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ -    │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 27.0 │ -    │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 27.0 │ 25.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 27.0 │ -    │ -    │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 27.0 │ 23.0 │ 26.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 27.0 │ -    │ 27.0 │ 27.0 │ -    │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 27.0 │ 26.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 26.0 │ 26.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 27.0 │ -    │ 27.0 │ 26.0 │ 27.0 │ 26.0 │ -    │ 27.0 │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 27.0 │ -    │ 27.0 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 27.0 │ -    │ 27.0 │ 27.0 │ 27.0 │ 26.0 │ 26.0 │ 27.0 │ -    │ 27.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ 27.0 │ 26.0 │ 27.0 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 2    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            0 │ -    │ -    │ 25.4 │ 26.0 │ 26.0 │ 25.5 │ 25.6 │ -    │ 25.5 │ 26.2 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            1 │ 26.8 │ -    │ 24.9 │ 25.8 │ 25.5 │ 26.0 │ 25.8 │ 25.1 │ 24.4 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            2 │ 26.0 │ -    │ -    │ 25.3 │ 25.9 │ 26.0 │ 25.6 │ 25.6 │ 25.4 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.1 │ 23.0 │ 25.7 │ -    │ 25.9 │ 25.1 │ 26.0 │ 25.0 │ 25.2 │ 25.7 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            4 │ 26.1 │ -    │ 26.0 │ 26.7 │ -    │ 25.8 │ 25.8 │ 25.3 │ 25.8 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 25.8 │ 26.0 │ 25.5 │ 25.2 │ 25.9 │ -    │ 25.0 │ 25.8 │ 25.3 │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 25.8 │ -    │ 25.8 │ 25.5 │ 25.6 │ 25.4 │ -    │ 25.9 │ 25.5 │ 25.6 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ 26.0 │ 26.2 │ 25.3 │ 25.4 │ 25.7 │ 25.7 │ 26.1 │ -    │ 25.7 │ 25.1 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ 26.4 │ -    │ 25.8 │ 25.5 │ 26.2 │ 25.8 │ 25.2 │ 26.2 │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ 26.3 │ 26.0 │ 26.0 │ 25.7 │ 24.8 │ 25.6 │ 26.4 │ 25.1 │ 25.5 │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 908.52  │ 1431.20 │ 1158.73 │ 1150.64 │ 953.63  │ -       │ 1014.42 │ 1303.93 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1306.76 │ -       │ 683.54  │ 1042.93 │ 774.31  │ 1039.25 │ 896.43  │ 629.20  │ 626.46  │ 765.79  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1034.94 │ -       │ -       │ 633.42  │ 940.86  │ 1220.87 │ 824.34  │ 1034.07 │ 699.88  │ 1340.58 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 822.73  │ 343.07  │ 1074.71 │ -       │ 677.58  │ 200.47  │ 1043.28 │ 834.70  │ 416.53  │ 758.46  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1051.39 │ -       │ 944.71  │ 1321.87 │ -       │ 1080.31 │ 974.92  │ 642.01  │ 1111.67 │ 777.23  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 822.00  │ 1439.37 │ 737.18  │ 687.46  │ 1127.65 │ -       │ 407.02  │ 1265.33 │ 618.12  │ 1427.01 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 819.43  │ -       │ 857.32  │ 1009.03 │ 563.40  │ 1021.01 │ -       │ 888.90  │ 768.82  │ 1044.03 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1053.84 │ 1175.34 │ 719.71  │ 877.92  │ 666.75  │ 787.11  │ 1262.04 │ -       │ 586.00  │ 490.08  │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1211.36 │ -       │ 1244.30 │ 680.91  │ 615.94  │ 999.63  │ 536.74  │ 1076.04 │ -       │ 1048.31 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 625.27  │ 1072.94 │ 646.82  │ 761.14  │ 380.64  │ 544.22  │ 1069.11 │ 710.37  │ 752.99  │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1524.64 │ 1511.81 │ 1441.24 │ 1522.78 │ 1524.61 │ -       │ 1410.79 │ 1517.54 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1513.89 │ -       │ 1467.12 │ 1522.71 │ 1515.08 │ 1517.55 │ 1514.94 │ 1510.69 │ 1110.94 │ 1443.81 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1520.19 │ -       │ -       │ 1519.00 │ 1519.80 │ 1515.19 │ 1520.17 │ 1511.90 │ 1521.49 │ 1510.09 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1520.53 │ 343.07  │ 1525.06 │ -       │ 1510.32 │ 1521.25 │ 1523.31 │ 1391.11 │ 1493.83 │ 1522.10 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1508.84 │ -       │ 1523.82 │ 1523.94 │ -       │ 1521.47 │ 1521.69 │ 1519.48 │ 1516.65 │ 1515.15 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1517.22 │ 1439.37 │ 1519.97 │ 1515.45 │ 1523.03 │ -       │ 1524.44 │ 1487.54 │ 1496.88 │ 1452.44 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1522.84 │ -       │ 1522.25 │ 1518.78 │ 1522.99 │ 1513.95 │ -       │ 1518.45 │ 1509.28 │ 1452.82 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1515.77 │ 1473.99 │ 1526.47 │ 1523.99 │ 1517.86 │ 1521.20 │ 1518.16 │ -       │ 1509.66 │ 1524.14 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1517.38 │ -       │ 1516.75 │ 1522.87 │ 1523.10 │ 1523.61 │ 1419.45 │ 1520.85 │ -       │ 1518.51 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1519.79 │ 1072.94 │ 1519.34 │ 1519.84 │ 1401.53 │ 1520.49 │ 1522.12 │ 1524.52 │ 1484.32 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 2       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8       │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡\n",
      "│            0 │ -       │ -       │ 1291.56 │ 1478.40 │ 1283.24 │ 1326.85 │ 1294.04 │ -       │ 1248.29 │ 1405.26 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            1 │ 1443.57 │ -       │ 1066.21 │ 1243.91 │ 1123.61 │ 1337.50 │ 1314.92 │ 1051.57 │ 828.02  │ 1209.89 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            2 │ 1384.22 │ -       │ -       │ 1239.34 │ 1338.08 │ 1368.43 │ 1275.29 │ 1323.63 │ 1179.27 │ 1404.36 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            3 │ 1306.46 │ 343.07  │ 1356.73 │ -       │ 1281.58 │ 1167.74 │ 1278.99 │ 1112.90 │ 1101.82 │ 1259.46 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            4 │ 1347.95 │ -       │ 1360.46 │ 1434.62 │ -       │ 1341.41 │ 1353.12 │ 1221.58 │ 1348.78 │ 1326.62 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            5 │ 1288.15 │ 1439.37 │ 1257.47 │ 1181.66 │ 1365.51 │ -       │ 1138.83 │ 1385.94 │ 1134.67 │ 1439.73 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            6 │ 1311.28 │ -       │ 1304.53 │ 1319.71 │ 1284.11 │ 1284.38 │ -       │ 1326.11 │ 1239.35 │ 1264.31 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            7 │ 1359.79 │ 1382.40 │ 1263.60 │ 1317.68 │ 1271.61 │ 1304.86 │ 1429.31 │ -       │ 1331.21 │ 1127.16 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            8 │ 1400.87 │ -       │ 1408.14 │ 1300.98 │ 1303.42 │ 1391.06 │ 1140.98 │ 1320.33 │ -       │ 1292.62 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│            9 │ 1305.58 │ 1072.94 │ 1335.24 │ 1292.30 │ 850.41  │ 1216.31 │ 1400.18 │ 1196.37 │ 1171.00 │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\3048279987.py:231: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_SVM.pkl\"  # SVM model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/SVM_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load SVM model\n",
    "svc_model: SVC = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = svc_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return svc_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdb7ca-f707-4943-9674-5a177aada2a0",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0e561b7-0f3b-4768-bb25-6beb84d3cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\275156326.py:46: UserWarning: Data appeared in [0,255]; normalized to [0,1].\n",
      "  warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Targeted Attack Summary Matrix =====\n",
      "target_label                  0                  1                  3                  4                 5                  6                  7                 8                 9\n",
      "true_label                                                                                                                                                                          \n",
      "2             2 / 1440.7 / 26.0  1 / 1385.8 / 27.0  1 / 1237.9 / 25.0                  -                 -                  -  2 / 1140.6 / 25.5                 -                 -\n",
      "3             1 / 1502.5 / 26.0  1 / 1424.2 / 27.0                  -                  -  2 / 638.8 / 24.0                  -   1 / 524.6 / 24.0  1 / 678.4 / 24.0                 -\n",
      "5             1 / 1428.3 / 26.0                  -  2 / 1462.2 / 26.0                  -                 -  2 / 1300.8 / 25.5                  -                 -                 -\n",
      "6             1 / 1382.9 / 26.0                  -                  -                  -                 -                  -                  -                 -                 -\n",
      "7                             -   1 / 853.2 / 25.0                  -  1 / 1422.5 / 26.0                 -                  -                  -                 -                 -\n",
      "8                             -                  -                  -   2 / 558.4 / 24.5  2 / 612.0 / 24.0  2 / 1322.9 / 26.0  2 / 1222.9 / 26.0                 -  2 / 948.1 / 25.0\n",
      "9                             -                  -                  -  4 / 1302.0 / 26.0                 -                  -  3 / 1246.9 / 25.0                 -                 -\n",
      "\n",
      "Total successful attacks: 37 / 9000\n",
      "Stats saved to CSV: adversarial_8bit_images/kNN_train\\targeted_attack_stats.csv\n",
      "\n",
      "===== Success Counts Table =====\n",
      "╒══════════════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│   true_label │   0 │   1 │   3 │   4 │   5 │   6 │   7 │   8 │   9 │\n",
      "╞══════════════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│            2 │   2 │   1 │   1 │   0 │   0 │   0 │   2 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            3 │   1 │   1 │   0 │   0 │   2 │   0 │   1 │   1 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            5 │   1 │   0 │   2 │   0 │   0 │   2 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            6 │   1 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            7 │   0 │   1 │   0 │   1 │   0 │   0 │   0 │   0 │   0 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            8 │   0 │   0 │   0 │   2 │   2 │   2 │   2 │   0 │   2 │\n",
      "├──────────────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│            9 │   0 │   0 │   0 │   4 │   0 │   0 │   3 │   0 │   0 │\n",
      "╘══════════════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╧═════╛\n",
      "\n",
      "===== Query Stats Table =====\n",
      "Min Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            2 │ 26.0 │ 27.0 │ 25.0 │ -    │ -    │ -    │ 25.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 27.0 │ -    │ -    │ 23.0 │ -    │ 24.0 │ 24.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ -    │ 26.0 │ -    │ -    │ 25.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 25.0 │ -    │ 26.0 │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ -    │ -    │ 23.0 │ 23.0 │ 26.0 │ 26.0 │ -    │ 24.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ -    │ -    │ 26.0 │ -    │ -    │ 25.0 │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Max Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            2 │ 26.0 │ 27.0 │ 25.0 │ -    │ -    │ -    │ 26.0 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 27.0 │ -    │ -    │ 25.0 │ -    │ 24.0 │ 24.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ -    │ 26.0 │ -    │ -    │ 26.0 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 25.0 │ -    │ 26.0 │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ -    │ -    │ 26.0 │ 25.0 │ 26.0 │ 26.0 │ -    │ 26.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ -    │ -    │ 26.0 │ -    │ -    │ 25.0 │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "Avg Queries:\n",
      "╒══════════════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│   true_label │ 0    │ 1    │ 3    │ 4    │ 5    │ 6    │ 7    │ 8    │ 9    │\n",
      "╞══════════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│            2 │ 26.0 │ 27.0 │ 25.0 │ -    │ -    │ -    │ 25.5 │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            3 │ 26.0 │ 27.0 │ -    │ -    │ 24.0 │ -    │ 24.0 │ 24.0 │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            5 │ 26.0 │ -    │ 26.0 │ -    │ -    │ 25.5 │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            6 │ 26.0 │ -    │ -    │ -    │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            7 │ -    │ 25.0 │ -    │ 26.0 │ -    │ -    │ -    │ -    │ -    │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            8 │ -    │ -    │ -    │ 24.5 │ 24.0 │ 26.0 │ 26.0 │ -    │ 25.0 │\n",
      "├──────────────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│            9 │ -    │ -    │ -    │ 26.0 │ -    │ -    │ 25.0 │ -    │ -    │\n",
      "╘══════════════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╧══════╛\n",
      "\n",
      "===== L2 Magnitude Stats Table =====\n",
      "Min Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤═════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 3       │ 4       │ 5      │ 6       │ 7       │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪═════════╪════════╪════════╡\n",
      "│            2 │ 1440.05 │ 1385.79 │ 1237.88 │ -       │ -      │ -       │ 924.87  │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            3 │ 1502.53 │ 1424.24 │ -       │ -       │ 54.57  │ -       │ 524.59  │ 678.43 │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            5 │ 1428.31 │ -       │ 1437.25 │ -       │ -      │ 1194.87 │ -       │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            6 │ 1382.92 │ -       │ -       │ -       │ -      │ -       │ -       │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            7 │ -       │ 853.16  │ -       │ 1422.49 │ -      │ -       │ -       │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            8 │ -       │ -       │ -       │ 251.58  │ 299.63 │ 1312.51 │ 1131.03 │ -      │ 412.52 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            9 │ -       │ -       │ -       │ 1279.62 │ -      │ -       │ 1118.32 │ -      │ -      │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧═════════╧════════╧════════╛\n",
      "\n",
      "Max Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╕\n",
      "│   true_label │ 0       │ 1       │ 3       │ 4       │ 5       │ 6       │ 7       │ 8      │ 9       │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╡\n",
      "│            2 │ 1441.36 │ 1385.79 │ 1237.88 │ -       │ -       │ -       │ 1356.38 │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            3 │ 1502.53 │ 1424.24 │ -       │ -       │ 1222.93 │ -       │ 524.59  │ 678.43 │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            5 │ 1428.31 │ -       │ 1487.16 │ -       │ -       │ 1406.64 │ -       │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            6 │ 1382.92 │ -       │ -       │ -       │ -       │ -       │ -       │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            7 │ -       │ 853.16  │ -       │ 1422.49 │ -       │ -       │ -       │ -      │ -       │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            8 │ -       │ -       │ -       │ 865.27  │ 924.30  │ 1333.34 │ 1314.77 │ -      │ 1483.73 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┤\n",
      "│            9 │ -       │ -       │ -       │ 1343.44 │ -       │ -       │ 1329.12 │ -      │ -       │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╛\n",
      "\n",
      "Avg Magnitude:\n",
      "╒══════════════╤═════════╤═════════╤═════════╤═════════╤════════╤═════════╤═════════╤════════╤════════╕\n",
      "│   true_label │ 0       │ 1       │ 3       │ 4       │ 5      │ 6       │ 7       │ 8      │ 9      │\n",
      "╞══════════════╪═════════╪═════════╪═════════╪═════════╪════════╪═════════╪═════════╪════════╪════════╡\n",
      "│            2 │ 1440.70 │ 1385.79 │ 1237.88 │ -       │ -      │ -       │ 1140.63 │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            3 │ 1502.53 │ 1424.24 │ -       │ -       │ 638.75 │ -       │ 524.59  │ 678.43 │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            5 │ 1428.31 │ -       │ 1462.21 │ -       │ -      │ 1300.76 │ -       │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            6 │ 1382.92 │ -       │ -       │ -       │ -      │ -       │ -       │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            7 │ -       │ 853.16  │ -       │ 1422.49 │ -      │ -       │ -       │ -      │ -      │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            8 │ -       │ -       │ -       │ 558.42  │ 611.97 │ 1322.92 │ 1222.90 │ -      │ 948.13 │\n",
      "├──────────────┼─────────┼─────────┼─────────┼─────────┼────────┼─────────┼─────────┼────────┼────────┤\n",
      "│            9 │ -       │ -       │ -       │ 1302.03 │ -      │ -       │ 1246.91 │ -      │ -      │\n",
      "╘══════════════╧═════════╧═════════╧═════════╧═════════╧════════╧═════════╧═════════╧════════╧════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyari\\AppData\\Local\\Temp\\ipykernel_13252\\275156326.py:231: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ─────────────── PATHS ────────────────────────────────────────────────────\n",
    "MODEL_PATH = r\"Models and Data splits/model_kNN.pkl\"  # changed model path\n",
    "DATA_PKL   = r\"Models and Data splits/Sampled_AllModels_train.pkl\"\n",
    "SUR_DIR    = r\"Models and Data splits\"\n",
    "OUT_DIR    = \"adversarial_8bit_images/kNN_train\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────── HYPER-PARAMETERS (0-1 domain) ────────────────────────────────\n",
    "EPSILON    = 0.1\n",
    "MAX_ITERS  = 5\n",
    "BIN_STEPS  = 20\n",
    "MAX_L2     = 1500\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z, dtype=np.float32)\n",
    "    pos = z >= 0\n",
    "    out = np.empty_like(z)\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-z[pos]))\n",
    "    ez = np.exp(z[~pos])\n",
    "    out[~pos] = ez / (1.0 + ez)\n",
    "    return out\n",
    "\n",
    "def softmax(lgt):\n",
    "    lgt = np.asarray(lgt, dtype=np.float32)\n",
    "    e = np.exp(lgt - lgt.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered\")\n",
    "\n",
    "# ─────────── DATA & MODEL ────────────────────────────────────────────────\n",
    "data = joblib.load(DATA_PKL)\n",
    "X, y, _ = data\n",
    "\n",
    "if X.max() > 1.0:\n",
    "    X = X.astype(np.float32) / 255.0\n",
    "    warnings.warn(\"Data appeared in [0,255]; normalized to [0,1].\")\n",
    "else:\n",
    "    warnings.warn(\"Data is already scaled to [0,1]; proceeding without change.\")\n",
    "\n",
    "# Load kNN model\n",
    "knn_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "def to_model(x01: np.ndarray) -> np.ndarray:\n",
    "    return x01.reshape(1, -1)\n",
    "\n",
    "# ─────────── surrogate cache ─────────────────────────────────────────────\n",
    "sur_cache = {}\n",
    "def load_sur(label):\n",
    "    if label not in sur_cache:\n",
    "        s = joblib.load(os.path.join(SUR_DIR, f\"surrogate_digit_{label}.pkl\"))\n",
    "        sur_cache[label] = (s.coef_.astype(np.float32), s.intercept_.astype(np.float32))\n",
    "    return sur_cache[label]\n",
    "\n",
    "def push_one_uint8(x_float01: np.ndarray, x_clean01: np.ndarray) -> np.ndarray:\n",
    "    x_pix = x_float01 * 255.0\n",
    "    x_orig = x_clean01 * 255.0\n",
    "    xi = np.rint(x_pix).astype(np.int16)\n",
    "    sign = np.sign(x_pix - x_orig).astype(np.int16)\n",
    "    changed = sign != 0\n",
    "    xi[changed] += sign[changed]\n",
    "    return np.clip(xi, 0, 255).astype(np.uint8).reshape(28, 28)\n",
    "\n",
    "# ─────────── stats collectors ─────────────────────────────────────────────\n",
    "total_trials = 0\n",
    "succ_total = 0\n",
    "misclassified = 0\n",
    "records = []\n",
    "\n",
    "# ───────────────────────── TARGETED ATTACK LOOP ──────────────────────────\n",
    "for source_digit in range(10):\n",
    "    idxs = np.where(y == source_digit)[0][:100]\n",
    "\n",
    "    for rank, idx in enumerate(idxs, 1):\n",
    "        x0 = X[idx].copy()\n",
    "        y0 = int(y[idx])\n",
    "\n",
    "        pred0 = knn_model.predict(to_model(x0))[0]\n",
    "        if pred0 != y0:\n",
    "            misclassified += 1\n",
    "            continue\n",
    "\n",
    "        total_trials += 1\n",
    "\n",
    "        for target_digit in range(10):\n",
    "            if target_digit == y0:\n",
    "                continue\n",
    "\n",
    "            query_count = [0]\n",
    "            def model_query(x_arr: np.ndarray):\n",
    "                query_count[0] += 1\n",
    "                return knn_model.predict(x_arr)[0]\n",
    "\n",
    "            W_src, b_src = load_sur(y0)\n",
    "            W_tgt, b_tgt = load_sur(target_digit)\n",
    "\n",
    "            x = x0.copy()\n",
    "            success = False\n",
    "\n",
    "            for _ in range(MAX_ITERS):\n",
    "                flat = x.reshape(-1)\n",
    "\n",
    "                if W_src.shape[0] == 1:\n",
    "                    p_src = sigmoid(W_src[0] @ flat + b_src[0])\n",
    "                    grad_src = W_src[0] * (p_src - 1)\n",
    "                else:\n",
    "                    p_src = softmax(W_src @ flat + b_src)\n",
    "                    oh_src = np.zeros_like(p_src); oh_src[y0] = 1\n",
    "                    grad_src = W_src.T @ (p_src - oh_src)\n",
    "\n",
    "                if W_tgt.shape[0] == 1:\n",
    "                    p_tgt = sigmoid(W_tgt[0] @ flat + b_tgt[0])\n",
    "                    grad_tgt = W_tgt[0] * p_tgt\n",
    "                else:\n",
    "                    p_tgt = softmax(W_tgt @ flat + b_tgt)\n",
    "                    oh_tgt = np.zeros_like(p_tgt); oh_tgt[target_digit] = 1\n",
    "                    grad_tgt = W_tgt.T @ (p_tgt - oh_tgt)\n",
    "\n",
    "                grad = grad_tgt - grad_src\n",
    "                x = np.clip(x + EPSILON * np.sign(grad.reshape(x.shape)), 0.0, 1.0)\n",
    "\n",
    "                if model_query(to_model(x)) == target_digit:\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            d, lo, hi, best = x - x0, 0.0, 1.0, 1.0\n",
    "            for _ in range(BIN_STEPS):\n",
    "                mid = (lo + hi) / 2\n",
    "                xm = np.clip(x0 + mid * d, 0.0, 1.0)\n",
    "                if model_query(to_model(xm)) == target_digit:\n",
    "                    best, hi = mid, mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "            x_best = np.clip(x0 + best * d, 0.0, 1.0)\n",
    "\n",
    "            delta = (x_best - x0).reshape(-1) * 255.0\n",
    "            l2_raw = np.linalg.norm(delta)\n",
    "            if l2_raw > MAX_L2:\n",
    "                scale = MAX_L2 / l2_raw\n",
    "                x_best = x0 + (x_best - x0) * scale\n",
    "\n",
    "            x_uint8 = push_one_uint8(x_best.reshape(28,28), x0.reshape(28,28))\n",
    "\n",
    "            if model_query(to_model(x_uint8 / 255.0)) != target_digit:\n",
    "                continue\n",
    "\n",
    "            y_adv = int(model_query(to_model(x_uint8 / 255.0)))\n",
    "            l2_final = np.linalg.norm(x_uint8.astype(np.float32) - (x0 * 255.0).reshape(28,28))\n",
    "\n",
    "            succ_total += 1\n",
    "            fname = f\"true{y0}_adv{y_adv}_mag{l2_final:.1f}_sample{rank}.png\"\n",
    "            Image.fromarray(x_uint8, mode=\"L\").save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "            records.append({\n",
    "                'sample_idx': idx,\n",
    "                'true_label': y0,\n",
    "                'target_label': target_digit,\n",
    "                'adv_label': y_adv,\n",
    "                'success': True,\n",
    "                'queries': query_count[0],\n",
    "                'l2_mag': l2_final\n",
    "            })\n",
    "\n",
    "# ─────────── Save Results & Display ───────────────────────────────────────\n",
    "df = pd.DataFrame(records)\n",
    "csv_path = os.path.join(OUT_DIR, \"targeted_attack_stats.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "pivot_data = df.groupby(['true_label', 'target_label']).agg(\n",
    "    success_count=('success', 'sum'),\n",
    "    mean_l2=('l2_mag', 'mean'),\n",
    "    mean_queries=('queries', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_data['cell'] = pivot_data.apply(\n",
    "    lambda row: f\"{int(row.success_count)} / {row.mean_l2:.1f} / {row.mean_queries:.1f}\", axis=1)\n",
    "\n",
    "matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"cell\").fillna(\"-\")\n",
    "\n",
    "print(\"\\n===== Targeted Attack Summary Matrix =====\")\n",
    "print(matrix.to_string())\n",
    "\n",
    "count_matrix = pivot_data.pivot(index=\"true_label\", columns=\"target_label\", values=\"success_count\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(count_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Success Count'})\n",
    "plt.title(\"Targeted Attack Success Count\")\n",
    "plt.xlabel(\"Target Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"summary_success_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTotal successful attacks: {succ_total} / {total_trials * 9}\")\n",
    "print(f\"Stats saved to CSV: {csv_path}\")\n",
    "\n",
    "\n",
    "# ─────────── Three Summary Tables ────────────────────────────────────────\n",
    "success_counts = df.groupby(['true_label', 'target_label'])['success'].sum().unstack().fillna(0).astype(int)\n",
    "print(\"\\n===== Success Counts Table =====\")\n",
    "print(tabulate(success_counts, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "query_stats = df.groupby(['true_label', 'target_label'])['queries'].agg(['min', 'max', 'mean']).unstack().round(1)\n",
    "query_min = query_stats['min'].fillna('-')\n",
    "query_max = query_stats['max'].fillna('-')\n",
    "query_mean = query_stats['mean'].fillna('-')\n",
    "\n",
    "print(\"\\n===== Query Stats Table =====\")\n",
    "print(\"Min Queries:\")\n",
    "print(tabulate(query_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Queries:\")\n",
    "print(tabulate(query_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Queries:\")\n",
    "print(tabulate(query_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "mag_stats = df.groupby(['true_label', 'target_label'])['l2_mag'].agg(['min', 'max', 'mean']).unstack()\n",
    "\n",
    "def format_float_table(table):\n",
    "    return table.applymap(lambda x: f\"{x:.2f}\" if pd.notnull(x) else '-')\n",
    "\n",
    "mag_min = format_float_table(mag_stats['min'])\n",
    "mag_max = format_float_table(mag_stats['max'])\n",
    "mag_mean = format_float_table(mag_stats['mean'])\n",
    "\n",
    "print(\"\\n===== L2 Magnitude Stats Table =====\")\n",
    "print(\"Min Magnitude:\")\n",
    "print(tabulate(mag_min, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nMax Magnitude:\")\n",
    "print(tabulate(mag_max, headers='keys', tablefmt='fancy_grid'))\n",
    "print(\"\\nAvg Magnitude:\")\n",
    "print(tabulate(mag_mean, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "af8d37c1-e1ad-4c0a-a7bf-8fea0efc8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_counts.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5768f5d-a1f3-4c3a-92fd-0502ab43effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_min.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8ffbb33-cd0d-46c1-a9db-e2564f3de77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_max.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba006f5d-d4d7-4a8d-bc69-1c9c600dc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mean.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e88afe5-fff9-408b-bf5c-c4099b592d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89c14fbe-a752-4a9a-82a3-c92c099cd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_max.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d90f5db-433e-4883-9563-68936431b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_mean.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34715a8-069b-41f3-a0ea-0e4d2b04b6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402205e-4d95-47f9-bbcf-767841b604d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPUEnabled]",
   "language": "python",
   "name": "conda-env-GPUEnabled-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
